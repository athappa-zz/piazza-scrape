2017-05-25 17:15:13.840909
Why do we add incorrect instead of correct examples to the subset of CNN@@@@@@You're trying to store a small subset of the original training examples. So intuitively, if you can correctly predict the label of the current example given the subset you have, then there is no point adding it to your subset. You'll just increase the size of your subset by 1 even though you could have correctly predicted the label without adding it. We add the incorrect ones because we want to be able to make a correct prediction which we can't given the current subset we have. So we add it to our subset to try to correct this mistake. Does that make sense?@@@2017-05-26T09:08:56Z@@@hw1 student
A1 Q4.2.6 Fitted Data For citiesBig2@@@I am assuming that citiesBig2 is to have its own model independent of any used on the citiesBig1 Data. Is that correct?@@@Yes you should make a model, fit it to the citiedBig2 training data, and then find the test error and training error as was done with the other models.@@@2017-05-26T23:29:52Z@@@hw1 student
4.1 KNN Implementation@@@For code implementation of predict function in KNN algorithm do we need to use matrices only for storing data orother data structures allowed as well? I implemented KNN but it works faster on citiesBig1 & citiesBig2 dataset for different k (tested only 1,2,3,4,5). I assume my implementation is correct and finds correct neighbors.@@@I don't see why you need to store data in the predict function. The predict function is used to return thelabel of the test points. Aren't you storing all the data you need in the fit and __init__ functions ?@@@2017-05-26T01:05:21Z@@@hw1 student
A1 Q4.2.2 CNN training error@@@Why should the training error for CNN be greater than 0? The pseudo code for the algorithm says that it runs until all of the points in the training set are categorized correctly by the set used to fit the model. Based on that it shouldn't get any of the training data incorrect.@@@After you fit the model using the algorithm described, try predicting the labels on for the original training data again. There is a good chance that you will get a non-zero error. EDIT: You're supposed to explain why this happens in question 4.2.4! So I can't answer why this happens. You should read the algorithm more carefully. At the end of the algorithm, we have a model - the condensed dataset. Focus on whether this condensed dataset can have perfect training accuracy. This is why I also wrote after in bold before. It's key that you consider this training accuracy after you've built your model and not how you predict on training examples while you're still building the model, which is the phase that the given pseudocode is describing. I hope this makes things clearer!@@@2017-05-26T03:30:45Z@@@hw1 student
No module named sklearn Error@@@Whenever I run python main.py -q 2 on my computer(MAC), I always got an ImportError: No module named sklearn.@@@As suggested in https://github.ubc.ca/cpsc340-2017S/home/blob/master/course_info.md I would download Anaconda. Not too sure how far you're into the assignment, but if you're using python 2 I found some problems using python 2 (on my mac) in question 5. I would advise you to download python 3 as well, if you haven't already. If you've done the above already, I'm not too sure what went wrong :(@@@2017-05-27T01:38:22Z@@@hw1 student
3.1 what should the plot look like?@@@I'm having really wierd shape of my plot. I'm wondering do we need to have a smooth line for the plot? Or we can just plot some dots instead of a line@@@Looks pretty similar to mine. Only difference is I plot dots instead of line....@@@2017-05-25T07:08:54Z@@@hw1 student
Q2@@@Hi everyone, I am confused about what is "an np.percentile-based splitting rule and the threshold-based splits". What are their differences. Thanks!@@@@48@@@2017-05-24T21:28:47Z@@@hw1 student
Q2.4@@@Do we have to explain why the errors of the sklearn's DecisionTreeClassier behave the way they do? That is, do we have to understand the concept of Information Gain?@@@You don't need to know it to the level of being able to implement it yourself. But you should understand the basic idea so that you can reason about it. I believe @Jacob Chen went over it in tutorials yesterday.@@@2017-05-24T05:14:30Z@@@hw1 student
Q4.2 class CNN(KNN)@@@Why does the class look like "CNN(KNN):" instead of just "CNN:"? Thanks!@@@I think it's related to class inheritance where CNN is a subclass of KNN? I would do a quick google search to confirm this :)@@@2017-05-24T06:50:33Z@@@hw1 student
Runtime of KNN (Lecture slides)@@@Why is the runtime of KNN for one test example O(nd)? Don't we also have to sort by distance which would take n*log(n), so we would get O(nd+n*log(n))?@@@There lots of other ways to get the k nearest neighbours other than sorting. You can use a selection algorithm to get the k nearest neighbours in linear time $$O(n)$$. If you're interested, then you can also look up kd-trees, and approximate nearest neighbour search and locality sensitive hashing (much more advanced material).@@@2017-05-26T05:14:09Z@@@other student
Explaining python code@@@Could someone explain what "%.3f" and "%" in the following line of code means? print("Testing error: %.3f" % te_error) Thanks!@@@Someone correct me if I"m wrong but %.3f should represent the format of a float with 3 decimals and % te_error is essentially being placed in where %.3f is. Ex) if te_error is 4.12345 the output of the print would be... Testing error: 4.123@@@2017-05-24T03:22:26Z@@@other student
A1: Q4.1.5@@@"If you didnt have an explicit test set, how would you choose k?" Is this assuming we test on a validation set instead or are we just testing on the training set itself?@@@Yes validation, the question is where do you get the validation set from? On the slides it describes where to get the validation set from.@@@2017-05-26T04:18:10Z@@@hw1 student
A1 Q5.2 Deal with Tie@@@Hi, I wonder what we should do if there are even number of random tree in the forest and the result from these tree are tie. e.g: there 4 random trees. 2 random trees vote for class A, another 2 vote for class B. Do we just randomly pick one class? Thanks,@@@Sure. In practice people often use this information as a measure of uncertainty. For example if you have a 15-0 vote then you could say the algorithm is more certain than if it's 8-7. (There's also more uncertainty information to be extracted if you don't split the tree all the way down to its leaves.) The scikit-learn RandomForestClassifier has this functionality build-in with the predict_proba function:http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba@@@2017-05-24T15:57:53Z@@@hw1 student
uploading on git@@@how does one upload the folder from your computer to github?  I kept going to my folder on my commandline terminal and typing 'git add .' 'git commit -m "blah" ' and 'git push' but it keeps saying not a git repository, even though it's a folder from a repository I downloaded?  (I missed the deadline for the assignment because of this, oh well..)@@@I'm assuming that you downloaded the file as a zip and not via cloning the repository viagit? If that is the case, then that is your prolem (I think you can link it back somehow but it would be very tedious). Highly recommend to use git clone@@@2017-05-27T07:12:40Z@@@other student
A1: Q4.1.3@@@"Hand in the plot generated by utils.plotClassifier on the citiesSmall dataset for k = 1." Just wondering if we should predict on X (training dataset), then plot, or predict on X_test (test dataset), then plot?@@@This is supposed to help you visualize the labelsthat the training set will give you if you used 1 nearest neighbor. So, fit on training set, then plot what the labels of the training set are. Cheers.@@@2017-05-25T00:33:12Z@@@hw1 student
A1: Q4.1.3@@@are we plotting utils.plotClassifier(cnnOBJECT, X_test, y_pred) or utils.plotClassifier(cnnOBJECT, X, y) or both?@@@Can't go wrong with just putting both in and labeling them.@@@2017-05-26T00:51:27Z@@@hw1 student
A1 Q2.3 - Finding out the split variables/values@@@I'm confused as to how I find out what variables the fit function split on when it was run, and what values it split on. I need this information to do q2.3 where it asks to code simplified predict. I tried looking through the Variable Explorer on Spyder but its a bit hard to interpret it. Is it just a matter of inserting a few print statements in the Decision Tree code to see the tree?@@@Yeah try printing out the values that are used by the included method to split, then write a series of if else statements based on these splits to tell which category the value represents. Also you can plot the way that the included version splits it and look at where the subsections are.@@@2017-05-26T02:46:51Z@@@hw1 student
Q4.2.3@@@"Hand in the plot generated by utils.plotClassier on the citiesBig1 dataset for k = 1." Are we supposed to do that for the original (X,y) in the citiesBig1 datasetor for the condensed version of (X,y)? Thanks@@@The classification surface should come from the trained CNN model. As for the points themselves, it's up to you whether you want to plot all of them or the subset.@@@2017-05-24T17:53:32Z@@@hw1 student
Clarification on function of code@@@Hey, I'm learning Python for the first time and am curious as to the way this code is working. splitIndex1 = X[:,j] > value splitIndex0 = X[:,j] <= value Is this setting splitIndex1 to X[:,j] if X[:,j] > value?@@@No, X[:,j] > value returns a boolean array. The boolean array has value True at the indices whereX[:,j]>value is True, and False otherwise. Here is a small script to test this: a = np.array([3,2,4,5]) indices = a >= 4 print(indices) This should print the following boolean array [False, False, True, True] since only 4 and 5 are larger or equal to 4@@@2017-05-24T17:01:43Z@@@hw2 student
A1 Q5.2 & 5.3 - evaluate model@@@Are we supposed to use the given evaluate_model function to find the Training Error and Testing error or do we write our own version for the Random Forest implementation? Thanks!@@@You're free to use it or modify it as you see fit. It's there for your convenience.@@@2017-05-24T17:01:24Z@@@hw1 student
A1 Q2.3 Tree depth wrong@@@Confused as the assignment says a tree of depth 2 is being produced, but I am only getting a tree of depth 1?@@@hmm.. Did you pass in the parameter into max_depth for the desired depth?@@@2017-05-25T00:24:40Z@@@hw1 student
Q4.2.6 "Try Out your function on the dataset CitiesBig2"@@@I have no idea which function this is refering to? The only function I wrote in 4 is the predict for KNN and that will not run using CitiesBig2.@@@I think it refers to prefers to using the CNN.fit and and predict function to find the training error and test error for citiesBig2.@@@2017-05-26T15:08:06Z@@@hw1 student
A1 Q5.4@@@Hi, I wonder how we are suppose to compare the speed and accuracy as there are many ways we can get the speed and accurary?For example : are we comparing both of the training error and testing error ? What should the depth be? Is it like before where we plot the graph from depth=1 to 15? And the question also suggest we can play around with the parameters in the RandomForestClassifier. So, I am confused how to discuss the result : do we need to explain why the randomForestClassifier is faster/slower than our implementation? Do we need to plot any graphs? Thanks,@@@Would assume we just use time.time() before and after running the predict functions and then to get accuracy, just use the method we have been using throughout the assignment. Instructors, correct me if I am wrong, but I believe we just need to show the different timings and then the training and testing errors for both algorithms.@@@2017-05-26T18:26:21Z@@@hw1 student
A1 4.2.3 - plotting@@@The function for plotting is hardcoded to plot colours based on the y vector having a 1 or 2, however the y vector in big cities has 0 or 1, so the scatter points will always be blue. ..Do you want us to fix the y vector so it plots correctly? Update: I just added 1 to the training and test vectors and the plot looks correct.@@@Yeah this was mentioned earlier, you have to add a 1 to all the data points.@@@2017-05-26T01:39:25Z@@@hw1 student
A1 Q4.2.1 Timing the@@@Hi, For questions 4,2,1, do we just need to time the time for fit() and predict() for CNN and KNN? What should the k be? Can we just put in the any k we want, e.g. k=3? Thanks!@@@"The point of this algorithm is to be faster than KNN. Try running the condensed NN on the citiesBig1 dataset and report how long it takes to make a prediction . What about if you try to use KNN for this dataset?" I took this to mean that timing was only for the predict function. I personally used k = 1 because the rest of the questions operate on k = 1, but I suppose you can list the assumption of which k value you plan on using.@@@2017-05-26T05:15:05Z@@@hw1 student
Clarification on euclidean_dist_squared@@@Hi, I'm not entirely sure how the function outputs.Does it compare each X object with each X_test, or is it the other way round? Do we sort the output matrix by columnthen (since it is a N x T matrix) to get the closest " X's " toeach X_test object?@@@edit: solved (turns out problem I was having was in another part of the code)@@@2017-05-27T02:58:16Z@@@hw1 student
Command for Update the Cloned Git Repository@@@How do I update my cloned git repository, so it will be the same as the remote again, using mac terminal command? " git pull "only update my local repository if there is any new commit in the remote, it does not detect any local changes I made. What if there is no new commit in the remote, and I made several unwanted changes or mistakes in my local repository, and want the cloned repository to be the same as the current remote git repository again? Thanks !@@@I think command to discard local changes is git checkout .@@@2017-05-24T21:09:23Z@@@other student
Python Not Responding when I run PlotClassifier with KNN@@@Is anyone else having or have solved this problem?@@@It's working fine for me, can you paste your code so I can see what you are trying to do? Is there potentially a loop that isn't finishing in you KNN predict function?? Edit: I fixed it, it was the fact that I was using len(Xtest) instead of Xtest.shape[1]@@@2017-05-26T23:49:24Z@@@hw2 student
A1 4.1 argsort does not give the expected result@@@I have an array named dist (the first few elements of the array) After I did indices = np.argsort(dist), I got: This seems to be wrong since the second element of my array is 0, so I should get 0 in my argsorted array, but i got 395. I can't figure out where is the problem. Can someone help me with this?@@@The elements in returned from argsort don't quite mean what you described above, I believe. Let's say I had the following dist = [4, 5, 2, 1] Argsort would return something like [ 3, 2, 0, 1] So... dist[3] -> gives you the smallest element dist[2] -> gives you the second smallest dist[0] -> gives you the third smallest dist[1] -> gives you the biggest@@@2017-05-27T01:38:59Z@@@hw1 student
A1 Q2.3 - If I set the tree depth to be a high number shouldn't I expect the error to be zero?@@@I'm struggling to make sure I'm on the right track with Q2. For 2.3 I would assume that by setting the tree depth to be a high number (10000) the error would be zero, for me it's not, does this mean I've got some other issues, or am I on the right track here? Thanks@@@You may find Q2.4 sheds some light on what you're observing in Q2.3.@@@2017-05-24T04:30:03Z@@@hw1 student
A1: Q 4.1 y value of neighbours?@@@So For 4.1 implementing predict function. I now have k nearest neighbours in a sorted list. But I am not sure how toget y value of those neighbours Any hints?@@@The trick is that you need to sort the y-values at the same time, otherwise you lose track of which y-values correspond to which x-values. You can get around this with np.argsort , which is why the assignment suggests this function.@@@2017-05-24T03:51:12Z@@@hw1 student
'No module'@@@I keep running into the problem of "ImportError: No module named 'numpy'  " whenever I run main.py on my Mac terminal.  I've done it with the following two commands: python main.py -q 1.1 python3 main.py -q 1.1  I've also downloaded Anaconda, but I still run into this problem. How do I get around it? Do I have to do something with Anaconda?  I asked my TA today, but I couldn't quite do what he suggested ("downloading PyCharm, then configuring to Python3"), and since I had class right after I couldn't stick around to complete the whole process.@@@If you ask about could not find module for random forest, just comment it out. You won't need this until the last problem. Darn ,my bad, I didn't noticednumpy. Juts ignore my answer. Apologies.@@@2017-05-24T01:53:45Z@@@hw1 student
Validation error@@@I'm having trouble understanding the following statement from the lecture slides: "Validation error is only an unbiased approximation if you use it once." Lets say we use a validation set to decide on the depth of our decision tree. What does it mean to "use it once"?@@@I think this is related to the issue that if you have some large number of models, like a million, and you test all of them on the same validation set then one will likely outperform the others even though it isn't a better model for real world data. So if you use the same validation set multiple times it is biasing a model that preforms well on that set specifically, or in other words you are overfitting to the data of the validation set.@@@2017-05-24T05:46:01Z@@@other student
Q4.1.1 Predict Single Point Or Whole DataSet@@@Was wondering if the KNN predict a single input or the entire test data in one call?@@@The entire dataset.@@@2017-05-26T03:16:23Z@@@hw1 student
Requesting Partners@@@For A2 we have to re-request our partners and this has to be done before the assignment is released;am I understanding that correctly?@@@Yep!@@@2017-05-26T19:47:23Z@@@hw2 student
A1 Q5.2 None after fitting random tree@@@I created RandomTree object and fit(X, y). When I print the result of the fitting, I got "None" for all myrandom trees. I am quite lost on why I got None. Any help is appreciated.@@@are you doing something like this? print(model.fit(X,y)) because fit function does not return anything if you want to see if object is created or not, I'd rather try print(model)@@@2017-05-26T06:43:37Z@@@hw1 student
A1 Q4.2.5@@@For this question, I'm confused on how n will be involved in finding the cost of the function. We're comparing the t test exampleswith the s subset examples and that would not involve n . Thanks!@@@Yeah I don't think it should include n at all. If you think about the case where all data points in n are the same category, then s should be of size 1 and the runtime for a predict would be the exact same if n was 1 as it would if n was 1 million.@@@2017-05-26T01:17:49Z@@@hw1 student
A1 Q5.2 - RandomForest Class@@@I'm a bit confused as to what we are supposed to include inthe RandomForest class and how to structure it. From what I understand, we are supposed to fit num_trees number of random trees and then take the mode of those predictions. However, I'm not too sure how we should store the fits of each of these trees in a way that we can use the predict function on them after. Should we be using an array in the random_forest class to store the fits or is there a better way to do this? Any help will be appreciated!@@@Yep, the easiest is to make a Python list and have it contain the RandomTree objects. Then you can iterate through the list and call fit on each RandomTree.@@@2017-05-24T20:03:55Z@@@hw1 student
A1 Q4.1.1@@@When I try to run the command "run main.py -q 4.1" after completing the predict function, it just stops here and shows nothing. Can someone give me a hint why it happened?@@@I don't what you've done but 4.1 part in main has nothing in it to start with. Maybe you have to add some code it?@@@2017-05-26T20:58:25Z@@@hw1 student
A1 Q3.2 need some clarification@@@In Q3.2, it says that "How could use more of our data to estimate the depth more reliably?" I'm having some trouble understanding the line "use more of our data". My understanding is that since we are having n/2 examples for training set and n/2 examples for validation set, the training set and validation size is the same. If we want to use more of our data to estimate the depth, we need to increase the size of training set and decrease the size of validation set. Say change training set size to 2n/3 and validation set size to n/3. This is what I'm thinking, but I'm not sure if this is what this line is really asking for. Can someone confirm me, or tell me what this line is asking if my understanding is wrong?@@@@@@2017-05-26T22:01:17Z@@@hw1 student unanswered
A1: Q4.1@@@How do we measure the test error for knn? how do we know if the predict value is correct?@@@There is a XTest and YTest inside the citiesSmall dataset... Predict using your trained data, compare the prediction with the test set labels. Cheers.@@@2017-05-25T00:21:49Z@@@hw1 student
Q5.2@@@How do I create a list of RandomTree objects? I am trying to do it this way models[i] = RandomTree(max_depth=np.inf) But the error appears: TypeError: float() argument must be a string or a number, not 'RandomTree' Should I initialize list using something else instead of np.zeros?@@@As @77 suggested a python list would do. You can create an empty list something like #create a list list_of_trees = [] #add to the list list_of_trees.append(< your random tree >)@@@2017-05-27T01:32:22Z@@@hw1 student
Question on Q3.2@@@For Q3.2, I assume we are using the dataset "citiesSmall" but since we are asked to cut it in half, is it actually to cut ytest, Xtest, y, and X arrays in half? I tried to do something like this: dataset = utils.load_dataset("citiesSmall") row_count = len(dataset) trainSet, validSet = dataset[:row_count*1/2], dataset[row_count*1/2] But it shows an error: File "main.py", line 205, in <module>     trainSet, validSet = dataset[:row_count*1/2], dataset[row_count*1/2] TypeError: unhashable type This is the dataset:@@@The type of the dataset variable is a dict . You need to cut the individual arrays in half. Also, you don't need to split the test data as we're assuming it doesn't exist.@@@2017-05-24T20:07:36Z@@@hw1 student
Assignment 1 Question 3.1@@@Are we supposed to insert the plot in the report, or just the description of the plot is okay or are we supposed to check in the generated plot, leaving it in the figs folder and link to it in the README? Thank you!!@@@I'd say just put the plot in the report in case the TA wants to see it and not have to go back to your figures folder or to the link. And it might be graded anyway so you should put it in either way.@@@2017-05-26T04:39:26Z@@@hw1 student
