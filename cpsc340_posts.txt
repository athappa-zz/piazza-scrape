What is the next course/step to take?@@@340 has been a very fruitful and interesting journey to me. I truly enjoyed the course! However, the more i learned the more i felt how big the gap is between getting a taste of the model VS implementing it in the real life problems. As i am looking into the career in data science, what would you recommend me to learn/ or courses to take? Below is some of my researches on this topic. Feel free to correct me STAT 406:Statistical Learning (re-teach everything 340 with more statistical applications) CPSC 540: Machine Learning in Grad-level(Is UBC not offering in 2017W ?) :( CPSC 406: Computational Optimization (Everything after you formulate a loss function?) CPSC 322/422: Artificial Intelligence (Feels like self-reading the algorithm is enough..) STAT 321: Stochastic Process (Good for studying Hidden Markov Chain?) STAT 460: Statistical Interference I Join some Kaggle competitions...@@@I thought it was mentioned in class that CPSC 540 WILL be offered next year (2017W) and that it would be sometime in the late afternoon probably 4:30PM Mon/Wed/Fri of Term 2. Though after that final I seriously question how much information I might be correctly recalling from the lectures... Mike edit: I thought it was 4-5pm. I guess we'll see soon.@@@2017-06-28T05:39:22Z@@@other student
More questions@@@I have more questions to complete my lecture slides: - L26 page 14: what are the weak assumptions to reach local minimum? - page 16: what is an example for non-sensible ordering? - page 20: which is the better one? - page 25: what is an example of removing correlations? - page 28: what is opponency (I can't find the word in my dictionary)? - L27 page 23: how do we choose numerator gradient? - L29 page 35: is binary search to look at only logn examples? - L31 page 12: what is/how do we subsample? - page 32: what is spacial regularizer? - L33: is bottom inequality restricting rules amount? - page 22: what is the 2^d calculation (is it two for present or not present)?@@@1. Don't know! 2. Maybe you just want a bunch of factors but in no particular order. That's all its saying. Rather than PCA which orders from most to least variance explained. 3. Depends what you're trying to accomplish! 4. See http://ufldl.stanford.edu/tutorial/unsupervised/PCAWhitening/ 5. See https://en.wikipedia.org/wiki/Opponent_process 6. This is described at the bottom of the slide (practical trick). 7. It seems that L29 does not have a page 35? 8. Subsampling means taking a subset of the samples and throwing away the rest. For example you can subsample (or "downsample") an image by throwing away 3 out of every 4 pixels to get half the resolution in each dimension. 9. A term that encourages neighbouring pixels to have similar values. 10. Which page? 11. Yes. Present or not present for each feature.@@@2017-06-28T04:18:57Z@@@other student
Final location@@@Does anyone know where the final is? I can't seem to access SSC --> I'm guessingit has something to do with 3rd year course registration, don't know.@@@Angus 098@@@2017-06-27T17:46:45Z@@@final_exam student
Low-dimensional representation?@@@From the2016W2 final question 5 b), I am unsure how to reduce this vector to $$[-2,0]^T$$. Can someone show me their approach?@@@Multiply $$ W^Tz_i $$ where $$ z_i $$ is the centeredlow dimensional representation vector in the quetion.@@@2017-06-27T16:16:07Z@@@final_exam student
A4 3.1 PCA by Hand@@@Why is reconstruction error not the sum of the squared errors but the square root of it.I'm looking at the formula from lecture 23 slide 14.@@@I'm pretty sure that the reconstruction error is different from what you have on the slide which is the loss function. The reconstruction error is just a measurement of how far off you were on the reconstruction,we use the square root of the sum of the squares because that's the distance from out reconstruction to the actual original point.@@@2017-06-27T03:56:42Z@@@hw4 student
Increased test error for L2?@@@In the slides, it says: It says "almost", so is there any situation that will increase the test error?@@@Iguess if lambda is very (infinitely) large, then the model can be even worse than without regularization, because we focus on minimizing ||w|| ignoring the rest of the function. For example, by playing with L15 demo and setting regularization strength to 100 I got the following. Imagine what would happen if reg strength is 10^10000.@@@2017-06-27T03:18:45Z@@@other student
Lecture 26, Slide 18@@@What do we mean by "negative coefficients usually make sense"? Does that mean that sometimes we want sparsity but not necessarily restrict ourselves to non-negativecoefficients because in a certain contextnegative coefficients make sense?@@@You tend to use NMF when negative parameters don't make sense for the problem (because NMF doesn't allow negative parameters). If negative paramters do make sense/is reasonable, then you may want to use L1 instead of NMF because the former allows negative weights.@@@2017-06-27T02:49:17Z@@@final_exam student
L14 Page 23: L0 optimization@@@In L14 P23, it says I was wondering if we cannot use gradient descent, then what do we use to optimize L0?@@@I'm not really sure, but we should minimize the whole thing, which is $$parabola+number\_of\_non\_zeros=parabola+integer$$ And$$parabola+integer$$ is just a parabola, so we can minimize it.@@@2017-06-27T02:47:08Z@@@hw0 student
How long is the final?@@@thanks for a good course@@@Last year's was 2.5 hours. I assume ours will be too. Yes it will (lecture 25 slide 2)@@@2017-06-27T02:35:05Z@@@final_exam student
PCA uniqueness@@@Why is it a problem if PCA is not unique?@@@Because it means that without restriction there are infinitely many solutions. I can write: $$X=ZW$$ or $$X=\frac{1}{10}Z*10W=ZW$$ or $$X=\frac{77}{89}Z*\frac{89}{77}W=ZW$$ etc. Remember when we got PC in assignment 4? Theline we got passes through (0,0) and (1,1) and it's equally correct to write it as <1,1> or <2,2> or <1/5,1/5> etc. But there is a restriction |w|=1 to make things more convenient, so now there are only two way to write it: $$<\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}>$$and$$<-\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}>$$@@@2017-06-27T02:31:22Z@@@final_exam other student
Pagerank@@@Maywe have bonus slides about studying Pagerank? I've been told that it is curriculum with this course in other terms...May we also have slides about all other missed material? I'd like course material that we missed due to oursummer term...@@@Check out Mark's website: https://www.cs.ubc.ca/~schmidtm/Courses/340-F16/@@@2017-06-27T02:20:08Z@@@other student
L29 page 38@@@Is "Not really simulating binary signal, but could be simulating rate coding.", about the reLU activation function, meaning that we should not use this when our response variable is a binary variable?@@@@@@2017-06-27T02:15:23Z@@@other student unanswered
2016W2 midterm Q3b@@@Why is the space complexity of Naive Bayes just O(d)? I thought we need to calculate the conditional probabilities, which means we need to have access to the original dataset.@@@Because "with binary features and binary models". So all you need to predict an example is to compare $$p(y=0|x)$$ with$$p(y=1|x)$$ And from L22 slides you can see that we iterate over d only when computing these things:@@@2017-06-27T02:12:21Z@@@final_exam midterm student
Softmax training cost@@@Does anyone know what is Softmax's training cost? I can't seem to find it in the slides...@@@I'm not sure but for training we have to use gradient descent. Gradient descent is usually O(dnt) where t is the number of iterations.So the question is probably how long it takes to calculate the gradient which in this case is a $$d x k$$ matrix. Lets see what Mike says.@@@2017-06-27T01:45:58Z@@@other student
Robust PCA Parameters - 2016W2 Final 3a@@@In 3a) on last term's final, we are asked for the number of values that need to be stored after training to make predictions later on for a number of models. I am just curious as to why the number of parameters for robust PCA doesn't include the means of the features - the answer key gives only kd as the solution, the size of W - but I was under the impression we would also need to store these means in order to subtract them off new examples, as we did in A4, before multiplying them by our W. For this, I would have answered kd + d ... is there something wrong with my intuition here?@@@That's a good point! $$kd+d$$ would be an even better answer.@@@2017-06-27T01:33:08Z@@@final_exam student
linear classifier parametric?@@@I know SVM is parametric, but can someone help to clarify if hinge-loss without regularization and logistic regression loss parametric or non-parametric.@@@All those things you mention are linear classifiers. So they are parametric. And in particular you have one weight per feature just like linear regression.@@@2017-06-26T22:47:21Z@@@other student
Pass Final@@@Do we need to pass the final to pass the course?@@@No@@@2017-06-26T22:37:52Z@@@final_exam student
Neural Network Parameters@@@Can someone shed some light as to why a neural network with two hidden layers of size "a" and "b" need to keep the following parameters: da + ab + bk + a + b + k? It makes sense to me why we want da, ab, a and b and k because those are the regression matrices for the hidden layers + intercept + linear regression coefficient for prediction. Why would we want bk though? I thought at the end, we would only have a column vector for the linear regression weights that combine the final learned latent factors (which we've accounted for with k).@@@The question states that $$k$$ is the number of outputs, so in the end we should be getting a vector of size $$k$$. So that means for each $$k_j$$ we take a linear combination of $$b_i$$'s. Hence the extra parameters of size $$bk$$.@@@2017-06-26T22:09:23Z@@@final_exam student
Gradient Descent with L1 and L0 regularization@@@Hi, I understand that we use smooth approx. to loss function fn so then we can differentiate the objective. So If we are using L1 or L0 regularization term, do we also need to use smooth approximation to the regularization term so that we can differentiate the objective fn? Thanks@@@I don't think we want smooth approximations to the regularizationterms because then we wouldn't get this nice sparsity effect anymore. To optimize loss functions involving L1 regularization we can use proximal gradient methods instead.@@@2017-06-26T21:02:57Z@@@final_exam student
Hinge loss: Lecture 17, Slide 19@@@Even if the solution is a perfect classifier (getting the sign right for every example), why does that imply that f(w)=0? We could still have a $$1-y_iw^Tx_i > 0$$ for an example even if we correctly predict its sign (for instance if $$y_i=1$$ and $$w^Tx_i = 0.5$$).@@@I added the "because then f(w)=0" to Mark's original slide. Then I remember in lecture saying I wasn't so sure about this anymore. If there is L2 regularization then it is not true. But if it's just $$f(w)$$ as written then it might be, because you could scale $$w$$ to be arbitrarily large. It's probably just confusing though. You can safely ignore it.@@@2017-06-26T20:27:03Z@@@other student
Exam 2016W2 Q3 Intercept Storing@@@I understand storing weights for making the predicitions, but I am unsure what the intercepts are and how they aid in prediciting?@@@The intercept values allow you to shift the model's prediction to the location of the data if it is not centered at 0. Consider a simple linear regression $$y=ax+b$$ . We want to find the $$a$$ and the $$b$$ to get the line of best fit that crosses through some data with minimum squared error. If we didn't have the intercept value, we'd only be able to work with $$a$$ and probably get a very bad fit if the data actually was shifted away from 0. Instead, we can add an intercept value to get a better fit. We can do this sneakily by saying that $$ y = \begin{bmatrix} a & b \end{bmatrix} \begin{bmatrix} x \\ 1 \end{bmatrix}$$ So the parameters we want to learn are $$ \begin{bmatrix} a & b \end{bmatrix}$$. See Lecture 9.@@@2017-06-26T16:48:10Z@@@other student
What's the weight percentage for before mt and after? Is that 50:50@@@@@@I guess I don't feel the need to specify it so precisely. The whole course will be covered, especially material that appeared on assignments. I don't want you to overfit to the specificationsof the exam.@@@2017-06-26T06:55:06Z@@@final_exam student
2016W2 final, Q4f@@@What parameters have to be initialized for logistic regression and SVMs?@@@The regression weights, $$w$$.@@@2017-06-26T06:53:28Z@@@final_exam student
When do we need to standardize columns in general?@@@It's in the last lecture slide Big ideas of the course:collecting your data,preprocessing(standardize columns?)@@@An example would be when using PCA. It assumes that the columns are centered around 0... so you'd just subtract the mean of each feature from each feature. So, a process would be standardizing the data, performing PCA, then when new data comes in, standardize with respect to the data. If we want to reconstruct the data, we'd have to reverse the process and so that requires us to add back the mean after the PCA reconstruction.@@@2017-06-26T06:44:17Z@@@final_exam student
What is the terminology "tiny effect" in general@@@@@@I believe it has to do with the weight associateda particular variable. So for instance $$10x_0$$ would have a much larger effect than $$0.000001x_0$$.@@@2017-06-26T06:36:21Z@@@final_exam student
2016W1final_sols.pdf@@@Is the solution to Q8c and Q8d correct? Shouldn't it increase the training error instead? Thanks@@@Yep (see @331)@@@2017-06-26T04:53:10Z@@@final_exam student
What room will the review session be in?@@@Will it be the same as the tutorials?@@@I think Mike mentioned it would be in dmp 110 or whatever the room number our lectures are in?@@@2017-06-26T04:15:30Z@@@final_exam student
Hinge loss@@@We might have discussed this, but how do we optimize the hinge loss?@@@We didn't really talk about it. We just said it's convex and it can be done efficiently.@@@2017-06-26T04:03:00Z@@@other student
MDS preserves high dimensional distances@@@I'm trying to understand MDS cost function here: I am confused that, since we need to minimize the cost function, then how does the cost function tell us the "z_i preserve high-dimensional distances between x_i"?@@@If $$f(Z)$$ is small, that means that the terms that we're summing up are small, ie. $$\|z_i - z_j\| - \|x_i - x_j\|$$ are small. In other words, $$\|z_i - z_j\|$$ and $$\|x_i - x_j\|$$ are close to each other. The first term here is the distance between examples $$i$$ and $$j$$ in low dimensions and the second term is the distance in higher dimensions. Thus, what we're trying to do is to minimize the difference between the high dimensional distance between examples $$i$$ and $$j$$ and their low dimensional distance.@@@2017-06-26T03:36:24Z@@@other student
non-parametric method@@@I am confused that why this is a non-parametric method? Can someone explain it? Also, is linear regression a parametric method or non-parametric method?@@@This is a weird one. Normally, linear regression with a polynomial basis would be parametric. The trick is that the basis of degree $$n$$, which means the complexity grows with the number of training examples. More generally, linear regressionis usually parametric. But if the number of features (and thus weights) grows with $$n$$ (like in the above or with RBF features) then we'd call it non-parametric.@@@2017-06-26T03:04:17Z@@@final_exam student
What does the @ symbol do?@@@It doesn't seem to be a standard python thing. And I'm having trouble figuring it out because you cant Google search the @ symbol.@@@When used as an operator (like +, -, /, *), it represents matrix multiplication.@@@2017-06-26T01:30:36Z@@@other student
Convolutional neural network@@@Could somebody explain whatthe whole point of convolutional neural networks is? I know that this is a big question but some form of short explanation might help in getting a better grasp of this. Thanks!@@@@@@2017-06-26T00:54:31Z@@@other student
Coding questions on final exam?@@@Apologies if this was mentioned already, but are there going to be coding questions on the final? The midterm did not have coding questions like Mike said, but I'm not sureif that is the case for the final.@@@Nobody has asked this yet. The answer is, the final might ask you to read and/or write Python code (last year's final had a question that involved reading code). But, if there is a question about writing code, syntax errors will be forgiven -- I understand nobody actually writes code on paper in real life.@@@2017-06-26T00:35:14Z@@@final_exam student
collaborative filtering@@@Why is it the case that collaborative filtering cant predict ratings for new users/movies? I read the post @330, which I think is related, but I still don't understand it. Is it simply because we estimate latent factors $$w_j$$ and $$z_i$$ for the existing movies and users and we simply don't have anything to estimate ratings of a new user or movie? But if, for example, we have a new user who has ratings for some movies why don't we just add that user into our original user/movie matrix and repeat the optimization process? Thanks!@@@(Warning: the below might look simple but it's not. Take your time!) Let's use the notation from the assignment, meaning the latent factors are $$u_i$$ and $$v_j$$ and we approximate $$y_{ij}\approx u_i^T v_j$$. Now imagine that $$y_{ij}$$ is missing for all $$j$$, meaningthat user $$i$$ has not rated any movies yet. Then there are no training examples to help us train $$u_i$$. Put another way, all predictions you might make with $$u_i$$ are missing training data, so we cannot train $$u_i$$ at all. The above is the PCA view of the problem. There is another view, which is that collaborative filtering finds similar users/movies (it's the same math, just different intuition).So if we want to predict $$y_{ij}$$, we could ask "what did user $$i$$ rate for similar movies?" or "what did similar users to user $$i$$ rate this movie as?" But if we have no ratings for user $$i$$ then we cannot answer either of these questions.@@@2017-06-26T00:25:21Z@@@other student
backpropagation@@@I am wondering how much we need to know about backpropagation for the final?@@@You should know what it is (derivative of neural net loss wrt weights using a clever algorithm to not re-compute things) but you don't need all the details.@@@2017-06-25T23:09:01Z@@@final_exam student
L0 regularization explanation (slide 14)@@@I'm having some trouble understand the line For L0 regularization, is f(w) the score function or just L0 norm the score function? what should 's' be then?@@@$$s$$ is some subset of the features. $$f(w)$$ is the score function, for example a squared error term plus an L0 term.@@@2017-06-25T21:17:54Z@@@final_exam student
Standardizing target@@@In the L2-Regularization slides, it says setting w=0 with a standardized target predicts average y i . I'm confused because wouldn't setting the weights to 0 make all predictions 0?@@@Correct me if I'm wrong: If you set the weights to 0, your predictions are 0, which equals the average$$y_i$$ if$$y_i$$ is standardized. (standardizing$$y_i$$ gives it a mean/average of 0).@@@2017-06-25T16:52:31Z@@@other student
Lists of questions@@@I listed my questions below. 1. Lesson 24 Page 9: How does PCA maximize variance in Z space? What does it mean and why? 2. From 2016 w2 midterm exam Q1(c): Including a bias (intercept) parameter in OLS will cause training error to decrease? The answer is Yes. But... - I thought it is acting a similar role as increase$$\lambda $$ in L2-regularized OLS, because it is also adding an extra term in the OLS. But why would including intercept parameter not cause training error will increase?? 3.From 2016 w2 midterm exam Q4(a): I was wondering why is it not 5 * 4 = 20? Because there will be 20 combinations of splits. 4. continued from the question above, (From 2016 w2 midterm exam Q4(b)) I don't quite understand the solution, but my answer was: yes, if we split 4 <= x1 <= 5, 2<=x2<=3, then all data within the range will belong to -1, and everything else will belong to +1. Why is it wrong? Thanks in advance.@@@1. Suggest you ask this as a separate post. A student should be able to answer but students probably don't want to answer all 4 questions. 2. Adding an intercept is completely different from adding regularization. The intercept is a trainable model parameter, whereas $$\lambda$$ is a hyperparameter. This is a critical distinction. More traininable parameters generally means more model complexity and therefore lower training error. Whereas regularization is meant to prevent overfitting but costs you a bit in training error. 3. I don't understand your reasoning. Can you explain it in depth? 4. The question is asking about a decision stump, you are thinking of a decision tree.@@@2017-06-25T07:12:41Z@@@other student
Opening an issue on GitHub@@@Just want to make sure I did this correctly. I opened an issue about the Assignment 4 grading by opening an issue in my grade repository. I explained what the problem is and included @cpsc340-2017S/staff . Is that the way to do it? Thanks@@@Yes. If it slipped through the cracks please try again.@@@2017-06-25T06:55:03Z@@@hw4 other student
Lecture 18, Slide 17@@@How exactly does $$\lambda$$ control the trade-off? Does a larger $$\lambda$$imply a smaller margin?@@@After teaching SVMs for the third of fourth time this term, I'm starting to think that we should drop the whole notion of margin. It's always taught this way, where you start from linearly separable data and maximize the margin. But whenis a data set ever linearly separable anyway?? And if it's not, does the margin even make sense? No to mention that we set the margin to 1 through some crazy manipulations as discussion in the bonus slides. So I'd say, to understand it to 95%+ depth, you can just forget the margin. Instead, just think about it as a linear model with a bunch of $$w$$'s that multiply the features just like linear regression. And regularization keeps the values in $$w$$ small. When you use a nonlinear basis, regularization is maybe even easier to understand. I suggest you play around with the notebook on this ( https://github.ubc.ca/cpsc340-2017S/home/blob/master/lectures/L20demo.ipynb ) and try changing the regularization parameter. This is $$C$$ in sklearn, which is basically $$\frac{1}{\lambda}$$. So when $$C$$ goes towards zero that means lots of regularization. Another way of answering your question: a bigger $$\lambda$$ means you're more forgiving about misclassifying points. This is true for every model (not just SVM). There's a tension between the data fit term (usually written on the left) and the regularization (usually written on the right), and $$\lambda$$ controls the tradeoff between them.@@@2017-06-25T01:35:59Z@@@other student
Face Detection via Eigenfaces@@@How much about the eigenfaces from L24 do we have to know for the final?@@@They are an example to help you understand and appreciate PCA and then later NMF. So you need them to the extent that they help you understand, not for the eigenfaces themselves. I think it's worth getting to the point where you understand the basic premise, which is that the images are "flattened" into feature vectors and the principal components can thus be put pack into image form (un-flattened?) and visualized as in the slides.@@@2017-06-24T23:45:13Z@@@final_exam student
Centring and Standardizing y?@@@Do we ever want to centre and standardize our target/class labels $$y$$, like we do with our examples/features matrix $$X$$?@@@Yes, this is sometimes done. In fact, having an intercept or "bias" term in linear regression is related to this issue. Instead of using an intercept, you could have centred the $$y$$ values instead. But this would not necessarily give you the same solution, because the intercept doesn't necessarily always work out to being exactly the mean of the examples. So it's better not to constraint yourself in this way. The scalingof the features $$X$$ is more important because you have to worry about the scale of each feature relative to the other features, for methods where this matters (e.g. KNN, most regularized models). The question to ask yourself is whether the model would be affected or not by a given preprocessing step.@@@2017-06-24T22:57:37Z@@@final_exam student
L27 Slide 14@@@I'm really confused as how we got w3, why do we move left from w2 to get w3? Also why do we go back for f1(w)?@@@With SGD using a minibatch size of 1, at each iteration you pick one random training example and take your gradient step with respect to that example only. In this slide you happened to pick a training example that isn't particularly representative (maybe it's an outlier) and its own little loss function (the lower parabola) tells you to go left. So you go left even though a regular gradient descent step would have taken you to the right.@@@2017-06-24T22:55:55Z@@@final_exam student
2016W1final Q8 (b) and (c)@@@I don't quite understand "since we can increase the norm of Z to compensate for any decrease in the norm of W" . How exactly is this done? Will this also affect the first term of the objective function? And for (c), why does the training error decrease instead in this case?@@@This is saying that if you don't have the orthogonality constraint on $$W$$, then you can always multiply the entire $$Z$$ matrix by some constant (say, 2) and divide the whole $$W$$ matrix by that same constant, and you'll get a model with the same loss. Sobasically if you only regularize $$W$$ then the solution is to make $$W$$ arbitrarily close to 0 and $$Z$$ correspondingly huge, which satisfies the regularization term and the data fit term. In (c) we're back to the normal world where regularization actually does stuff.@@@2017-06-24T22:23:49Z@@@final_exam student
Movie Recommender for Unsupervised Learning@@@If I remember correctly, professor said that using unsupervised learning method for movie recommender, it wouldn't work if the new movies don't have ratings yet. Is it because since we are grouping similar users with the movies they rate, if the movies are not rated, we cannot find any users with the new movies?@@@The way I interpret it is that the with an unsupervised model we are try to learn the Z and W that best represent X, i.e. X = ZW. In the assignment the SVD model essentially finds two matrices U and V that best reconstruct the original matrix, let's call it X, which contains all the ratings for particular movies and users. When we constructed a training and validation set we removed certain elements of the matrix X, but not necessarily complete rows or columns, i.e. complete users and movies. The goal of our unsupervised approach is try and fill in the missing matrix entries by using the information we have about the rest of the column and row for that particular movie/user pair, coupled with other information in our data set.@@@2017-06-24T21:16:24Z@@@other student
L28 Questions@@@Hello, I have a question about lecture 28 Slide 8 - Inactual neurons, a signal is either propagated through axion, or not.But in our neural networks, we always send the signal (value of $$W_c x_i$$) along, large or small. It is my understanding that we want to only approximate the binary decision of the propagation of the signal in our brain by using a sigmoid function.In the slide,it is mentioned that sigmoid function is used as an approximation to identity function, because identity function ishard to optimize. But identity function being hard to optimize and non-differentiable is not the only reason we are not using it, correct? It is also because we want all signals to be propagated, in our neural network, correct?If we could use the identity function, it would mean that some of the elements of z_i would not be propagated and used for predicting $$y_i$$, which is definitely not want we want, correct? Thank you!@@@If we are talking about the identity, $$f(x) = x$$, I would disagree against the reasoning as to why avoid using it. The reason we use a non-linear activation function like the relu or sigmoid is that we want to add non-linearity to our model. If we just had the identity function as our activation function then we could collapse two hidden layers into a single matrix operation. $$W_2h(W_1X)$$ cannot be simplified if $$h$$ is the sigmoid, for example. However, $$W_2f(W_1X)$$ can be simplified to $$W_2W_1X = (W_2W_1)X = W_3X$$, if $$f$$ is the identity function. We are not adding any non-linearity to our model and therefore we can collapse the two matrix operations $$W_2$$ and $$W_1$$ into $$W_3$$.@@@2017-06-24T18:55:19Z@@@other student
Why I can't have 0 training error?@@@When I use a neural network, if I have a single hidden layer with the size being the same as the number of examples, I should have 0 training error, right? I have tried that on the boston house price dataset from sklearn.dataset, but I still get a training error around 23, which is the same as using the linear fitting (hidden_layer_sizes = ()). Why is this the case?@@@There are other things that effect what the net converges too. I was able to get lower and lower training errors increasing iterations with 1 layer the size of n but it requires a specific combinations of other parameters as well.@@@2017-06-24T05:45:16Z@@@hw5 student
Search and Score Lecture 14, Slide 20@@@Under "Usual Score Functions" it says "Validation/cross-validation". How doesvalidation/cross-validation act as a score function? Thanks@@@The score function needs to prevent overfitting (hence why we can't use training error, which would cause us to keep all features). Validation error does that. So it's an alternative to training error + L0.@@@2017-06-24T05:16:34Z@@@other student
Regression Weight Approach to Feature Selection Lecture 14, Slide 16@@@Why does the regression weight approach to feature selection allow tiny effects? If we have two collinear tiny effects then I understand how each of them could end up with a large weight in absolute value. But if we just have one tiny effect,why will it still be allowed?@@@My interpretation is the same as yours: that it allows tiny effects in the same way it allows non-effects, due to the craziness that can happen with collinearity.@@@2017-06-24T04:49:58Z@@@other student
Q3.1 Model 6@@@Is anyone else getting a train/valid loss of ~1.4? Not sure if I've implemented it correctly.@@@I've seen people with lower. Mine is in that regionwhich is why I'm thinking I did something wrong.@@@2017-06-24T02:40:00Z@@@hw5 student
Q3.1 Combining prediction@@@In #4 and #9, we need to combine previous predictions, is it as simple as (predA + predB)/2?@@@For #4 yes, for #9 you need to think about it carefully. It's just one line of code, and not a crazy line, but it requires understanding what the model is doing.@@@2017-06-24T00:27:49Z@@@hw5 student
A5 3.1@@@I'm a bit confused on 4) Avg of per-user and per-movie averages. Are we supposed to take the average of all each user's average rating and each movie's average rating..?@@@All i did was (movie + user)/2 still unsure about it@@@2017-06-24T00:17:41Z@@@hw5 student
A5 Q3.5@@@I'm a little stuck on this question and unfortunately did not get to Q3.5 during office hours. Basically, I'm not sure what the significance is of splitting on the three different classes. Considering this is the question being asked in the assignment, I'd like to know in general: - I'm not entirely sure what concepts are being linked together here. Judging by the wording of the problem, it seems to me that we have to combine the concept of multi-class regression and validation. I could be wrong about this though (in the sense that I don't recall regression with multiple classes just classification), and maybe this is why I got stuck in the first place. Any help is appreciated. Thanks.@@@I'm confused -- what do you mean by three different classes? There is no classification going on here, only regression. We are trying to predict the ratings which are numbers from 1 to 5 (well I guess they are integers but we are treating them as continuous values).@@@2017-06-23T23:42:22Z@@@hw5 student
Can a4 solutions be posted?@@@Thanks!@@@Done: https://github.ubc.ca/cpsc340-2017S/home/tree/master/solutions/a4@@@2017-06-23T20:08:46Z@@@hw4 student
L33-recommender systems@@@I am wondering whether these two W are the same or not? and what are the dimensions for these two Ws? Thanks!@@@They're different. $$w^T$$ is just regression weights, so it is $$1$$ x $$d$$ if we have $$d$$ features. $$w^T_j$$ is a column of $$W$$ ($$k$$ x $$m$$), so it is $$1$$ x $$k$$.@@@2017-06-23T18:34:33Z@@@other student
Linking Jupyter notebook in README file@@@How do I link to theJupyter notebook file? Do I just use the address in my browser? Thanks@@@Yeah, the same way you'd link to a .py file. The nice thing is that GitHub automatically gives in-browser static renderings of Jupyter notebooks.@@@2017-06-23T17:38:09Z@@@hw5 student
Do we need to know SVD?@@@SVD seems to be in the assignment, but it's in the bonus slides, do we need to know it for the final?@@@You need to know it exists and that it gives you PCA with orthogonal PCs ordered by importance. That's it.@@@2017-06-23T17:19:06Z@@@other student
Review session on Monday@@@Is it possible to change the review session time from 10am-12pm to a bit later? Some of us have final for CPSC313 until 11am.@@@It's too late to change the room. It's more complicated to reserve lecture rooms than regular rooms. However, I just added an office hour from 5-6pm on Monday.@@@2017-06-23T16:42:13Z@@@other student
Softmax classes@@@For softmax, do we encode the classes as {-1,1} or {0,1}@@@You just want to keep track of the classes that you model predicts. In the end, the softmax loss does something like this: $$f(w) = \sum_{i=1}^n \log \left( \sum_{c=1}^k \exp(w_c^T x_i) \right) - w_{y_i}^T x_i$$ So, you just want to understand what column of $$w$$ corresponds to what class. It's easier if you assign labels for your $$y_i$$ that go from $$[0, 1, 2 ...]$$ so that you know that the $$0^{th}$$ column of $$w$$ corresponds to label $$0$$ and so on.. But, I guess you could also have labels that are [-1, 1, -100, 300, 666] as long as you know which column of $$w$$ corresponds to what label..@@@2017-06-23T16:40:29Z@@@other student
Final exam material@@@How much of the final will be onpre- and post- midterm content?@@@He said in class that it'll be very slightly heavier on post midterm content, but in a pretty hand wavy motion so I think it'll be roughly equal.@@@2017-06-23T16:13:04Z@@@final_exam student
A5:Q3.3@@@For this question, should we also mention why we would use L2-regularization vs for example L1-regularization? Thanks@@@You don't have to.What I really want you to think about is why in (5) we don't really want/need any regularization at all.@@@2017-06-23T08:00:39Z@@@hw5 student
Matrix Factorization@@@Are we basically doing a PCA-esque thing TWICE (once for movie features ($$W$$), once for user features ($$Z$$)) and then combining them in our linear model?@@@No, not quite. The PCA-esque thing gives us $$U$$ and $$V$$ in the assignment's notation. The weights $$W$$ for the features $$Z$$ is a regular linear regression, not a PCA-esque thing. And furthermore the PCA-esque thing has a sort of symmetry in that we interpret$$U$$ and $$V$$ roughly in the same way whereas when we talked about PCA the $$W$$ and $$Z$$ had quite different interpretations. Does that make sense?@@@2017-06-23T06:46:21Z@@@other student
A5 q3: In model 9 why does the validation error increase@@@After a certain number of iterations, the validation error increases. How does this happen?@@@This is a classic symptom of overfitting. There's no guarantee that the validation error goes down when training error goes down. Because maybe the model starts getting too crazy.@@@2017-06-23T05:25:57Z@@@hw5 student
A5 Q3@@@On the line ratings = pd.read_csv(os.path.join("..", "data", "ml-latest-small", "ratings.csv")) I get the following error: FileNotFoundError: File b'../data/ml-latest-small/ratings.csv' does not exist And I don't see this file in the data folder myself. There is also no such file inhome/assignments on GitHubthat can be downloaded separately. So I'm confused where to get this ratings.csv file.@@@Edit: Nvm, I messed up the code trying to make it work through PyCharm. Found the link in the notebook after redownloading the code and using web-browser.@@@2017-06-23T02:39:12Z@@@hw5 student
method 7 has invalid error@@@I do not know why I have this error. I did not touch anything in method 7. I tried to restart and rerun all the cells but it still doesn't work. Could anyone help me? Thank you so much!@@@I changed the avg_n and avg_m during the implementation of method 4. I think this is why.@@@2017-06-22T23:58:29Z@@@hw5 student
A5: Q3 model 6@@@I am getting pretty good training loss~0.7 for model 6, but i got a HUGE (~10^24) validation loss... It doesn't seem normal, but I don't know what went wrong. Can someone shed some light on this?@@@never mind I just restarted thenotebook and it worked@@@2017-06-22T21:37:25Z@@@hw5 student
Will the final lecture slides be posted@@@@@@I just posted them. I just removed the slide about the prize winnersin case they didn't want to be on aslide.@@@2017-06-22T19:09:07Z@@@final_exam student
HW5 Q2 - MLPClassifier for image data@@@I got all ambitious for Q2 and downloaded about 400 images of cats and dogs and decided I was going to try to classify them, I regularized the image size and converted them all to greyscale. But I'm now realizing this may not be such a good idea. Without any consolation layers do I have any chance? I'm getting about 0.45 error and I think it's because about 45% is dogs and the model has learned just to classify cat. Should I give up on this? Thanks@@@@@@2017-06-22T18:10:54Z@@@hw5 student
Whats the motivation for Gradient Descent?@@@I was wondering if someone could explain the motivation behind gradient descent and stochastic gradient. I understand how they work, just not why we use them. If we know the gradient already, why not just solve for when$$grad f(x) = 0$$ ? I can't follow the motivation described in lecture 12. Thanks@@@Update: Added another answer [Answer 1] because we can't "just solve it". the equation is almost always unsolvable in closed form so we use iterative methods. least squares is a rare exception. [Answer 2] I don't think "Answer 1" is necessarily wrong but I was confused about this too so I'll try to add a bit of color. The tl;dr version is that both are optimization techniques but stochastic gradient descent is a more scalable solution because it uses a subset of the data to pick the "direction to the bottom." Here's how I think about it ( Mike, if this is wrong please let me know ). Consider wehave some data and we've chosen a model and a cost function. For now, let's saywe have a regression problem and are using a linear regression model in $$\mathbb{R}^2$$...Given this, we will want to estimate the weights (or parameters) of the model and we do this using gradient descent. In this case, we have a squared error cost function and we will use gradient descent combined with our cost function to figure out the slope and intercept.In short,we initialize the parameters to something, iterate with gradient descent, and we head to the global minimum (because we're in convex-land). The motivation for why we use Stochastic Gradient Descent is because it's really computationally expensive to compute the gradient because we have to sum over all the examples and then we have to do this over arbitrarily many features. Not good! So the idea istomake it such that we don't have to do these costly training-set long summations by just taking some number of training examples that are in some sort of random order.@@@2017-06-22T01:57:45Z@@@other student
Convolutional Neural Networks and Dimensionality Reduction@@@When we make our $$W$$ matrix represent a convolution applied to the elements of $$x_i$$, the outputted $$z_i$$ will have the same number of features as $$x_i$$, just altered after applying the convolution to each entry of $$x_i$$. Thus, convolutional neural networks do NOT do dimensionality reduction. Is this correct? (1) The "dimensionality reduction" then occurs later on if we do max pooling, which reduces the number of features. Or we could do dense layer (PCA layer) and reduce the dimensions in that way. Is this correct? (2)@@@It does not necessarily reduce the dimension nor increase the dimension. It depends on how you pad the image and how many convolution filters you apply. Let's say you have an image of 3 channels, 10 rows and 10 columns. You apply 32filters of size 3x5x5on top of the image,you end up with an image of 32 channels, 6 rows and 6 columns. Then the number of features you have as a result is: 32*6*6 which is larger than 3*10*10. However, you can reduce the dimensions by having large few filters. For example, if you had 2 filters of size 3x8x8 then applying that on the original image gets you an image with 2 channels, 3 rows and 3 columns, which has only 2*3*3 features. Max pooling usually reduces the dimensions significantly.@@@2017-06-21T22:51:14Z@@@other student
Q3.1@@@I'm a bit confused with why the Per User Average implementation is using avg_n = np.nanmean(Y,axis=1) with axis = 1? If I'm not mistaken Y is a (671 x 9066) or (N x M) or (user x movie) matrix. In a 2D matrix, is axis = 1 the column (M in this case)? Was this a mistake or am I understanding this wrong? thank you!@@@This takes the average across the columns. Each row in Y represents a user, so taking the average across columns (or axis 1) of a row represents theaverage rating of that user. Running the command, avg_n = np.nanmean(Y,axis=1) results in a 671 sized vector containing the average rating for each of the 671 users.@@@2017-06-21T21:55:34Z@@@hw5 student
A5: Q3@@@In model 9, why do we have: print("Per-movie average train loss: %f" % score( Y_pred_9 , Y)) print("Per-movie average valid loss: %f" % score( Y_pred_9 , Y_validate)) That is, why are the predictions the same for both the validation and training set?@@@Not sure if understanding your question fully... But, we use use this same setup for all the models. It's just that the Y_validate and Y have sensible entries at different positions. When we validate our model, we only look at the entries where there is a value and not a NaN. Hope this was getting at your question.@@@2017-06-21T20:48:03Z@@@hw5 student
L28 Questions@@@Hi, I had a few questions about L28. What does it mean by 'we can now think of z_ic as binary features we learn' -I understand that z_ic here refers to an element of z_i. Why is it a binary feature? Thanks :)@@@@288@@@2017-06-21T20:45:51Z@@@other student
Instructors Office hours@@@Hello Mike, I was wondering if you will be having office hours this week Thanks, Anny.@@@That's a reasonable request! I've just added onefor 2-3pm tomorrow.@@@2017-06-21T17:21:06Z@@@other student
A5:Q2@@@Are we allowed to use stuff fromsklearn.preprocessing to preprocess the data? Edit: Also, do we have to plot a graph for this question?@@@Absolutely, use whatever you want. You don't need to create avisualization, and indeed this is harder to do when $$d>1$$. But if there's a visualization that seems interesting, absolutely include it!@@@2017-06-21T06:41:22Z@@@hw5 student
A5: 3.1 - Missing one of the ten methods?@@@The following methods are listed in the Jupyter notebook as methods we will compare. 1. global average rating 2. user average rating 3. movie average rating 4. average of (2) and (3) above 5. linear regression on movie features, globally 6. linear regression on movie features, separately for each user 7. SVD (naively treating missing entries as 0) 8. SVD (treating missing entries as missing, via gradient descent) 9. Combining (8) with (6) 10. Same as (9) but trained using SGD instead of GD However, we're missing one of these (I believe it's #9). Instead, the section for method 9 seems to be method 10 from the list above. Is this how it's supposed to be? Thanks!@@@Whoops you'reright. It's (10) that I removed (the SGD). The rest are there.@@@2017-06-21T02:58:55Z@@@hw5 student
A5: Q1 What is good enough?@@@For this question, what is considered "good enough"? I can play with this all day and get what I perceive to be good, but I don't know what range would be considered acceptable? Thanks.@@@Question is marked on reasoning not coding. So it probably matters less how "good" an implementation is and more how well you can can explain why it is good. If you want something to compare it to, we've had the same dataset for a previous assignment - you could check you training and testing error against the performance you got there.@@@2017-06-21T00:44:03Z@@@hw5 student
A5: Q3 Data@@@I was just taking a look at Q3 and when I tried to runthe Jupyter notebook I receivedthe following error message: FileNotFoundError: File b'../data/ml-latest-small/ratings.csv' does not exist I went and looked in the data folder and sure enough, there is no subfolder called ml-latest-small containing ratings.csv. I also took a look inside the assignments folder on the Github page and didn't see a zip file for A5. Am I missing something? Where can I find the data?@@@Read the Jupyter file... clear instructions are provided.@@@2017-06-20T06:29:58Z@@@hw5 student
Logistic regression vs Logistic loss vs Logistic function@@@I have gone over the relevant lecture slides several times, but I am still confused about the following things. Here is what I know The above is taken from L18. Logisticregression attempts to minimize logistic loss Logistic loss looks like this (the green one) Logistic loss and logistic function are not the same thing Logistic function looks like this Here is what I amunsure about, hoping someone can verify my understanding and answer my questions (Please verify if I am correct) There are two ways to think about logistic regression One as the minimizer for the loss function One as thelogistic function And in either case the logistic regressionlooks the same? THanks so much!@@@2 ways: Minimizing the logistic loss. NOT as the logistic function itself. In the second way, you can think of assuming that the likelihood is a logistic likelihood, ie. $$P(y^i \mid x^i, w) = \dfrac{1}{1 + \exp(-y^iw^Tx^i)}$$. Minimizing the logistic loss or maximizing the log logistic likelihood yields logistic regression.@@@2017-06-20T03:43:43Z@@@other student
Final exam cheatsheet@@@Is the final exam cheatsheet also 1 page double sided?@@@Yes@@@2017-06-20T00:31:46Z@@@final_exam student
A5: Q1@@@How can we add a bias variable to sklearn's neural network?@@@The bias variable is already included in the sklearn's neural network model. You can access the values of the bias vector after training the` model `using the following statement: ` model . intercepts_ ` See the attributes section here: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier@@@2017-06-19T19:48:05Z@@@hw5 student
When will assignment grades be updated again?@@@As title says, when will the grades repo be updated again? I still don't have a grade for a3, and a5 is out already.@@@Just posted a3 grades (TAs finished grading last night). They are now working on a4. Sorry about the delay.@@@2017-06-19T07:08:01Z@@@hw3 hw4 other student
Lecture 28, Slide 5@@@What makes the$$z_{ic}$$ binary?@@@The number will be somewhere between $$0$$ and $$1$$. So we say it is "sort of" binary.@@@2017-06-19T04:01:41Z@@@other student
Lecture Slides Questions@@@I have saved questions over all the previous lecture slides: - L3 page 9: What is the "()" rule? - L4 bonus page 4: Is "degree" meaning depth? What is "VC"? -L15 page 12: Is "do better away from data" about test error? - L15bonus page 16: What is a universally consistent estimator, and where can I read more about it? - L16 page 3: What term is y_i*x_i? -L20 page 13: With the upper equation, are we missing only the lower polynomial terms from the lower equation? Are all polynomial interactions included in the upper equation?@@@() rule means you just predict the mode of the data without any splitting rule. Yes, I would assume degree here means depth. VC stands for Vapnis-Chervonenkis. VC-Dimension is one way of measuring the complexity/capacity of a class of functions. I don't know if I can explain all of it here, but I'm happy to talk to you about this in office hours :) Yes. Between the training examples, our prediction is dependent on the $$\sigma$$ that we choose for the RBF basis. So by adding a bias or polynomial basis, we can potentially do better than just relying on the RBF approximation at points far away from the test examples. [I'm not 100% sure about this one] Universally consistent means that as the number of training examples goes to infinity, the test error converges to the irreducible error for any underlying distribution of the data. An example is KNN, which is mentioned in the (bonus) slides? This is a result of the application of Stone's theorem. I'm not sure where to read more about it in popular ML literature. But I'm sure you can find out more in functional analysis (something like MATH 421) and advanced statistics textbooks. If you want the minimum of $$f(w)$$ to be at $$w = 0$$, then you need $$f'(0) = 0$$. Taking this derivative and setting it to 0 yields the term you're referring to. Yes, with the upper equation we are only missing the lower order terms. I'm not sure what you mean by "all polynomial interactions". The upper equation contains all polynomial terms of degree 4.@@@2017-06-18T11:19:54Z@@@other student
A5: Q3 (4)@@@The model (4) says its Average of per-user and per-movie averages In the given code is the following (which the 'Per-movie' part is the same for part (3)). print("Per-movie average train loss: %f" % score(Y_pred_4, Y)) print("Per-movie average valid loss: %f" % score(Y_pred_4, Y_validate)) Should the print be the following instead? print("Per-user per-movie average train loss: %f" % score(Y_pred_4, Y)) print("Per-user per-movie average valid loss: %f" % score(Y_pred_4, Y_validate))@@@Yes@@@2017-06-18T00:53:47Z@@@hw5 student
A4 README@@@Looks like README hyperlinks on github stopped working. Can this be fixed?@@@If you are talking about this type of hyperlinks "./figs/highway_000.png" then it works fine for me. Try to refresh it or check your punctuation.@@@2017-06-17T03:49:43Z@@@hw4 student
Determine the norm for latent factors@@@For PCA, I was wondering how do we determine the F in the equation?@@@The F denotes thefrobenius norm.@@@2017-06-16T23:02:57Z@@@other student
A4 Q5: Animal Data and Determining Good Graphs@@@Having trouble figuring out which method worked best. For example should bat be near gorillia or grizzly bear. Any chance are the features being used in the data known so that we can use that to determine the best fit? Also for Q5.2 what job are they trying to be best at?@@@I think even if we knew what features were included in the data set, it wouldn't necessarily help us (or hurt us) in teasing out what the latent factors might be. I don't think there's a method that works "best". Each method brings out different flavours in the data.@@@2017-06-16T18:31:49Z@@@hw4 student
A4 Q5@@@I was experimenting with different number of neighbours and found out that for NN=1 the plot is much more representative than for the other ones (I would say NN=1 is the best and NN=2 is the second best). But sincewe are asked to report NN=2 and NN=3 I want to clarify if I it is actually the case that NN=1 produces good representation and we are not asked to report it or I messed something up and my NN=1 and NN=2 are actually NN=2 and NN=3.@@@It's either you or me that's doing something wrong. You might be off by one? My 2 nearest neighbour looks pretty bad, while my 3 looks much better.@@@2017-06-16T05:04:22Z@@@hw4 student
Which Nearest Neighbour For A4 Q5.1@@@My scatterplots are different between choosing the decision rule for creating an edge between points that are mutually KNN or are one-wayKNN. Which implementation should I use? Should I look at how are they categorized to decide?@@@@255@@@2017-06-16T00:12:14Z@@@hw4 student
A4 Q4@@@In the RPCA reconstruction, sometimes I can get a even more clear black shade than the PCA reconstruction. Is this supposed to happen or I am doing something wrong?@@@It looks good to me..@@@2017-06-15T10:19:27Z@@@hw4 student
A4: Q3.2@@@Why do we standardize the features? In particular, why do we want the columns of X to have a variance of 1(I think in class we only discussed adjusting the mean). And if we standardize the features in main.py, there really is no point in subtracting the mean in the fit method, right?@@@We want to just center the mean around 0 in order to apply PCA to the data. PCA tries to "explain the variance in the data". Yeah you don't have to subtract the mean in fit if you do it already in main.@@@2017-06-15T06:43:53Z@@@hw4 student
A4@@@Are we allowed to calculate Frobenius norm using np.linalg.norm() function?@@@Sure, although it's really just np.sum(X**2)@@@2017-06-15T05:59:03Z@@@hw4 student
A4: Q3.2@@@"... but because of the binary features even a scatterplot matrix will show us almost nothing about the data." What do we mean by "binary features"? The features don't seem to be binary...@@@try print(X) somewhere in your code My command line didn't print all elements in the matrix X, but the bits it printed seems to be either 0 or 1 -suggesting that it actually may be binary@@@2017-06-15T05:25:21Z@@@hw4 student
Q3.2@@@In our code when we choose k, do we need to perform procedure described in L24 slide 10? Calculate error with k=0 and compare it with non-zero k error and choose k that gives smallest varienceRemaining (generated dynamically)? Or is k supposed to be hard-coded?@@@Since we want to display data with a scatter plot, I think we should reduce data to just 2 dimensions, thus,k should be picked accordingly.@@@2017-06-15T04:22:10Z@@@hw4 student
PCA alternating minimization@@@With the alternating minimization, we take turns 'playing with' W and Z to optimize the function. I was wondering though, why is Z a variable to begin with? Isn't Z the set of projections of all points of X onto the subspace W?@@@Yes, that is indeed what $$Z$$ represents. The key point here is that to compute the loss you need to know $$W$$ and $$Z$$. So you can't just leave $$Z$$ fixed and do gradient descent w.r.t. $$W$$, because each new $$W$$ value implies a new optimal $$Z$$ value. So you find the best $$Z$$ given $$W$$, then the best $$W$$ given $$Z$$, and so forth. There are variants where you solve the problem to completion each time, i.e. find the *best* $$W$$ given $$Z$$, and there are also variants where you just take a single gradient step: take a descent step in $$W$$ holding $$Z$$ fixed, then a descent step in $$Z$$ holding $$W$$ fixed, etc. You're intuition is right that the values in $$Z$$ is sort of parameters and sort of not parameters. As I said in class, from a ML point of view they aren't really parameters, for the reason you said. But if we forget the interpretation and just treat it as a straight up optimization problem, then we have a bunch of variables (the $$W$$ and $$Z$$ values) that we need to fiddle with in order to minimize the loss. Does that help?@@@2017-06-15T02:58:25Z@@@other student
Q3.1.1@@@To find the first principal component do I pick a random initialization for z and then do alternating minimization?@@@No, that sounds hard!If you subtract the means from both columns then you'llrealize the data set was intentionally picked so that the PCscan be seen by inspection. Nocalculation needed for 3.1.1.@@@2017-06-15T01:52:16Z@@@hw4 student
Why can we drop the constant in L2 regularization?@@@We have a constant in the NLL of Gaussian prior, but the constant is not included in L2 regularization. Why this is the case?@@@Suppose $$f(w)=w^2+(constant)$$. What is the $$w$$ that minimizes this function? $$0$$. Now, what happens if we change $$f(w)$$ so that $$f(w)=w^2$$ (we get rid of the constant). What is the $$w$$ that minimizes this function? Still $$0$$. So basically, the reason is because the constant doesn't change the minimizer.@@@2017-06-15T01:03:33Z@@@hw4 student
Principal components and z_i@@@I want to think of the reconstruction of an example as the weighted sum of the principal components where the weights are z_ik. I don't think this is correct because I wrote the matrix equation out and it appears we reconstruct each feature of x-hat separately as the dot-product of the j-th column of W (i.e. the j-th feature of all principal components) and z_i. So we use z_i repeatedly for all features of the reconstructed x_i. Is there an intuitive way to describe PCA in terms of our reconstruction and the learned W & Z? For example, with simple linear regression, we can say the prediction given some x_i is the weighted sum of the elements of x_i.@@@It is the weighted sum of principal components. It just happens to be that the principal components themselves are linear combinations of features, so each PC contributes (potentially, as it could have $$0$$ for a certain feature) to a training example's feature values.@@@2017-06-14T23:34:43Z@@@other student
A4: Q4 Log-sum-exp approximation@@@I noticed in the outline for this question that you recommend to use the "multi-quadric" approximation, however in my implementation I experimented with using the log-sum-exp approximation (as that is what I am familiar with) and my results look pretty good. I suppose my question is: do we need to use the multi-quadric approximation? Or is the log-sum-exp approximation fine for this implementation? Thanks!@@@I suppose that for the assignment, yes you should use the multi-quadratic just so everyone is answering a question of equal difficulty. However, it wouldn't surprise me to hear thata log-sum-exp or Huber approximation works fine. The pros and cons of these different approximations are way beyond the scope of CPSC 340 (and, in fact, the scope of my own knowledge!).@@@2017-06-14T22:48:56Z@@@hw4 student
A4:Q4@@@I'm trying to take the derivative of the multi-quadric approximation but I can't seem to get the numerator and denominator dimensions to match. Am I doing something wrong?@@@I guess so... I'd suggest taking the partial derivative with respect to one particular element of $$W$$ or $$Z$$ and then try to reassemble things back into a gradient afterwards.@@@2017-06-14T22:46:38Z@@@hw4 student
Lecture 24, Slide 28@@@Why is$$z_i = w^T_cx_i$$? Edit:Never mind, it's explained on slide 20.@@@@259 may help?@@@2017-06-14T21:13:39Z@@@other student
Q3.2 Does all count as a Bunch?@@@Question says to label a bunch of points on the scatter plot, not sure if that means there is some specific criteria for choosing what points to label or is it fine to just label all of the points?@@@All is fine.@@@2017-06-14T19:41:21Z@@@hw4 student
Robust PCA@@@Why does robust PCA use absolute error? Isn't the absolute function gonna make it unstable?@@@What does unstable mean? Anyways, I think we use absolute error because the principal components/factors (i.e., the 'means' or the 'bases') are less affected by outliers. If we don't care about the outliers so much, and care onlyabout getting the projection of the non-outlier-points onto the components/factors as close as possible, we want to use a measure of error that's more robust to outliers - i.e., absolute errors. Then the compression will still occur, but in such a way that it's more accurate with the non-outlier points. (Note: PCA is very sensitive to outliers if using euclidean distance/squared error). Absolute function is still convex, so while there's a lack of smoothness that allows us to simply take the derivative/gradient to immediately find minimization point via a closed-form answer, we can use gradient descent to eventually approach the minimization point.@@@2017-06-14T07:22:55Z@@@other student
choosing hyper-parameter k@@@In class we discussed how the elbow method could be used to determine the hyper-parameter k for k-means. I was wondering, could we construct a loss function that also takes in the input k such that we can optimize for k? Specifically, the issue seams to be that there's a tradeoff between: 1) Too high a k 2) Too high an error But what if we added some form of regularization on k? So something like: minimize: f(k,W) = (error from optimized clustering) + g(k) where g(k) is some function of k with positive first derivative such that increasing the value of k puts a penalty on the function f. Depending on the class of function g, the magnitude of penalty can be large - in increasing order of magnitude, for example, a log, polynomial, or exponential function.@@@This makes sense to me and a quick search turned up at least one result: https://www.cs.cmu.edu/~dpelleg/download/xmeans.pdf I'm really glad to see you thinking along these lines. The course is working!@@@2017-06-14T06:08:21Z@@@other student
A4: Q3.3@@@How to get variance explained? I just know that VarianceExplained = 1 - VarianceRemain@@@That's right, and variance remaining is a normalized version of the loss. See L24 slide 10 for the definition.@@@2017-06-14T03:14:21Z@@@hw4 student
Naive Bayes for any number of classes@@@In L22, slide 20 it discusses how we would do prediction for naive Bayes for any number of classes. I'm a bit confused on how k would come to play in this part. Are we able to disregard it because the probabilities were calculated in the training phase or are we checking the k probabilities for each of the d features?@@@The equation above, $$p(y=c|x_i) \propto \ldots $$, gives you the probability for a particular class $$c$$ where $$c\in\{1,2,\ldots,k\}$$. If you have $$k$$ classes then you have $$k$$ such probabilities and you take the largest one. Does that help?@@@2017-06-14T01:12:15Z@@@hw4 student
Principal component@@@For A4 3.1, what does it mean to give the first principal component? Are you looking for a vector? An equation of a line? a matrix?@@@It should be the first column of W. W is k by d matrix. Each row(1 by d) in W is a vector of mean for a cluster; Each column(k by 1) is a set of all means for feature'j'.@@@2017-06-14T01:11:37Z@@@hw4 student
A4: Q2.3@@@How can we implement the training phase in$$O(nd)$$ time instead of$$O(ndck)$$ time?@@@This is one of those unusual cases where the space complexity is more than the time complexity. It's rare since usually you at least need to traverse all the space you use. The space complexity of storing all the conditional probabilities is $$\mathcal{O}(dck)$$. This is the array p_xy in the code. The time complexity of computing all the conditional probabilities, using a straightforward implementation like the one in your assignment, is $$\mathcal{O}(ndck)$$. I agree there. However, to do this you really only need to pass through your data set, which has size $$\mathcal{O}(nd)$$. Basically, for each example and each feature, you look at the feature value itself. And you look at the corresponding y-value. And you use those to index directly into your big array. So you're not looping over the $$c$$ and $$k$$ dimensions, but rather using them to index directly in somewhere. Because at the end of the day you're just counting things and that shouldn't take longer than passing through your data set. As I said before, it's a bit unintuitive because your array has these factors of $$c$$ and $$k$$ in its size but you don't necessarily need to loop over those dimensions. It's sort of like indexing into an array or hash tabletakes constant time even though the size of the thing could be big, if that helps.@@@2017-06-13T21:13:07Z@@@hw4 student
Q1.3 typo?@@@Is "Gaussian likelihood where each datapoint where the variance is sigma 2 instead of 1" meant to say "Gaussian likelihood where the variance is sigma 2 instead of 1" (i.e. the overall sigma 2 ) ?@@@Yes, that's right. Or it couldsay, "We use a Gaussian likelihood for each datapoint where the variance is $$\sigma^2$$ instead of 1"@@@2017-06-13T18:46:11Z@@@hw4 student
A4 5.1@@@Regarding KNN, in this context am I correct in assuming that a point cannot be considered one of its own nearest neighbours? For example, if we use number of neighbours = 2 and DO allow a point to consider itself as one of its nearest neighbours, then it only has one choice of edge to get through the graph to the next point. Is this correct? Or should it be, as I'm thinking, ignored, so we would actually consider the 2nd and 3rd nearest neighbours when choosing our edge for number of neighbours = 2?@@@You're right, it's the latter. We look for $$k$$ neighbours other than itself. Or $$k+1$$ neighbours including itself.@@@2017-06-13T05:59:44Z@@@hw4 student
A4: Q2.2@@@Hi, I'm a bit confused on why the commented example in the code says # Compute the conditional probabilities i.e.          # p(x(i,j)=1 | y(i)==c) as p_xy         # p(x(i,j)=0 | y(i)==c) as p_xy Isn't it true that p(x(i,j)=1 | y(i)==c) is the same as p(x(j)=1 | y(i)==c) since at example i we're basically finding out p(feature == 1 | y(i)==c) and p(feature == 0 | y(i) == c) Thanks@@@No because x_i is a d by 1 vector, whereas x_ij is the jth feature of that vector.@@@2017-06-13T01:33:23Z@@@hw4 student
multinomial logistic regression@@@I am still not quite sure how is this related to multi-label regression? Why don't we sum k classes for multi-label regression?@@@Sorry, I don't understand the question. What do you mean by "sum k classes"? Also, multi-label is different from multi-class. Are you intentionally referring to multi-label as opposed to multi-class?@@@2017-06-12T18:57:46Z@@@other student
A4 Q1(5) What's the meaning of "very robust"@@@In Q1(5) "We use a (very robust) student t likelihood witha mean of ...." What's the meaning of very robust hear?@@@Very robust would mean that the model is very insusceptible to outliers affecting the fit of our resulting model.Hint, think about the shape of the loss function.@@@2017-06-12T05:05:33Z@@@hw4 student
Multinomial Logistic Regression@@@What does something like this mean? Does it mean that the first term is proportional to the second term? If so, why would that be the case? Thanks@@@It means that the two terms are directly proportional. $$\exp(w_c^Tx_i)$$ increases if and only if $$\exp(w_c^Tx_i)/ (\exp(w_c^Tx_i) + 1)$$ increases; and $$\exp(w_c^Tx_i)$$ decreasesif and only if$$\exp(w_c^Tx_i)/ (\exp(w_c^Tx_i) + 1)$$ decreases. This is true because $$exp(w_c^Tx_i)$$ is always positive and the denominator in the left hand side expression is always greater than 1.@@@2017-06-11T20:30:59Z@@@other student
Kernel trick with polynomials@@@Why does testing cost only O(ndt)? What about taking the inverse of$$K+\lambda{I}$$? Doesn't that cost$$O(n^3)$$?@@@You can do thatsolve at training time since $$K$$ doesn't involve the test examples. So this is done once during training, not repeatedly per test example. Hence the $$\mathcal{O}(n^3)$$ term in the training time complexity.@@@2017-06-11T18:33:33Z@@@other student
A2 Mechanics@@@For Assignment 2, was there a requirement to have a link to main.py in the README.md file? I didn't get full marks on "mechanics" and I'm trying to figure out why exactly. Thanks!@@@Yes, according to the homework instructions you should have a link to everything you want the markers to look at.@@@2017-06-11T16:57:58Z@@@hw2 student
A4 Q2.2 p_xy variable name@@@For Q2.2, I am confused that # Compute the conditional probabilities i.e.         # p(x(i,j)=1 | y(i)==c) as p_xy         # p(x(i,j)=0 | y(i)==c) as p_xy         p_xy = 0.5 * np.ones((D, C, 2))         ''' TODO for Q2.2: replace the above line with the proper code ''' both probabilities are using the same variable name p_xy. If I follow the example to code, then one of them is gonna overwrite. I was wondering how exactly are we supposed to express 2 probabilities using the same variable name? Thanks!@@@p_xy = 0.5 * np.ones((D, C, 2)) You can see that p_xy has three dimensions, you would use the third dimension to express each of the probabilities@@@2017-06-11T06:59:31Z@@@hw4 student
A4: Q2.2@@@I'm getting a very high validation error for this question. I think I implemented it correctly. Is it reasonable for the validation error to be so high? It seems unlikely given that for past assignments it has gone down upon "fixing", but I just wanted to make sure...@@@My result with naive Bayes is slightlybetter than the random forest. I guess you have a bug.@@@2017-06-11T03:17:26Z@@@hw4 student
A4: Q1.2@@@For Q1.2, do we use both Laplace prior and Laplace likelihood? Or do we just use Laplace likelihood and 'normal distribution' prior?@@@The latter. For each of the parts you keep the initial assumptions except for the change indicated by the question.@@@2017-06-10T22:34:53Z@@@hw4 student
Q2.2 - Singular Matrix Error@@@Hello all, For my Q2.2, I have randomly shuffled my data and am trying to apply the LeastSquaresRBF model to it. However, a Singular matrix error appears. I've checked the dimensions of my arrays and they seem to line up. Did anyone have the same problem as me for this question? Thanks in advance for any help.@@@Probably duplicated a column somehow? Just guessing...@@@2017-06-10T04:28:56Z@@@hw3 student
Q4.4 Code@@@Hello, My code seems complete to me, butI cant figure out where could I possibly have the issue, (I opened agithub issue for instructors) but meanwhile, did anyone ever get results like this? Exception: User and numerical derivatives differ: [ 0. 0. 0. 0. 0.] <-- theirs [ 78. -32.  10. -142.  86.] <---- mine If yes,where did you realize the issue was and how did u go about solving it?? Any tips or help would be greatly appreciated, thanks so much <3 p.s. The way I calculate the gradient, isI iterate through the rows and then columns of the matrix that stores output of the gradient, and then i calculate the derived formula for each one.@@@Think theres something weird going on with your function, since that's what they use to estimate your gradient. Not sure what.@@@2017-06-10T03:42:00Z@@@hw3 student
Q4.3 Massive Struggles with Taking the Derivative@@@Is it simply just a long process or am I missing some insight or trick? EDIT: To clarify I meant the "algreba" and calcuating the derivative being insanely long.@@@It took me a long while too... Both for 4.3 and 4.4. :S@@@2017-06-10T02:28:34Z@@@hw3 student
Markdown Matrices@@@Tryting to make matrices in my .md file. Anyone have a way to make nice looking matrices. Is there an html tag?@@@You can write math equations in .md the same way as you do in latex. The markdown file linked below contains code that results in nice looking matrices: md_test.md Once you download it, run in terminal the following command to compile the file into pdf: `pandocmd_test.md -o md_test.pdf` You should get a pdf that looks like this:@@@2017-06-10T01:43:55Z@@@other student
Q4.4 Implemented gradient almost identical to estimated gradient@@@Running the gradient checker, I always get gradients correct up to the third decimal place... Is this enough? I can't really figure out where I went wrong unless someone could look at the code@@@You just need to reshape it differently. Remember in python a d by 1 is not the same as a vector of length d.@@@2017-06-10T01:07:22Z@@@hw3 student
Midterm questions@@@Q1 (b) The question is asking "why do we need gradient descent for robust linear regression". However, since robust linear regression use absolute error, I thought the graph of the difference between predicted y and real y will look like a straight line. And we cannot take gradient at 0 because it is a straight line.... Could someone pls explain? (i) How do we know the function has local minima if the function is convex?@@@I think Q1(b) was maybe the most problematic on the whole exam. I don't mean it was a bad question, but that a huge number of students were surprised that their answer was not correct. In particular, most students wrote something about smoothness, which is not what the question is asking. The question is about why do we need gradient descent. The answer is that least squares is a very, very special case where we can (amazingly) write down the solution in "closed form" as $$w=(X^TX-\lambda I)^{-1}X^T y$$ (with L2-regularization). Think about it: for any data set, just plug it in and BAM! The best possible linear model in one line. Wow! Here's an analogy: from high school math, we're given the equation $$ax^2+bx+c=0$$ and we're given the quadratic formula $$x=\frac{-b\pm \sqrt{b^2-4ac}}{2a}$$. Unfortunately high school math teachers make this seem normal. But it is not normal! It is amazing that you can just write down the solution. For the other 99.999999% of equations you can't just do that. For example, how about $$ax^5+bx^4+cx^3+dx^2+ex+f=0$$. Nope, no closed form solution there. So, how to solve it? Well, some sort of iterative procedure! For example Newton's method. Or, sure, gradient descent. So, the thing I really want you to understand is that least squares, like a quadratic equation, is a special case. For most/all other cases, including robust regression, logistic regression, SVM, etc. you can't just write down the solution. So you need to use some sort of iterative method like gradient descent. That's a bit unpleasant becausewe have to deal with an initial guess, a step size, convergence issues, termination conditions, etc. So we'd typically (with some exceptions -- stay tuned) just use the closed form solution if you can. Which, again, is basically only possiblefor least squares. This whole thing has nothing to do with smoothness. For example, logistic regression is smooth, but we need gradient descent. Regarding Q1(i), this comes from the definition of convexity. We're not going into details in CPSC 340. But what I really want you to know is that if a function is convex then every local minimum is a global minimum (and there are no maxima). This doesn't necessarily mean that there is only one minimum. For example, ordinary least squares could have a bunch of solutions with the same loss (this is what we called on-uniqueness). But L2-regularized least squares has a unique solution. Both are convex. The answer, then: we care if something is convex because, if we find a place where $$\nabla f(w)=0$$, then we know there's no other $$w$$ that would have a better (lower) loss.@@@2017-06-09T21:42:25Z@@@midterm student
A3 3.2@@@Question 3.2 says that the findMinL1 function implements the non-differential part of the objective function. Does it implement this for both f and g?@@@Yes.@@@2017-06-09T21:07:10Z@@@hw3 student
Different answers for 3.3@@@My partner and I both implemented 3.3 and we got different answers, we checked the implementation and it was identical.It was all the same up until the last selected feature. What could the reason be? Is it because I'm on mac and my partner is on windows?@@@@@@2017-06-09T20:05:55Z@@@hw3 student
Incorrect Assignment Deadline for Assignment 2?@@@I noticed in the grade report for assignment 2 that the due that was "2017-02-05 23:59" instead of"2017-05-30 23:59" and got the "Late: Assignment not counted for credit message". My assignment was submitted 6 mins before the correct deadline (30th May 11:59pm). Can someone take a look into that please? (I'm assuming that the grades are calculated automatically from github grade reports). Thank you.@@@This is a mistake. I believe they will fix it soon.@@@2017-06-09T16:00:47Z@@@hw2 other student
A3 Q4.4 - Vectorizing the cost function and gradient@@@I'm trying to find a way to write the cost and gradient functions in vector notation. I'm having trouble doing this because while I found an expression for f(W), it involves W. This will create problems if I try to pass it to findMin.findMin unless I change that as well. Should I flatten W and try to obtain an equivalent vector notation form? Or would it be easier to just for-loop it@@@@@@2017-06-09T08:02:44Z@@@hw3 student
A3 Q4.1 Question about gradient of logistic regression@@@In order to find the min loss, I guess I need a funObj in my logLinearClassifier to use findMin. Since we have multi-class now the loss function I got is : $$\displaystyle f(w)=\sum_{i=1}^N \sum_{c=1}^C log(1+exp(-y_{ic}W_c^TX_i))$$ But I have trouble finding the gradient of this function, can someone give me some hints?Thanks!!@@@Never mind, I shouldn't calculate the loss function in the way I posted above. Each class should be treated independently.@@@2017-06-09T07:41:56Z@@@hw3 student
Why L2 does not do feature selection@@@Hi, I wonder why L2 does not do feature selection. Isn't having more non-zero term in w would also increases the regularization term and hence the model would be penalized? Thanks!@@@The penalization is bearable as long as w_i is small. More importantly, the minimum doesn't occur at w_i = 0. The L2 regularization, even for super large values of lambda, would only pull you asymptotically close to 0 but never quite reach it. If w_i isn't 0, then it remains selected.@@@2017-06-09T03:40:02Z@@@other student
A3 Q4.4@@@AfterI have derived the gradient of the loss function I am confused how I should minimize it to find the best W? We used findMin when w was a vector, but now W has more than one column, which is not acceptable by findMin. And I think we can't minimize with respect to each column of W separately, because that's the point to consider W as a whole.@@@Just reshape your W into a column vector w, worked for me.@@@2017-06-09T03:13:56Z@@@hw3 student
Wikipedia Cross-Validation/Monte-Carlo Cross-Validation@@@https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation This seems to differ from the slides which says k-fold randomizes splits each run. Whereas wikipedia says they are fixed and just a different one is used for validation each time?@@@They are fixed. But you can/should do a randomization step to begin with. Which is the same as picking the folds randomly. But once the $$k$$ folds are picked then you keep them througought the $$k$$ training/prediction phases.@@@2017-06-09T02:53:11Z@@@hw3 student
A3 Q3.3@@@I'm having difficulty figuring out how to compute the score once fitting selected_new. I know we have to compute the score using the function given in the pdf; however, I am having trouble figuring how to do so after fitting the data. The minimize function returns an array and a float (i.e. [0.01.. , 0.02...] and 340.12....) My intuition, after looking at findMin.py, is that the float that is returned is the value from our summation over our features (f) and the array is our w. Since we're using L0, would that mean we use np.count_nonzero(w), multiply that count by lambda and then add to f to receive our score? And if so, our best feature is that w array and our min loss is score? Or am I completely off?@@@Sounds about right. the findMin function returns the left-hand term of the loss, and you manually add in the L0 regularization term by counting the number of nonzero entries in $$w$$ (which should also just be the length of selected_new ).@@@2017-06-09T01:00:42Z@@@hw3 student
Getting errors of 1.0 running LogReg@@@When running python main.py -q 3  I get training and test errors of 1.000 which definitely should not happen. I thought  I might have messed with the logReg function so I redownloaded the files and tried again but got them same thing. I asked my tutorial TA about this and he changed "self.w = np.zeros(d)" to "self.w = np.random.randn(d)", which seemed to fix the problem.  Has anyone else  encountered this problem? And is it ok to alter the given logReg code?@@@Interesting that the zero initialization caused problems. Sure, I guess it's fine. But I'm surprised about the error. Curious to hear if anyone else encountered it...@@@2017-06-09T00:31:24Z@@@hw3 student
one vs all ; one vs one@@@I am not 100% sure what do those two terms mean@@@One-vs-all means that for each class you train a binary classifier that classifies that class vs. all others. Like cat vs. not cat, dog vs. not dog, etc. At prediction time you get a score from each of those classifiers and pick the highest score. One vs one means you learn a classifier between every pair of classes. This is more work because you need to train $$\mathcal{O}(k^2)$$ binary classifiers if you have $$k$$ classes.@@@2017-06-08T23:51:47Z@@@hw3 student
A3 Q4.1@@@The question asks to use logistic loss so I am trying to do it with already implemented logReg class. When I fit the model, however, I got an error caused by check_gradient. I wonder how the implemented and estimated gradients are the same when using logisticData dataset, but different when I am trying to fit one vs all.@@@logisticData is a data set. One vs. all is not a data set, it's a model. So I'm a bit confused by your question. Could you explain exactly what you did, and what the numerical gradient is, and what your gradient is?@@@2017-06-08T06:12:29Z@@@hw3 student
Multi-class Classification@@@I'm not sure if I missed anything about this in class but I'm confused by how the columns and rows in this diagram are named. Do k and c refer to the same thing? I am also confused as to why do we have d rows in the Y and W matrix? Thanks!@@@I have in my notes that Y actually has dimension NxC. N rows because there are N examples, and C represents the number of classes that the examples can be classified as. The W matrix has d-rows because w_1 is the weight vector for a single model that classifies whether an example is a cat or not a cat. Remember, most of the linear regression models we discussed have weight vector "w" of dimension "dx1" because you make a prediction by taking the dot product of w^T*x_i. If an example x_i has d features, then it follows that w^T should have d values or the dot product won't make sense.@@@2017-06-08T04:52:22Z@@@hw3 student
A3 Q2.3@@@Hi, For constructing Z distance matrix in RBF do we use training set to multiply with testing set or the other way around, because I am trying to figure out the dimension of Z. Also, would the dimension of w be changing depend on the size of testing data? Is the dimension of w is t*1? Thanks@@@The number of features becomes the number of training examples. So at test time your $$Z$$ matrix has $$n$$ columns, where $$n$$ is the number of training examples. No, the dimension of $$w$$ is independent of the size of the testing data. As always, it's equal the number of features, which is now $$n$$.@@@2017-06-08T03:28:52Z@@@hw3 student
Q2.3@@@Can we assume that our computer solves the following system of equations: Ax=b via the process of Gaussian elimination? If so, we can easily calculate the runtime of solving this system as a function of the matrix/vector sizes.@@@Yeah. This is also discussed in @219 and in the slides. You can assume the process of solving $$Ax=b$$ takes $$\mathcal{O}(d^3)$$ if $$A$$ is a $$d \times d$$ matrix.@@@2017-06-08T02:22:32Z@@@hw3 student
Function for 2.2@@@Are we allowed to use the sklearn.utils.shuffle function to shuffle our X and y for 2.2? Thanks!@@@Sure, that sounds reasonable.@@@2017-06-08T00:05:33Z@@@hw3 student
A3 Q2.3 Cost of solving a linear system of equations?@@@I'm trying to figure out Q2.3 and feel really confused about what is the cost of solving a linear system of equations. Can anyone explain a little bit about this? Thanks.@@@When we consider regression (with any sort of basis functions), we learn by identifying the vector "w" of weights that minimize some cost function. Long story short, this typically involves solving the normal equation at the very end to obtain "w". The normal equation is: X^T*X*w = X^T*y. We need to solve this equation in order to obtain the "w", and therefore the cost of solving this equation is part of the cost of fitting the model. You can break down the cost of this by seeing what you would need to do at each step. E.g. what does it cost to multiply X^T with X? What is the cost to multiply X^T with y? What is the cost to then solve Ax = b (a general matrix equation). If A is invertible, what is the cost? Hope this helps.@@@2017-06-07T23:55:55Z@@@hw3 student
A3 Q3.1@@@I am confused by how we calculate the gradient in the objective function method. My understanding was that the L2 regularization term was lamda/2 * ||w||**2 whose derivative islamda/2 * w. But when I implement this in my code I get the following exception: Exception: User and numerical derivatives differ: [ 31.69983779 67.21686918 0.81754183 39.16749733 35.19620532] [ 31.32280542 66.81556771 0.70251601 38.81689108 34.76745623] I don't quite understand why my gradient is off by such a small amount.@@@$$\lambda /2 ||w||^2$$. You forgot the squared, which will change your gradient.@@@2017-06-07T22:33:30Z@@@hw3 student
A3 Q2.1@@@Hi, I was wondering if for this part we have to do any changes in the code or is all that is required from us just an explanation? THank you!!!@@@Just an explanation.@@@2017-06-07T22:11:46Z@@@hw3 student
Can tutorial slides be posted please?@@@:)@@@Its under tutorial 5.@@@2017-06-07T21:50:46Z@@@other student
A3 Q3.2 "different gradient"@@@When I solve the problem, I commend out the check-gradient because I get different gradient by using findMin.findMinL1. And I still get the answer Is that normal that I have different gradient?@@@How do you know thatyou get the correct answer? Typically, if your gradient is incorrect then optimization wouldn't work too well. But there are some exceptions. For example, if you gradient is a scalar multiple of the true gradient then it won't matter much because the step size is chosen adaptively anyway. Maybe you can paste in the numerical gradient and your gradient, so we can see how they differ?@@@2017-06-07T18:38:03Z@@@hw4 student
A3 Q4.1 "replace one-vs-all model"@@@The Question asks "write a logLinearClassifier class that replaces the squared loss in the one-vs-al model with the logistic loss" Is that old model code be given?@@@Yes, it is in the leastSquaresClassifier class directly above.@@@2017-06-07T18:35:37Z@@@hw4 student
A3 Q3.3 TODO@@@TODO for Q3.3: Fit the model with 'i' added to the features, # then compute the score and update the minScore/minInd 1. What's the "score" and "minInd" here? Is that the smallest loss/validation error? I am a bit confused@@@Whoops, I changed the variables names in the code but forgot to change the comment. minScore refers tominLoss and minInd refers to bestFeature.@@@2017-06-07T18:31:28Z@@@hw4 student
Cross Validation@@@With say 5-fold cross validation, for each time we use a 1/5th of the X, y in our training, do we then test on the 4 other splits combined or each of them separately?@@@It's the other way around. You train on $$\frac{4}{5}^{th}$$ of the training data and test on the remaining fifth.@@@2017-06-07T15:28:07Z@@@hw3 student
A3 Q3 logReg@@@The Code: +class logReg:  +    # Logistic Regression  +    def __init__(self, verbose=1, maxEvals=100):  +        self.verbose = verbose  +        self.maxEvals = maxEvals  +        self.bias = True  +  +    def funObj(self, w, X, y):  +        yXw = y * X.dot(w)  +  +        # Calculate the function value  +        f = np.sum(np.log(1. + np.exp(-yXw)))  +  +        # Calculate the gradient value  +        res = - y / (1. + np.exp(yXw))  +        g = X.T.dot(res)  +  +        return f, g  +  +    def fit(self,X, y):  +        n, d = X.shape  +  +        # Initial guess  +        self.w = np.zeros(d)  +        utils.check_gradient(self, X, y)  +        (self.w, f) = findMin.findMin(self.funObj, self.w,  +                                      self.maxEvals, X, y, verbose=self.verbose)  +    def predict(self, X):  +        w = self.w  +        yhat = np.dot(X, w)  +  +        return np.sign(yhat) I have trouble understanding the way we call the function "funobj" in class "logReg": 1. When the function "funobj" was defined, it has 4 arguments:      def funObj( self, w, X, y) 2. But when we call"funObj" ,  there are not arguments at all:       findMin.findMin ( self.funObj, ... ) Can you please explain why it is possible ? What value of w, X ,y were passed into self.funObj when we call it ? Thanks !@@@In the line that you talk about, we are not calling $$\texttt{funObj}$$. We are just passing the function as an argument to another function, $$\texttt{findMin.findMin}$$. If you look at $$\texttt{findMin}$$, you'll see that it calls the function as $$\texttt{funObj(w, *args)}$$. The $$\texttt{*args}$$ takes care of the remaining arguments.@@@2017-06-07T05:25:50Z@@@hw3 student
A3: Q4.4 How to get (w_yi)^T in python?@@@Please help, I been stuck for a whileand not making any progress...@@@If w is a vector and y is an vector and i is an integer than something like w[y[i]] should work. I think in the code you'll actually have W as a matrix so you'll have to be a bit more careful to think about the dimensions of W and what you actually want, but that's the general idea. Also note that the utils.load_dataset function does y-=1 after loading the data here. In the raw data the labels go from 1 to 5 but we change them to go from 0 to 4 by subtracting 1. That way we can use the label (0,1,2,3,4) to directly index into a Python array. (In the pastCPSC 340used Matlab which uses 1-based indexing, hence the data set was crafted to be convenient for Matlab).@@@2017-06-07T04:42:45Z@@@hw3 student
A3 4.1 logistic loss@@@For logistic loss, do we need to add the L2-regularization term in the onjective function? Thanks!@@@You're not required to for the assignment. But you could try it out for fun, if you want to!@@@2017-06-07T03:57:59Z@@@hw3 student
A3 Q1.2 - Generate Figure@@@I have figured out how to add the bias term but I'm having trouble outputting the figure. I keep getting dimension errors that when I try to plot the model saying that my dimensions that are getting input to predict are notaligned. I tried subsetting the data to just includethe column that we care about and that didn't seem to help either. Does anyone have any suggestions?@@@If you can't extract an answer from Piazza, feel free to open an issue in your a3 repo, describe the problem, and tag @cpsc340-2017/staff. Then one of us will have a look at your specific code.@@@2017-06-07T03:24:07Z@@@hw3 student
python RuntimeWarning: overflow encountered in exp@@@How should I deal with this overflow warning? Is it okay to just ignore it?@@@It's probably OK. But can you provide more information, like which part of the assignment you're doing and when the overflow happens? Is it during a softmax calculation?@@@2017-06-07T02:27:48Z@@@hw3 student
A3 Q2.2, sklearn@@@The question says not to use a library like cross_val_score, but can we use sklearn.model_selection.kfold, as it only does the splitting of the data for us?@@@No@@@2017-06-07T00:36:51Z@@@hw3 student
A3 Q2.3 - Cost@@@When we are calculating the cost, should we be including what it takes to find the hyperparameters like the degree of the polynomial or the variance of Gaussian RBF? Thanks!@@@1. There is no polynomial involved. The linear model refers to the one with the original data. 2. Use a fixed variance for the Gaussian RBF.@@@2017-06-06T01:56:26Z@@@hw3 student
A3 3.3 query@@@Hey there, I'm a bit stuck on this question, would someone be able to explain to me what we are trying to do with the selected_new set? I'm a bit confused by fhe notion of "refitting" with only the features in that set.@@@selected_new contains a subset of the features. The minimize function, which you are given, takes in a subset of the features (such as selected_new ) and fits the model using only those features (by subsetting the data matrix X ). So you're supposed to fit the model using minimize andcompute theloss to seehow well the model performs with that particular subset of features. Then you find the best subset of features, and you see if you want to stick with it or terminate (based on the L0 norm criterion).@@@2017-06-05T15:27:40Z@@@hw3 student
Feature combinations that are greater than the individual features?@@@Just a thought, since we learn how to weight each individual feature is there a way to account for 'combos' of features to be weighted appropriately? For example, food could be both healthy or tasty but if it's both then it's more popular than just the sum of either.@@@Yes, definitely. We'll talk about this soon, in the context of the polynomial basis when $$d>1$$.@@@2017-06-05T03:18:19Z@@@other student
Will A5 and A6 both be due on June 23rd?@@@According to the scheduled both of those assignments are due on the Friday of that week, wondering if thats how it is or theres an error. Cheers@@@That was an error. a6 no longer exists. I just fixed it.@@@2017-06-04T21:55:11Z@@@hw5 hw6 other student
Midterm grading concern@@@If we have a concern about our midterm marking, should we wait until Tuesday to submit an issue on GitHub?@@@@197 text in bold@@@2017-06-02T20:51:35Z@@@midterm student
Adding a linear basis to matrix "X"@@@I have two questions from lecture 13: (1) To model data of an unknown function, we may consider varying the degree of polynomials used to estimate the data. However, the dimension of the weight vector remains "dx1" throughout. I don't understand how this is possible. Suppose we model with a 1 dimension feature vector with n examples, then our model for simple linear regression is y_i = w*x_i. However, if we wished to estimate the same data with quadratic basis, our model is now y_i = w_1*x_i + w_2 * (x_i)^2. So we went from one weigh to two weights. Unless the dimension is referring to each particular w_i, which is scalar for 1-feature data and (dx1) for d-feature data. So we'd actually have a "weight" matrix with p weights, each of dimension (nx1) (2) page 21: what is the effect of adding a linear basis to the modified matrix? With bias "y", we are translating the prediction vertically. Will the linear basis also impart an overall positive or negative trend much like in lecture 13, page 15 (bottom figure)?@@@First, a terminology thing: you should say "fit the data" or "estimate the model parameters" but not "estimate the data". The data are fixed and do not need to be estimated. (1) We define $$d$$ to be the number of features. So yes $$w$$ has size $$d\times 1$$ but $$d$$ changes as the degree of the polynomial changes. If we use a quadratic basis on a single original feature, then $$d=3$$ because the model is $$y=w_0+w_1x+w_2x^2$$. There is no $$w$$ matrix (until we get to PCA in a couple weeks). (2) Yes, exactly. In addition to the "local" regression we get from RBFs, we also get a global trend. This is particularly relevant far away from the data when the RBF functions tend to zero.@@@2017-06-02T06:26:44Z@@@other student
Why are KNN clustering sensitive to normalization?@@@I'm having a hard time visualizing why it would change anything if we multiplied everything by, say, 100. Could someone help me out?@@@Never mind, I got it. Consider multiple features where a feature is on the wrong scale, it'll affects the distances between points@@@2017-06-01T06:07:23Z@@@midterm student
A1, Q3.2@@@For Q3.2 of Assignment 1, I got that depth 8 minimizes the validation error when using the first half for training and depth 6 when using the second half for training. I checked a few random assignments from other people and they seem to have found the same. I was wondering if there's perhaps an error in the official solution (and hence the grading)? (in the official solution the answer is the other way around) Thanks!@@@We'll look into this after the midterm is graded and sorted out.@@@2017-06-01T03:53:07Z@@@hw1 student
K-means Convex@@@I still don't fully understand what convex means. I only know non-convex means the shape is weird looking. In what situation the K-means clusters is non-convex?@@@A set C is convex if $$\forall x, y \in C,\ \alpha \in [0,1].\ \alpha x + (1-\alpha) y \in C$$. This means that if you take any two points $$x$$ and $$y$$ in the set $$C$$ and draw a line segment between them, then all the points on that line segment are also in the set $$C$$. A function $$f : A \to B$$ is convex if $$A$$ is a convex set and $$\forall x, y \in A.\ \alpha \in [0,1].\ f(\alpha x + (1-\alpha)y) \leq \alpha f(x) + (1-\alpha) f(y)$$. This means that the function is, roughly speaking, "bowl shaped". The function always lies below the line segment between any two points on the function. K-means always produces convex clusters, it can never find non-convex clusters. Why? K-means partitions the space into half-spaces. In the figure above, the line between the blue and red region represents the points from which the blue mean and the red mean are equidistant, and similarly for all the other lines. These regions that we get from dividing the space by line segments like these are convex sets. So K-means will always find convex clusters.@@@2017-06-01T03:50:04Z@@@other student
2016W2midterm Q1(e)@@@I am not sure why OLS is not sensitive to normalization but OLS with L2 regularization is@@@This is a good question -- the answer is a bit subtle. I'll start by saying that L2-regularization isn't on our midterm. We start with OLS. Imagine a feature is multiplied by 1000 because you convert from kilometres to metres. Then, all the values in that column go up by a factor of 1000. The change to the solution is straightforward: the element of $$w$$ corresponding to that feature will be divided by 1000. So that way everything will stay the same. That's why OLS without regularization is not sensitive to scaling. The model you learn and the predictions you make would be unchanged. When you add regularization you have this $$||w||^2_2$$ term. This term is a sum of squares of the elements of $$w$$. If you multiplied or divided one of the elements of $$w$$ by some factor then its importance would change relative to the other elements of $$w$$. So, the solution would change. Imagine for example that originally $$w_1=1$$. The regularization term takes a penalty of $$1^2=1$$ for that weight. And then imagine you divide the feature by 1000 so that $$w_1$$ becomes 1000. Now the regularization term is taking a penalty of $$1000^2=1000000$$ for that weight. That's a huge penalty. With a huge gradient there: you could reduce the penalty a lot by reducing $$w_1$$ a bit, whereas that wasn't true originally. So the model would probably pick a smaller $$w$$ even if it took a hit in training error. Did that make sense? It's really an important point that's worth understanding even if it takes a few tries, so I'm happy to continue the conversation. I also suspect that the lecture on L1 regularization tomorrow may help developthis way of thinking.@@@2017-06-01T03:43:40Z@@@midterm student
Assignment 1 marks@@@For my marks on assignment 1, the feedback I got was "LATE: assignment not counted for credit". However, I uploaded all my files except the README by the deadline of 11:59pm and I uploaded the README after the deadline (oops). Does that still mean I don't get marks for the assignment?@@@I'm fine accepting it, but I'll have the TAs take off marks under the "mechanics" category for not following the instructions.@@@2017-06-01T03:38:08Z@@@hw1 student
Do the midterm cover the topics of L2 regularization and Naive Bayes?@@@I think we haven't learned it yet but I saw a lot of questions about this topic on sample midterms.@@@No. I've changed the order of the topics since last year (naive Bayes is coming later) and the midterm is also a little earlier in the term (so L2 regularization is out). See @107.@@@2017-06-01T02:51:42Z@@@midterm student
Will we be able to keep or get our cheatsheet back?@@@So that we could re-use for the final?@@@Yes@@@2017-05-31T23:57:53Z@@@midterm student
Decision tree splitting (A1: Q 2.4)@@@In A1, Q2.4 our tree stops splitting once both sides of a split have the same mode of the labels. What if instead we kept going? Isn't there a possibility that doing further splits down the road we could still increase the overall accuracy of the tree?@@@@@@2017-05-31T23:32:54Z@@@other student
Convexity@@@When we talk about convexity of the function g below, do we care about the function being convex w.r.t to w? or with respect to $$w^Tx_i-y_i$$? Does it matter?@@@In general, we care about its properties w.r.t. $$w$$.@@@2017-05-31T23:00:21Z@@@other student
DBScan clusters 'taking' points from others@@@In lecture it was said that in DBScan clusters couldn't 'take' points from other clusters, and that once something is defined as being a part of a cluster it stays that cluster. But in the demo on the outline it looks like they can take them from other groups. https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/ Is this a mistake in the demo implementation? Or is this distinction not very important. Also I'm wondering if this could be altered to make it possible for one point to be labeled as a part of multiple clusters (this is stated as missing feature KMeans), meaning the same result would be given regardless of the initialization (for the same hyperparameters).@@@Can you specify which of the demos in that link show this behaviour? I am not sure about your second question but some relevant keywords would be "soft assignments" or "soft clusters" or "overlapping clusters". Some quick Googling makes me think this is possible but not sure about the details. Maybe we could think more about this together some time after the midterm.@@@2017-05-31T22:50:39Z@@@midterm student
What does it mean when something is sensitive to outliers?@@@I was reading the slides about outlier detection and for graphical outlier detection one example was PCA but it said that it was sensitive to outliers. What does it mean when something that is used for graphical outlier detection is sensitive to outliers?@@@Outliers affect/change the model significantly.@@@2017-05-31T22:01:29Z@@@midterm student
2016W2midterm, Q4a@@@Is the reason why having x unique features gives us x-1 possible splits that there's no points in having a split such as "variable > maximum value of variable"?@@@It is because if you have x values and you want to make two groups (split them), one group must have at least 1 value and the other can have at most (x-1) values. So the possibilities are 1 and (x-1), 2 and (x-2), ..., (x-1) and 1. (x-1) possible splits in total! Any others wouldn't actually split the data, you'd be left with a group of 0 values and a group of x values, which is the same as a single group of x values.@@@2017-05-31T19:02:12Z@@@midterm student
Tutorial slides@@@Could all the tutorial slides be posted please? :) Thanks@@@I've passed this request along to the relevant TAs. Raunak: Slides for 18th May were posted that day itself. For 25th, I worked on the board: I just went through the code for A1, explaining how classes and inheritance works in Python, and I reviewed linear models and normal equations.@@@2017-05-31T18:44:10Z@@@other student
Question about Gradient descent (Slides)@@@I understand how gradient descent works but I feel confused about why we can't take the gradient at zero when we try minimize the absolute error?@@@The absolute value function is not differentiable at zero, so we can't take the gradient there.@@@2017-05-31T18:26:37Z@@@midterm student
Cheatsheet@@@Can we print the one page sheet of notes? or do we have to hand write it?@@@No limitations. You can generate it however you wish.@@@2017-05-31T16:37:15Z@@@midterm student
Midterm format@@@I have read through the midterm information provided on github and unfortunately I walked into class today as Mike was, I believe, talking about the midterm, but I may have missed if he explained the format. I was wondering what we should expect the midterm to look like in regards to code, written explanations, and mathematical manipulations. Going through the practice midterms, it seems if there is code, it would be writing psuedo code, and the rest is written explanations and calculations/mathematical manipulations. I just want to make sure I don't focus heavily on python code when the focus is on application and the practicality of the algorithms and topics we have covered.@@@He said the recent spring offering (when he taught the course) gives a flavour of what our exam'll be like@@@2017-05-31T06:01:33Z@@@midterm student
Q2: Quantize runtime@@@My quantize and dequantize functions seem to be really slow at higher values of k. Will this be a problem when it comes to grading?@@@Hard to say, depends on whether the code is actually correct I guess. You'll find out soon enough!@@@2017-05-31T05:02:46Z@@@hw1 student
RBFs bumps@@@I have a few questions about this graph: (1) What does it tell us that for Gaussian RBFs, no matter what's the w, it will only have one bump? (2) Comparing to Cubic basis, how does it tell us that Gaussian RBFs is better than Cubic basis? (2) How do we know RBFs is a universal approximators?@@@Here are my thoughts: (1)The single bump indicates that a specific gaussian RBF becomes important when you approach the training point that gives rise to that basis function. The further away you are from the other training points, the more likely it is that their basis functions would take on a small or possibly non-zero valueand have little/lesser effect on our predictions of the data. In a way, I suppose it has built-in distance scaling in that the further away you are from point xyz, the smallerits contribution to the overall prediction (subject to, of course, the weighting). (2) I don't think gaussian RBFs are necessarily better than cubic basis functions, although they are certainly more flexible. Which one you use depends on the context of the problem, the data, and what task you wish to perform. I'm a little iffy on (3). Here's what I think, but it kinda contradicts the slide which states gaussian RBF fits "locally". (3) RBFs are universal approximators because weights can be arbitrarily large or small such that its dot product with the basis functions result in a function which can approximate your data quite well. Furthermore, the basis functions take on values in "different ranges", and therefore allow you to model most of the space. Again, you can take arbitrary weights to help approximate more complex curvature. Note that this isn't always possible with other basis functions: e.g. cubic basis is terrible for approximating periodic functions (you'll want sinusoidal basis for those)@@@2017-05-31T04:51:33Z@@@other student
Q2: How to create array when only having np.argmin values?@@@Once we have an array with all the indices of what is needed from means, how do make an array with the same length that contains the actual content from means? Ex: if I had [1,2,3,1,2,2] and that translates to [[1,1,1],[2,2,2],[3,3,3],[1,1,1],[2,2,2],[2,2,2]], how do I arrive at the second array? I guess this is more of a general python question but I'm getting stuck on this for question 2. Thanks!@@@Your number of mean values is equal to your number of clusters, so you won't have the same amount of mean values as pixels. You need to find a way to associate your means with your cluster assignmentsbut do remember that the indexes of your pixels and your cluster assignments are equal, so perhaps a loop will help you make these associations. Hope that helps. Let me know if I misunderstood your question.@@@2017-05-31T04:26:44Z@@@hw2 student
Q2: How to print image@@@Are we supposed to use PIL or some other module to display the image? I noticed that the boilerplate we have doesn't import anything to do with an image library, so I was wondering what the correct way would be to display the image with the provided b values. Thanks.@@@It says "You can view the picture by using the plt.imshow function, or by saving it to a file." But this didn't work for me so I opted for the save option by using plt.imsave . Give that a try!@@@2017-05-31T03:37:03Z@@@hw2 student
A2: Q 3.3@@@Hi, For a2, q3.3 I was wondering what our final answers should look like? I have gotten to the step where A w = b, for some A and b Should my answer me something along the following lines 'At at minimizer where \nabla f(w) = 0, we have A w = b' or 'w = inverse of A * b' or something else completely?@@@$$Aw=b$$ sounds good.@@@2017-05-31T02:48:55Z@@@hw2 student
Decision Tree: parametric vs non-parametric@@@I've seen a few websites that categorize decision trees as being a non-parametric model. However, if I remember correctly we said that the decision tree is a parametric model? What was the reason for that again? Thanks@@@I think it depends on which algorithm you're using to grow the tree. We said that when we have more data for non-parametric models, the number of parameters grows with the data and the models get more complicated. Adecision tree can be non-parametric if you don't define a max-depth (and so it keeps on growing as you provide it with more data).@@@2017-05-31T02:16:15Z@@@other student
quantize@@@Is the quantize function actually supposed to return something? What does it mean to return the 'cluster assignments'?@@@"cluster assignments" means an integer label for each point indicating whichcluster it's in. This is basically what Kmeans.predict outputs.@@@2017-05-31T01:37:04Z@@@hw2 student
Can a non-parametric model overfit?@@@I was wondering if it's possible to have overfitting on a non-parametric model like KNN, and if so, how? I was thinking that with a parametric model like decision trees, we might overfit by making the tree fit the data too well (make it too deep) in attempt to get a lower training accuracy. But what about for a KNN?I don't see how this could ever have overfitting because I don't think training accuracy means anything in this context. If we assume the test and training data are i.i.d, could it ever overfit? Any help would be appreciated, thanks!@@@(Modified) I believe so. KNN model is easy to get overfitted as k decreases. Say if we choose k = 1 . Then the KNN would be the same as the original data set, which is overfitting for sure.@@@2017-05-31T00:29:57Z@@@other student
L2 norm notation@@@Could you clarify the notation for the l-1 l-2 l-0 l-infinitynorms? - Is ' ||x|| 2 ' just the l-2 norm (i.e. sqrt(x T x)) or is it the l-2 norm squared (i.e. sqrt(x T x) 2 )? What about ' ||x|| 2 2 ' ? - If a norm was written as "||x||" then is it assumed to be the l2-norm?@@@$$||x||^2$$ is the L2 norm of $$x$$, squared. Namely $$\sum_{i=1}^n x_i^2$$ or $$x^T x$$. $$||x||^2$$ is the same thing as $$||x||_2^2$$. If there's no subscript then we assume it's the L2-norm.@@@2017-05-30T22:52:33Z@@@other student
Q2 - Using a different image@@@How could I input a different image into main.py instead of the dog?@@@You can use skimage.io.imread : http://scikit-image.org/docs/dev/api/skimage.io.html#skimage.io.imread Basically, from skimage.io import imread X = imread(PATH_TO_FILE)@@@2017-05-30T22:23:31Z@@@hw2 student
A2:Q4.1@@@Apply this model to the data containing outliers, setting z = 1 for the first 400 data points and z = 0.1 for the last 100 data points I'm not sure how to plot this, wouldn't I have 2 different lines this way?@@@Your plot should look the same as the one provided in Q4 but the line will be different because the loss function was changed.@@@2017-05-30T22:19:00Z@@@hw2 student
Q4.2@@@I'm having a lot of trouble with this question. Much like 3.3.3 (where we can create a diagonal matrix Z), is there a 'convenient' method we can use?@@@For this question, I personally find it easier to just compute one partial derivative. Try to guess what the other ones look like and assemble them into a vector to form the gradient. To write your answer in matrix/vector notation, try to replace the sums with norms or dot products.@@@2017-05-30T20:04:11Z@@@hw2 student
Lecture 8 Graphical Outlier detection@@@Box plot: Only one variable at a time Scatter plot: Only two variables at a time What exactly do we mean by the number of variables? Why are they different for the box plot and scatter plot?@@@A scatter plot shows two features plotted against each other. A box plot just shows the distribution of one feature.@@@2017-05-30T19:09:05Z@@@other student
Gradient descent@@@In the notes it is mentioned that some issues with gradient descent have to do with scaling and units. Could some explain what exactly the issue was? Thanks@@@Can you please refer to the specific place in the notes? Thx.@@@2017-05-30T17:53:52Z@@@other student
Normal equations@@@Why does solving a dxd linear system cost O(d^3)?@@@You can solve a linear system using Gaussian elimination which has a runtime of $$O(d^3)$$ for a $$d \times d$$ system. Look here if you want a review of how we get that complexity. Basically, for each of the $$d$$ rows we perform row operations with $$O(d)$$ other rows, where each operation takes $$O(d)$$ time. So, overall we get $$O(d^3)$$.@@@2017-05-30T17:47:44Z@@@other student
Density based clustering@@@If I want to calculate the number of reachable points for point A, does point A itself count as a reachable point?@@@I don't think so. It should be points other than itself.@@@2017-05-30T17:34:11Z@@@other student
A2: Q4.2@@@I am lost about how we can simplify f(w) in this question. I was able to get rid of log for part of it, but I am still stuck with some log and exp in the expression. How can I re-write it in a clean matrix/vector form? Also, just want to double check -- is the question supposed to be $$f(w) {=} \sum_{i=1}^n  \log\left(\exp(w^Tx_i - y_i) + \exp(y_i - w^Tx_i)\right)$$? I tried to google "log-sum-exp approximation" and the top few results are all using$$\log \sum_{i=1}^n \exp(x_i)$$.@@@It's the log-sum-exp approximation of the max function, it's correct :) I would suggest taking the partial derivative of $$f(w)$$ with respect to $$w_1$$. You will need to use the chain rule. Look at what the result looks like and see if you can figure out what the other partial derivatives look like. Once you have this, then you can try to gradually convert this to matrix/vector notation. If you implemented this gradient naively, you would have 2 for loops in your code. Try to eliminate the loops one by one, replacing them with a matrix/vector multiplication / norm, etc.@@@2017-05-30T07:36:38Z@@@hw2 student
Collinearity@@@I understand that the solution is not unique if we have collinearity. But what do we mean when say "and yet, there are no local minima because of convexity" What's the point of that sentence? Thanks!@@@Consider these two functions: First function, $$f(x)=x^4-x^2-0.1x$$ Second function, $$f(x)=max(0,x^2-1)$$ If the solution to $$\nabla f(x)=0$$ is not unique, the worry is that you might be in situation 1. And that you've found the minimum on the left instead of the one on the right (which is better). But convexity means you're in situation 2: multiple places with$$\nabla f(x)=0$$ but all have the same function value (namely, the lowest possible). So all are considered equally good and you don't have to worry about which one you have (or at least the little optimizer inside your head doesn't worry; the little machine learner worries, hence tomorrow's lecture).@@@2017-05-30T05:39:19Z@@@other student
Q1.1 Are we trying to find the value of the given function or the minimized function?@@@@@@Value@@@2017-05-30T05:06:05Z@@@hw2 student
Q2@@@I was wondering if anyone could provide me some guidance with how to extract the features from img. I have a feeling it maybe has to do with np.reshape(), since it was part of the hint but I'm still having trouble with what to do with it. Any hints or advice will be much appreciated. Thank you! Edit: Nevermind, I think I've figured it out.@@@Instead of having an image represented as an array of shape(H, W, 3) you want to create the nxd matrix that we all know and love.@@@2017-05-30T04:48:13Z@@@hw2 student
KNN fit() runtime cost@@@What is the KNN fit runtime cost? Since it is just simply taking the data as model, would the cost just be O(n)? I can only find in the slide that the predict cost is O(nd)@@@I'd call it $$\mathcal{O}(1)$$ since you don't actually do anything. Prediction is $$\mathcal{O}(nd)$$ per test point, yep, at least the way we've implemented it.@@@2017-05-30T04:31:32Z@@@other student
ytest vs y_hat@@@From Xtest, it has a pair of predicted ytest, is this ytest the same thing as y_hat or y_predict? Or can someone clarify the difference@@@Test data is split into Xtest and ytest, where Xtest is the objects and their features and ytest is their corresponding labels. y_hat is the labels that your model predicts given Xtest. I think y_predict is the same as y_hat, but I'm not sure.@@@2017-05-30T03:42:24Z@@@other student
z in 4.1@@@Is the z parameter that the fit function in WeightedLeastSquare takes in a vector or a matrix?  I know how to solve the least square with the weighted values (z_i), but the solution I wrote down (as suggested on piazza) involves the matrix Z.@@@I believe it will be a matrix. What I did was initialize it as a diagonal matrix (500x500). Once you do that, you need to figure out what you want those diagonal elements to contain.@@@2017-05-30T01:35:38Z@@@hw2 student
A2: 4.2 matrices dimensions@@@I am confused with dimensions of function we are given $$\sum log(exp(w^{T} x_i - y_i) + exp(y_i - w^{T}x_i))$$. In particular,$$w^{T}x_i - y_i$$ because dimensions of$$w^{T}x_i$$ do not match$$w^{T}$$ is$$1\times d$$ and$$x_i$$ is$$1\times d$$ and$$y$$ is$$N \times 1$$. How is that formula valid?@@@yi is 1x1. w.T is 1xd and xi is dx1.  x_i is not 1xd, if I remember correctly - although it does represent the i-th row in the matrix X. check slide 23 on lecture 9!@@@2017-05-30T00:00:44Z@@@hw2 student
Q2@@@I'm very confused as to what Q2 is asking for. Can someone answer the following questions?  1) An image is a collection of pixels, where each pixel is one of RGB, and also has an x-coordinate and y-coordinate value (I'm sure those aren't the right terminologies but). Am I correct? 2) The feature here is the colour channels, according to the assignment. Does that mean all examples have only one feature we're examining, and that is the colour? 3) What is the 'output' or the 'result'? (I.e., in the context of our lectures, the y vector?) Is it an X-Y coordinate? I.e., y = [ (1,1) (10,34) (56,42) ... ]^T  I guess I'm very confused because I'm used to the notation we're familiar with, which is X and y, where each row in X is an example and each column in X is a feature, and each row entry in y is the 'result' corresponding to the row example in X.@@@1) We flatten the image so that the number of examples $$n$$ is the total number of pixels. 2) The number of features $$d$$ is 3, the number of colour channels. 3) This is an unsupervised (clustering) problem, so there is no $$y$$. You'll construct $$X$$ which will be of size (number of pixels) x 3. When you're done, each of your $$k$$ means will be a vector of length 3. In other words each of your means will be a colour. These will be your prototype colours -- the small number of colours that you've found to be the most useful. Then you'll reconstruct the images using only these $$k$$ colours instead of all possible colours.@@@2017-05-29T20:44:44Z@@@hw2 student
x_i, y_i, z_i@@@Is the following set of interpretations correct?:  x_i = the i-th column of matrix X y_i = the i-th entry of a d by 1 vector y z_i = the i-th entry of a d by 1 vector z, or the entry in row i, column j in the diagonal matrix Z@@@Corrections: $$x_i$$ is the $$i$$th row, aka the $$i$$th training example. $$y$$ is $$n\times 1$$ as it contains all the labels. $$z_i$$should be row $$i$$, column $$i$$ of $$Z$$ since the elements are on the diagonal. See also @139 @141@@@2017-05-29T20:36:43Z@@@hw2 student
Q3.3.3/4.1@@@Is taking the square root value of the Z and put in inside the bracket the right approach to start?@@@Try defining a new diagonal matrix Z with z_i long the diagonal. Edit: there's a better approach than taking the square root of Z.Remember that $$||x||^2=x^Tx$$.@@@2017-05-29T19:53:51Z@@@hw2 student
A2: Q3.3.3@@@I'm kind of stuck on #3 of 3.3. Confused about what z in this case is -- do we just assume it's a dx1 column vector, or does it have any special meaning? If it's just a dx1 vector, how do we approach this problem? I know the part that we talked about in class, but really confused what I can do with z. Any hint/help would be appreciated!@@@$$z$$ is an $$n \times 1$$ column vector. It's relevance shows up in Q4. You can use $$Z$$ to denote an $$n\times n$$ diagonal matrix that has the values $$z_i$$ along the diagonal -- this should help with the notation.@@@2017-05-29T08:20:10Z@@@hw2 student
A2 Q4.2 & 4.3@@@When deriving the objective, what is our goal at the end? Are we supposed to finding an equation or a single value? I've tried several times to derive the equationbut I get a single value every time and so I don't see how we can implement the gradient in 4.3. Any help will be greatly appreciated Thanks!@@@The gradient is a vector of the same size as $$w$$. Each partial derivative is a scalar (that depends on $$z,w,X$$ and $$y$$), and the gradient is a vector that holds all these partial derivatives.@@@2017-05-29T07:40:05Z@@@hw2 student
Assignment 2: Q3.2.2@@@In our standard notation w is a d-vector but here the second summation goes from j=1 to j=n (instead of d). Is that on purpose? Thanks@@@That's a typo. Thanks.@@@2017-05-29T03:41:02Z@@@hw2 student
A2 Q1.1@@@I'm having some trouble understanding the objective formula that's in the question. After printing out the means matrixthere are k rows which corresponds to the k clusterings. However, I am confused how thisrelates to $$w_{{c_i}j}$$. Also, are we supposed to be using the utils.euclidean_dist_squared function or are we implementing the summations ourselves.@@@$$w_{c_{i}}$$ is the cluster that corresponds to the cluster that $$x_i$$ belongs to. This is after you fit k means to the training data to obtain the cluster label for each training datum. the $$j$$ is the feature. So for each datum, you compute a squared distance to the corresponding dimension of the cluster. So if $$x_i$$ is [1,2,3,4,5] and its closest cluster mean is $$w_{c_{i}}$$, which is [1,1,1,1,1], then the distance is $$(1-1)^2 + (2 - 1)^2 + (3-1)^2 \dots$$ Yes you can use utils.euclidean_dist_squared@@@2017-05-29T00:46:23Z@@@hw2 student
A2: Q1.3@@@Are we suppose to get algorithm that classifies each outlier to the closest cluster (assuming each cluster in the center is classified correctly)? It seems like I get the same results for k-means and k-medians, which should not be corrected; according to the question the results should be different Edit: Accidentally used L1 for k-means error, using L2 indeed leads to not so great clustering, which actually raised another question for me. What's the reason to use L2 instead of L1 for k-means if L1 works better in the case with outliers?@@@When you say "use L2 instead of L1" do you mean as the error function which is then used to pick the best of 50 runs? The reason, then, is that the $$k$$-means clustering algorithm itself corresponds to minimizing the L2 loss (as described in Q1.1). So with L2 we're just continuing to use the loss we were already using implicitly. Doing what you suggested is a bit "inconsistent".Is that helpful?@@@2017-05-29T00:17:58Z@@@hw2 student
A2: Q3.3@@@"Write finding a minimizer w of the functions below as a system of linear equations (using vector/matrix notation and simplifying as much as possible). Note that all the functions below are convex so finding a w with f(w) = 0 is sufficient to minimize the functions (but show your work in getting to this point)." I was wondering: 1. Do we need to show how we foundthe minimizers? 2. What does the note mean? Do we need to show work of how we know functions are convex? Or we just need to show how we foundthe minimizers?@@@Sure, you should show a couple steps. The note means that if you set the gradient to zero you have found the global minimum. But you're not asked to show convexity. The note is particularly relevant in Q4.1 when you take the result from Q3.3.3 and assume it gives you a minimum even though you only set the gradient to zero.@@@2017-05-28T23:58:35Z@@@hw2 student
showing that a function is convex@@@If we want to show by norms, do we need to show that every norm is convex? This is L10 page 14.@@@I may have my answer by page 19 L10.@@@2017-05-28T23:25:33Z@@@other student
Assignment 2: Q2@@@If we print the pictures of the dog in Q2, do we have to label the axes? In general, do we have to label axes if everyone knows what's on the axis anyway? That is, how strict do we have to follow the rules here? Thanks :)@@@I don't think it matters that greatly, as long as the output of the dequantization hasthe same dimensions of the original image, it should be fine..@@@2017-05-28T23:11:06Z@@@hw2 student
Bonus Material on Midterm?@@@Does the midterm cover the topics in bonus material?@@@No@@@2017-05-28T21:53:15Z@@@midterm student
Getting RuntimeWarning: Mean of empty slice.   warnings.warn("Mean of empty slice.", RuntimeWarning)@@@I am getting a weird runtime warning for Q1.1 and 1.2. After doing some debugging i know it is coming from the fit function, it doesn't happen in the q1 example, but when I am looping the fit for question 1.1 at some point it starts throwing up that warning. Any idea into why this is happening? It seems to be running the code fine, but the perfectionist in me really wants to stop this warning.@@@I got two runtime warning as well: XXX\Anaconda3\lib\site-packages\numpy\core\_methods.py:59: RuntimeWarning: Mean of empty slice. warnings.warn("Mean of empty slice.", RuntimeWarning) XXX\Anaconda3\lib\site-packages\numpy\core\_methods.py:68: RuntimeWarning: invalid value encountered in true_divide ret, rcount, out=ret, casting='unsafe', subok=False) I wanna know how to avoid these and if we will lose marks because of these.@@@2017-05-28T21:14:46Z@@@hw2 student
A2: Question 1.3@@@Is the Kmedians algorithm guaranteed to converge if we use distances in the L1-norm?@@@I suspect yes, but I'm actually not certain. Let me know if you'd like me to dig into this and come up with a better answer. Or maybe one of the TAs knows.@@@2017-05-28T20:42:06Z@@@hw2 student
Q2@@@img = utils.load_dataset('dog')['I']/255 For img.shape I get(394, 640, 3). Could someone explain what those numbers mean? Is it number of rows, number of columns, and number of channels? Also, can we assume that the input image to the quantize function comes in the form of a 3D array? Thanks@@@The image is a 394 height by 640 width image (pixels). Each pixel has a value for red, green and blue (3 values. RGB), which combine to give the colour for that pixel.@@@2017-05-28T19:47:07Z@@@hw2 student
A2: Question 1.1 using utils.plot_2dclassifier@@@I'm confused as to why we are using utils.plot_2dclassifier. The code assumes the input "y" has only 2 class labels, but our model has 4 class labels because we set k = 4.@@@Is that a typo regarding the question number? Section 1.1, question 2 states to use the utils.plot_2d clustering function?@@@2017-05-28T19:20:59Z@@@hw2 student
Assignment 2:Q2@@@For Q2 are we supposed to make a new file "quantize_image.py", create a class within that file and the two functions quantize and dequantize? Or is there supposed to be a file"quantize_image.py" already prepared for us and we only have to add the functions?@@@Yes, you should create it.@@@2017-05-28T18:48:12Z@@@hw2 student
L9: 1/2 in Linear Least Square Formula@@@Hi, In L9 Sildes15, we have f(w)=1/2(sum of squared error).I wonder where is the 1/2 coming from. Thanks@@@It's anarbitrary scaling factor that doesn't change the solution. It just makes the math prettier by cancelled the factor of 2 that comes from differentiation.@@@2017-05-28T17:32:16Z@@@midterm student
L8 S11 Other Clustering Methods@@@Hi, S11 just briefly mention about the other clustering methods. I wonder how well we need to know them? Is there are learning outcome document for this course? Thanks@@@I don't have such a list, sorry. But, roughly speaking, my priorities from highest to lowest are: Topics covered in assignments Topics not in assignments but discussed extensively in lecture Topics just barely mentioned in lecture You can look at last term's exams to see what I mean -- the lessertopics just showed up in the multiple choice, nothing major on the exam.@@@2017-05-28T16:02:47Z@@@midterm student
AI: AMA textbook chapter titles@@@I think I have a different version of AI: AMA as the chapter 18 in my book ends at 18.7, but the readings listed go to 18.10. Could someone post the titles/descriptions of the textbook chapters so I can see if they are somewhere else in the version I have?? Mainly wondering about the topics covered in these chapters: AI: AMA 18.8, AI: AMA 18.10, AI:AMA 18.6 Thanks!!@@@@@@2017-05-28T15:45:43Z@@@other student unanswered
Slides: Pseudocode for DBSCAN@@@Why is it "less than minPoints"? Don't we need more than minPoints within the radius to be considered a core point?@@@Yep that's a mistake. Will fix now.@@@2017-05-28T08:02:47Z@@@other student
A2: Q1.2 Plot@@@Hand in a plot of the minimum error found across 50 random initializations, as you vary k from 1 to 10. I don't understand how plot should look like. I assume that x-axis is k levels (1...10) but what is y-axis? Or does it ask to make 50 lines of different color progressing through k=1 up to k=10?Readability becomes an issue in this case.@@@One line.The x-axis is the levels of $k$ from 1 to 10. Each of the 10 points on the y-axis is the minimum error across 50 initializations, using that value of $k$.@@@2017-05-28T07:43:24Z@@@hw2 student
A2: Q2@@@What color space is used to represent R G B values? Also, does converting current color space to some other one affectstraining result model (I think yes and at same time no)?@@@Yes, it probably would have an effect, but we're just sticking with RGB.@@@2017-05-28T07:43:14Z@@@hw2 student
How to open L12demo.ipynb?@@@I'm using Anaconda jupyter notebook. I have downloaded L12demo.ipynb (raw so it was appended .txt) so I have removed the .txt extension. When I try to open it with jutyper notebook it says: "L12demo.ipynb NotJSONError('Notebook does not appear to be JSON: \'{\\n "cells": [\\n {\\n "cell_type": "m...',)" Also, I cannot preview the file on github.@@@You're right, the file was corrupted. I just fixed it.@@@2017-05-28T04:14:19Z@@@other student
A2: Q1.1@@@I assume that when we search closest mean to Xi,j we use means generated in training phase, right? In other words. we need to find closest self.mean to Xi,j, isn't?@@@yep@@@2017-05-28T03:27:37Z@@@hw2 student
A2: Q1.1 kmeans Code clarification@@@Hi, I was wondering if someone could help clarify the code we were given for the fit/predict function in kmeans. What is this line doing? dist2[np.isnan(dist2)] = np.inf It looks like the inner function is making a boolean matrix of true if the element in dist2 is not a number? I don't really understand... I'm stilllearning python so any help would be much appreciated. Thanks@@@I ran this to check if it was making any change and nothing was printed before = dist2 dist2[np.isnan(dist2)] = np.inf if(before is not dist2): print(before) print(dist2) I think it's making any of the NaN values in the matrix equal to Inf so it doesn't lead to an error.@@@2017-05-28T02:26:32Z@@@hw2 student
Last git push for assignment 1 failed and our files were not submitted@@@Is there some way I can get the files for assignment 1 to a TA (alternate repo or just send it to them)? I have no idea why the files in my repo don't match with the ones I made for my last commit (git possibly failed to merge files correctly). I know Mike said at the start of the term that the repo locks automatically, but there has to be some other way to still get marked for the assignment. Edit: Also there was a latex files submitted with all the answers in it that did get into the repo, but it's obviously in the wrong format for submission and it wasn't in the README.md file.@@@This kind of question is better suited for a GitHub issue. Let's discuss there.@@@2017-05-28T00:59:16Z@@@hw1 student
A2: Q1.4 DBSCAN cluster@@@For this question, do we need to be able to include the outliers into the 4,3,2,1 clusters? And is there explanation needed? Or do we just need to provide the combination of eps and minPts that we used?@@@The question talks about the clusters not the outliers so I think they are irrelevant, and I put in my images of the graphs just to show that what I got when I ran it was what they asked for. And it doesn't ask for an explanation.@@@2017-05-27T22:32:13Z@@@hw2 student
A2: Q1.2 Elbow Method@@@What is the elbow method for choosing k? In the question it says 'looking at the above plot and visually trying to choose the k that makes the sharpest elbow ( the biggest change in slope )' What is slope that it's talking about?@@@The slope of the line in the plot of error vs. k.@@@2017-05-27T18:52:32Z@@@hw2 student
uploading on git@@@how does one upload the folder from your computer to github?  I kept going to my folder on my commandline terminal and typing 'git add .' 'git commit -m "blah" ' and 'git push' but it keeps saying not a git repository, even though it's a folder from a repository I downloaded?  (I missed the deadline for the assignment because of this, oh well..)@@@I'm assuming that you downloaded the file as a zip and not via cloning the repository viagit? If that is the case, then that is your prolem (I think you can link it back somehow but it would be very tedious). Highly recommend to use git clone@@@2017-05-27T07:12:40Z@@@other student
Clarification on euclidean_dist_squared@@@Hi, I'm not entirely sure how the function outputs.Does it compare each X object with each X_test, or is it the other way round? Do we sort the output matrix by columnthen (since it is a N x T matrix) to get the closest " X's " toeach X_test object?@@@edit: solved (turns out problem I was having was in another part of the code)@@@2017-05-27T02:58:16Z@@@hw1 student
A1 4.1 argsort does not give the expected result@@@I have an array named dist (the first few elements of the array) After I did indices = np.argsort(dist), I got: This seems to be wrong since the second element of my array is 0, so I should get 0 in my argsorted array, but i got 395. I can't figure out where is the problem. Can someone help me with this?@@@The elements in returned from argsort don't quite mean what you described above, I believe. Let's say I had the following dist = [4, 5, 2, 1] Argsort would return something like [ 3, 2, 0, 1] So... dist[3] -> gives you the smallest element dist[2] -> gives you the second smallest dist[0] -> gives you the third smallest dist[1] -> gives you the biggest@@@2017-05-27T01:38:59Z@@@hw1 student
No module named sklearn Error@@@Whenever I run python main.py -q 2 on my computer(MAC), I always got an ImportError: No module named sklearn.@@@As suggested in https://github.ubc.ca/cpsc340-2017S/home/blob/master/course_info.md I would download Anaconda. Not too sure how far you're into the assignment, but if you're using python 2 I found some problems using python 2 (on my mac) in question 5. I would advise you to download python 3 as well, if you haven't already. If you've done the above already, I'm not too sure what went wrong :(@@@2017-05-27T01:38:22Z@@@hw1 student
Q5.2@@@How do I create a list of RandomTree objects? I am trying to do it this way models[i] = RandomTree(max_depth=np.inf) But the error appears: TypeError: float() argument must be a string or a number, not 'RandomTree' Should I initialize list using something else instead of np.zeros?@@@As @77 suggested a python list would do. You can create an empty list something like #create a list list_of_trees = [] #add to the list list_of_trees.append(< your random tree >)@@@2017-05-27T01:32:22Z@@@hw1 student
Python Not Responding when I run PlotClassifier with KNN@@@Is anyone else having or have solved this problem?@@@It's working fine for me, can you paste your code so I can see what you are trying to do? Is there potentially a loop that isn't finishing in you KNN predict function?? Edit: I fixed it, it was the fact that I was using len(Xtest) instead of Xtest.shape[1]@@@2017-05-26T23:49:24Z@@@hw2 student
A1 Q4.2.6 Fitted Data For citiesBig2@@@I am assuming that citiesBig2 is to have its own model independent of any used on the citiesBig1 Data. Is that correct?@@@Yes you should make a model, fit it to the citiedBig2 training data, and then find the test error and training error as was done with the other models.@@@2017-05-26T23:29:52Z@@@hw1 student
A1 Q3.2 need some clarification@@@In Q3.2, it says that "How could use more of our data to estimate the depth more reliably?" I'm having some trouble understanding the line "use more of our data". My understanding is that since we are having n/2 examples for training set and n/2 examples for validation set, the training set and validation size is the same. If we want to use more of our data to estimate the depth, we need to increase the size of training set and decrease the size of validation set. Say change training set size to 2n/3 and validation set size to n/3. This is what I'm thinking, but I'm not sure if this is what this line is really asking for. Can someone confirm me, or tell me what this line is asking if my understanding is wrong?@@@@@@2017-05-26T22:01:17Z@@@hw1 student unanswered
A1 Q4.1.1@@@When I try to run the command "run main.py -q 4.1" after completing the predict function, it just stops here and shows nothing. Can someone give me a hint why it happened?@@@I don't what you've done but 4.1 part in main has nothing in it to start with. Maybe you have to add some code it?@@@2017-05-26T20:58:25Z@@@hw1 student
Requesting Partners@@@For A2 we have to re-request our partners and this has to be done before the assignment is released;am I understanding that correctly?@@@Yep!@@@2017-05-26T19:47:23Z@@@hw2 student
A1 Q5.4@@@Hi, I wonder how we are suppose to compare the speed and accuracy as there are many ways we can get the speed and accurary?For example : are we comparing both of the training error and testing error ? What should the depth be? Is it like before where we plot the graph from depth=1 to 15? And the question also suggest we can play around with the parameters in the RandomForestClassifier. So, I am confused how to discuss the result : do we need to explain why the randomForestClassifier is faster/slower than our implementation? Do we need to plot any graphs? Thanks,@@@Would assume we just use time.time() before and after running the predict functions and then to get accuracy, just use the method we have been using throughout the assignment. Instructors, correct me if I am wrong, but I believe we just need to show the different timings and then the training and testing errors for both algorithms.@@@2017-05-26T18:26:21Z@@@hw1 student
Q4.2.6 "Try Out your function on the dataset CitiesBig2"@@@I have no idea which function this is refering to? The only function I wrote in 4 is the predict for KNN and that will not run using CitiesBig2.@@@I think it refers to prefers to using the CNN.fit and and predict function to find the training error and test error for citiesBig2.@@@2017-05-26T15:08:06Z@@@hw1 student
Why do we add incorrect instead of correct examples to the subset of CNN@@@@@@You're trying to store a small subset of the original training examples. So intuitively, if you can correctly predict the label of the current example given the subset you have, then there is no point adding it to your subset. You'll just increase the size of your subset by 1 even though you could have correctly predicted the label without adding it. We add the incorrect ones because we want to be able to make a correct prediction which we can't given the current subset we have. So we add it to our subset to try to correct this mistake. Does that make sense?@@@2017-05-26T09:08:56Z@@@hw1 student
A1 Q5.2 None after fitting random tree@@@I created RandomTree object and fit(X, y). When I print the result of the fitting, I got "None" for all myrandom trees. I am quite lost on why I got None. Any help is appreciated.@@@are you doing something like this? print(model.fit(X,y)) because fit function does not return anything if you want to see if object is created or not, I'd rather try print(model)@@@2017-05-26T06:43:37Z@@@hw1 student
A1 Q4.2.1 Timing the@@@Hi, For questions 4,2,1, do we just need to time the time for fit() and predict() for CNN and KNN? What should the k be? Can we just put in the any k we want, e.g. k=3? Thanks!@@@"The point of this algorithm is to be faster than KNN. Try running the condensed NN on the citiesBig1 dataset and report how long it takes to make a prediction . What about if you try to use KNN for this dataset?" I took this to mean that timing was only for the predict function. I personally used k = 1 because the rest of the questions operate on k = 1, but I suppose you can list the assumption of which k value you plan on using.@@@2017-05-26T05:15:05Z@@@hw1 student
Runtime of KNN (Lecture slides)@@@Why is the runtime of KNN for one test example O(nd)? Don't we also have to sort by distance which would take n*log(n), so we would get O(nd+n*log(n))?@@@There lots of other ways to get the k nearest neighbours other than sorting. You can use a selection algorithm to get the k nearest neighbours in linear time $$O(n)$$. If you're interested, then you can also look up kd-trees, and approximate nearest neighbour search and locality sensitive hashing (much more advanced material).@@@2017-05-26T05:14:09Z@@@other student
Assignment 1 Question 3.1@@@Are we supposed to insert the plot in the report, or just the description of the plot is okay or are we supposed to check in the generated plot, leaving it in the figs folder and link to it in the README? Thank you!!@@@I'd say just put the plot in the report in case the TA wants to see it and not have to go back to your figures folder or to the link. And it might be graded anyway so you should put it in either way.@@@2017-05-26T04:39:26Z@@@hw1 student
A1: Q4.1.5@@@"If you didnt have an explicit test set, how would you choose k?" Is this assuming we test on a validation set instead or are we just testing on the training set itself?@@@Yes validation, the question is where do you get the validation set from? On the slides it describes where to get the validation set from.@@@2017-05-26T04:18:10Z@@@hw1 student
A1 Q4.2.2 CNN training error@@@Why should the training error for CNN be greater than 0? The pseudo code for the algorithm says that it runs until all of the points in the training set are categorized correctly by the set used to fit the model. Based on that it shouldn't get any of the training data incorrect.@@@After you fit the model using the algorithm described, try predicting the labels on for the original training data again. There is a good chance that you will get a non-zero error. EDIT: You're supposed to explain why this happens in question 4.2.4! So I can't answer why this happens. You should read the algorithm more carefully. At the end of the algorithm, we have a model - the condensed dataset. Focus on whether this condensed dataset can have perfect training accuracy. This is why I also wrote after in bold before. It's key that you consider this training accuracy after you've built your model and not how you predict on training examples while you're still building the model, which is the phase that the given pseudocode is describing. I hope this makes things clearer!@@@2017-05-26T03:30:45Z@@@hw1 student
Q4.1.1 Predict Single Point Or Whole DataSet@@@Was wondering if the KNN predict a single input or the entire test data in one call?@@@The entire dataset.@@@2017-05-26T03:16:23Z@@@hw1 student
A1 Q2.3 - Finding out the split variables/values@@@I'm confused as to how I find out what variables the fit function split on when it was run, and what values it split on. I need this information to do q2.3 where it asks to code simplified predict. I tried looking through the Variable Explorer on Spyder but its a bit hard to interpret it. Is it just a matter of inserting a few print statements in the Decision Tree code to see the tree?@@@Yeah try printing out the values that are used by the included method to split, then write a series of if else statements based on these splits to tell which category the value represents. Also you can plot the way that the included version splits it and look at where the subsections are.@@@2017-05-26T02:46:51Z@@@hw1 student
A1 4.2.3 - plotting@@@The function for plotting is hardcoded to plot colours based on the y vector having a 1 or 2, however the y vector in big cities has 0 or 1, so the scatter points will always be blue. ..Do you want us to fix the y vector so it plots correctly? Update: I just added 1 to the training and test vectors and the plot looks correct.@@@Yeah this was mentioned earlier, you have to add a 1 to all the data points.@@@2017-05-26T01:39:25Z@@@hw1 student
A1 Q4.2.5@@@For this question, I'm confused on how n will be involved in finding the cost of the function. We're comparing the t test exampleswith the s subset examples and that would not involve n . Thanks!@@@Yeah I don't think it should include n at all. If you think about the case where all data points in n are the same category, then s should be of size 1 and the runtime for a predict would be the exact same if n was 1 as it would if n was 1 million.@@@2017-05-26T01:17:49Z@@@hw1 student
4.1 KNN Implementation@@@For code implementation of predict function in KNN algorithm do we need to use matrices only for storing data orother data structures allowed as well? I implemented KNN but it works faster on citiesBig1 & citiesBig2 dataset for different k (tested only 1,2,3,4,5). I assume my implementation is correct and finds correct neighbors.@@@I don't see why you need to store data in the predict function. The predict function is used to return thelabel of the test points. Aren't you storing all the data you need in the fit and __init__ functions ?@@@2017-05-26T01:05:21Z@@@hw1 student
A1: Q4.1.3@@@are we plotting utils.plotClassifier(cnnOBJECT, X_test, y_pred) or utils.plotClassifier(cnnOBJECT, X, y) or both?@@@Can't go wrong with just putting both in and labeling them.@@@2017-05-26T00:51:27Z@@@hw1 student
3.1 what should the plot look like?@@@I'm having really wierd shape of my plot. I'm wondering do we need to have a smooth line for the plot? Or we can just plot some dots instead of a line@@@Looks pretty similar to mine. Only difference is I plot dots instead of line....@@@2017-05-25T07:08:54Z@@@hw1 student
A1: Q4.1.3@@@"Hand in the plot generated by utils.plotClassifier on the citiesSmall dataset for k = 1." Just wondering if we should predict on X (training dataset), then plot, or predict on X_test (test dataset), then plot?@@@This is supposed to help you visualize the labelsthat the training set will give you if you used 1 nearest neighbor. So, fit on training set, then plot what the labels of the training set are. Cheers.@@@2017-05-25T00:33:12Z@@@hw1 student
A1 Q2.3 Tree depth wrong@@@Confused as the assignment says a tree of depth 2 is being produced, but I am only getting a tree of depth 1?@@@hmm.. Did you pass in the parameter into max_depth for the desired depth?@@@2017-05-25T00:24:40Z@@@hw1 student
A1: Q4.1@@@How do we measure the test error for knn? how do we know if the predict value is correct?@@@There is a XTest and YTest inside the citiesSmall dataset... Predict using your trained data, compare the prediction with the test set labels. Cheers.@@@2017-05-25T00:21:49Z@@@hw1 student
Q2@@@Hi everyone, I am confused about what is "an np.percentile-based splitting rule and the threshold-based splits". What are their differences. Thanks!@@@@48@@@2017-05-24T21:28:47Z@@@hw1 student
Command for Update the Cloned Git Repository@@@How do I update my cloned git repository, so it will be the same as the remote again, using mac terminal command? " git pull "only update my local repository if there is any new commit in the remote, it does not detect any local changes I made. What if there is no new commit in the remote, and I made several unwanted changes or mistakes in my local repository, and want the cloned repository to be the same as the current remote git repository again? Thanks !@@@I think command to discard local changes is git checkout .@@@2017-05-24T21:09:23Z@@@other student
Question on Q3.2@@@For Q3.2, I assume we are using the dataset "citiesSmall" but since we are asked to cut it in half, is it actually to cut ytest, Xtest, y, and X arrays in half? I tried to do something like this: dataset = utils.load_dataset("citiesSmall") row_count = len(dataset) trainSet, validSet = dataset[:row_count*1/2], dataset[row_count*1/2] But it shows an error: File "main.py", line 205, in <module>     trainSet, validSet = dataset[:row_count*1/2], dataset[row_count*1/2] TypeError: unhashable type This is the dataset:@@@The type of the dataset variable is a dict . You need to cut the individual arrays in half. Also, you don't need to split the test data as we're assuming it doesn't exist.@@@2017-05-24T20:07:36Z@@@hw1 student
A1 Q5.2 - RandomForest Class@@@I'm a bit confused as to what we are supposed to include inthe RandomForest class and how to structure it. From what I understand, we are supposed to fit num_trees number of random trees and then take the mode of those predictions. However, I'm not too sure how we should store the fits of each of these trees in a way that we can use the predict function on them after. Should we be using an array in the random_forest class to store the fits or is there a better way to do this? Any help will be appreciated!@@@Yep, the easiest is to make a Python list and have it contain the RandomTree objects. Then you can iterate through the list and call fit on each RandomTree.@@@2017-05-24T20:03:55Z@@@hw1 student
Q4.2.3@@@"Hand in the plot generated by utils.plotClassier on the citiesBig1 dataset for k = 1." Are we supposed to do that for the original (X,y) in the citiesBig1 datasetor for the condensed version of (X,y)? Thanks@@@The classification surface should come from the trained CNN model. As for the points themselves, it's up to you whether you want to plot all of them or the subset.@@@2017-05-24T17:53:32Z@@@hw1 student
Clarification on function of code@@@Hey, I'm learning Python for the first time and am curious as to the way this code is working. splitIndex1 = X[:,j] > value splitIndex0 = X[:,j] <= value Is this setting splitIndex1 to X[:,j] if X[:,j] > value?@@@No, X[:,j] > value returns a boolean array. The boolean array has value True at the indices whereX[:,j]>value is True, and False otherwise. Here is a small script to test this: a = np.array([3,2,4,5]) indices = a >= 4 print(indices) This should print the following boolean array [False, False, True, True] since only 4 and 5 are larger or equal to 4@@@2017-05-24T17:01:43Z@@@hw2 student
A1 Q5.2 & 5.3 - evaluate model@@@Are we supposed to use the given evaluate_model function to find the Training Error and Testing error or do we write our own version for the Random Forest implementation? Thanks!@@@You're free to use it or modify it as you see fit. It's there for your convenience.@@@2017-05-24T17:01:24Z@@@hw1 student
A1 Q5.2 Deal with Tie@@@Hi, I wonder what we should do if there are even number of random tree in the forest and the result from these tree are tie. e.g: there 4 random trees. 2 random trees vote for class A, another 2 vote for class B. Do we just randomly pick one class? Thanks,@@@Sure. In practice people often use this information as a measure of uncertainty. For example if you have a 15-0 vote then you could say the algorithm is more certain than if it's 8-7. (There's also more uncertainty information to be extracted if you don't split the tree all the way down to its leaves.) The scikit-learn RandomForestClassifier has this functionality build-in with the predict_proba function:http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba@@@2017-05-24T15:57:53Z@@@hw1 student
Q4.2 class CNN(KNN)@@@Why does the class look like "CNN(KNN):" instead of just "CNN:"? Thanks!@@@I think it's related to class inheritance where CNN is a subclass of KNN? I would do a quick google search to confirm this :)@@@2017-05-24T06:50:33Z@@@hw1 student
Validation error@@@I'm having trouble understanding the following statement from the lecture slides: "Validation error is only an unbiased approximation if you use it once." Lets say we use a validation set to decide on the depth of our decision tree. What does it mean to "use it once"?@@@I think this is related to the issue that if you have some large number of models, like a million, and you test all of them on the same validation set then one will likely outperform the others even though it isn't a better model for real world data. So if you use the same validation set multiple times it is biasing a model that preforms well on that set specifically, or in other words you are overfitting to the data of the validation set.@@@2017-05-24T05:46:01Z@@@other student
Q2.4@@@Do we have to explain why the errors of the sklearn's DecisionTreeClassier behave the way they do? That is, do we have to understand the concept of Information Gain?@@@You don't need to know it to the level of being able to implement it yourself. But you should understand the basic idea so that you can reason about it. I believe @Jacob Chen went over it in tutorials yesterday.@@@2017-05-24T05:14:30Z@@@hw1 student
A1 Q2.3 - If I set the tree depth to be a high number shouldn't I expect the error to be zero?@@@I'm struggling to make sure I'm on the right track with Q2. For 2.3 I would assume that by setting the tree depth to be a high number (10000) the error would be zero, for me it's not, does this mean I've got some other issues, or am I on the right track here? Thanks@@@You may find Q2.4 sheds some light on what you're observing in Q2.3.@@@2017-05-24T04:30:03Z@@@hw1 student
A1: Q 4.1 y value of neighbours?@@@So For 4.1 implementing predict function. I now have k nearest neighbours in a sorted list. But I am not sure how toget y value of those neighbours Any hints?@@@The trick is that you need to sort the y-values at the same time, otherwise you lose track of which y-values correspond to which x-values. You can get around this with np.argsort , which is why the assignment suggests this function.@@@2017-05-24T03:51:12Z@@@hw1 student
Explaining python code@@@Could someone explain what "%.3f" and "%" in the following line of code means? print("Testing error: %.3f" % te_error) Thanks!@@@Someone correct me if I"m wrong but %.3f should represent the format of a float with 3 decimals and % te_error is essentially being placed in where %.3f is. Ex) if te_error is 4.12345 the output of the print would be... Testing error: 4.123@@@2017-05-24T03:22:26Z@@@other student
'No module'@@@I keep running into the problem of "ImportError: No module named 'numpy'  " whenever I run main.py on my Mac terminal.  I've done it with the following two commands: python main.py -q 1.1 python3 main.py -q 1.1  I've also downloaded Anaconda, but I still run into this problem. How do I get around it? Do I have to do something with Anaconda?  I asked my TA today, but I couldn't quite do what he suggested ("downloading PyCharm, then configuring to Python3"), and since I had class right after I couldn't stick around to complete the whole process.@@@If you ask about could not find module for random forest, just comment it out. You won't need this until the last problem. Darn ,my bad, I didn't noticednumpy. Juts ignore my answer. Apologies.@@@2017-05-24T01:53:45Z@@@hw1 student
Problem loading citiesBig1@@@I used "dataset = utils.load_dataset("citiesBig1")", and it showed something like this : I tried the alternative set as well but still doesn't work@@@Hmm.. it looks like you're using Python 2.7. You tried to Python 2 version of the data from https://github.ubc.ca/cpsc340-2017S/home/tree/master/assignments ?@@@2017-05-23T21:44:20Z@@@hw1 student
A1: Q1.1 clarification@@@Does the question ask to compute statistics for each region separately or just once for the whole dataset? I'm assuming the former, but the note aboututils.mode() confused me because it can compute mode only for the 2D dataset, not for 1D array (which I need if I treat each region separately).@@@Just once for thewhole data set.@@@2017-05-23T17:06:52Z@@@hw1 student
A1: Q4.1 Have Test Set?@@@As KNN needs to have test set to predict, I wonder if we have test set for this question. If not, do we just split the dataset into training set and test set? How do we decide the number of rows for training set? Edit: Okay, I got it, it is in the dataset as well. Thanks,@@@The data set should come with a test set.Unless it's somehow missing?@@@2017-05-23T13:15:28Z@@@hw1 student
A1: Q2.2 clarification@@@I know how to find the mode for continuous data, but I'm not entirely sure if we are supposed to write our own implementation of finding the mode for continuous data or if we are expected to use a method from Numpy.@@@The features are continuous, but the outputs are still discrete (categorical labels). When you find the mode it's for the labels, not the features.@@@2017-05-23T00:54:16Z@@@hw1 student
Logistics@@@(1) Are there office hours beyond during lecture breaks and after lecture? (2) Will we be provided with official assignment solutions? Thanks!@@@Yes, there are tons of office hours! See https://github.ubc.ca/cpsc340-2017S/home/blob/master/course_info.md And, yes, you'll be provided with assignment solutions. I'll try to get those posted shortly for a0.@@@2017-05-22T20:34:01Z@@@other student
A1: Q3.1 - which model to graph?@@@Are we supposed to make the graph of training error & testing error for our decision tree implementation or sklearn's implementation? Or both? Thanks.@@@Using sklearn's implementation is fine.@@@2017-05-22T19:11:35Z@@@hw1 student
Greedy Recursive splitting and training error@@@If we use the greedy recursive splitting algorithm to fit a decision tree and we allow depth to be arbitrarily large, do we always end up with a tree that will give us 0% training error?@@@Spend some time looking at question 2.4 on assignment 1. That may help.@@@2017-05-22T18:22:43Z@@@other student
A1 Figures by utils.plotClassifier@@@Do we need to label plot title, axis, etc... for the plot generated byutils.plotClassifier?@@@The questions just say to hand in the plot generated, so I don't think so.@@@2017-05-22T16:11:51Z@@@hw1 student
citiesBig1 and citiesBig2@@@I printed the values of y for citiesBig1 and citiesBig2 and it seems like they are 0 and 1 for citiesBig1 and all 1s for citiesBig2. Is it supposed to be this way? I thought the y values were supposed to be either 1 or 2.@@@Yep. The actual values of the labels shouldn't matter, but you can have the y values be 1 and 2 if you want by just adding 1 to the array.@@@2017-05-22T07:26:59Z@@@hw1 student
How to pass by reference in python?@@@I want to have a function that can alter a variable in the caller, but I can't find a way to do so. Something like this: def outer_fun():     outer_var = 2     def inner_fun(outer_var):         outer_var=3         return     inner_fun(outer_var)     return outer_var print(outer_fun()) This print 2 because it is passed by assignment, but I want it to return 3. Please help.@@@It would probably be better to use classes and separate the two (and set outer_var as a field), but you can also fix this by using the nonlocal keyword and removing outer_var from the argument to inner_fun(). def outer_fun():     outer_var = 2     def inner_fun():         nonlocal outer_var         outer_var = 3         return     inner_fun()     return outer_var print(outer_fun())@@@2017-05-22T07:14:41Z@@@other student
A1: Q4.2.2@@@Report the training and testing errors for condensed NN, as well as the number of variables in the subset, on the citiesBig1 dataset with k=1 What does the subset refer to in this question? The number of variables in X?@@@The amount of datapoints in the new dataset that was built using CNN.@@@2017-05-22T06:33:36Z@@@hw1 student
A1: Q2.3@@@Does the simple_decision.py need to be compilable? Or does it just need to be python psudo code? And since it is specific to the dataset 'citiesSmall', can we assume that we know what the split decision threshold value?@@@1. It should be actual code. 2. Yes, use the specific splits learned by the decision tree on this data set.@@@2017-05-21T22:27:15Z@@@hw1 student
MATLIBPLOT error@@@When I try tocreate a plot with matplotlib,I run into issues. import stuff if __name__ == "__main__":     X = np.array([1, 2, 3, 4, 5, 6, 7])     y = np.array([1, 2, 3, 4, 5, 6, 7])          plt.plot(X, y, label="myFirstGraph")     plt.xlabel("X")     plt.ylabel("Y")     plt.legend()     fname = os.path.join("..", "figs", "test")     plt.savefig(fname) I get the following error message: This application failed to start because it could not find or load the Qt platform plugin "windows" in "".  Reinstalling the application may fix this problem. Anyone else encountering this problem? If so, how did you fix it? I tried "conda install qt", but it says I don't have enough permission to do that (even though I'm opening Anaconda Prompt as admin). I tried creating a virual environment and installing it there, but that doesn't work as it complains that the following folder doesn't exist .../Anaconda3/env/myVirtualEnvironment/env/myVirtualEnvironment (not a typo). Tried un-checking the "Read-only" properties on the Anaconda3 folder, but Windows prompty changes it back to read-only.@@@Does this help? https://stackoverflow.com/questions/41994485/error-could-not-find-or-load-the-qt-platform-plugin-windows-while-using-matplo@@@2017-05-21T17:46:41Z@@@hw1 student
Python Syntax@@@I tried searching online, but I don't get what this piece of code does: y[X[:,d] == value]. As far as I can tell, X[:,d]==value converts a Nx1 array into True/False values. y is also Nx1, with values 1 or 2. What happens when you combine the two together? Does it spit back an array whose values come from y only if the row of X[:,d]==value is true? I tried that in the Python intepreter, and it didn't seem to do that.@@@Yes, that'scorrect. It's sometimes called boolean indexing. Not sure why it didn't seem that way when you tried it.@@@2017-05-21T04:05:16Z@@@other student
A1: Q2 - Unpickling error?@@@When I run python main.py -q 2 I get the following error: _pickle.UnpicklingError: the STRING opcode argument must be quoted From the following line of code (line 125) in utils.py: data = pickle.load(f, encoding='latin1') I'm usingPython 3.6.0 with Anaconda 4.3.1 (64-bit) on Windows 8.1. Anyone else having a similar issue? I've looked around online and the closest thing to a definitive answer I could get was that the pickled file may not be compatible with different versions of Python- has anyone gotten it to work for Python 3.6?@@@Did you forgot to add quotations around any of the .pkl files when you called utils.load_dataset("someDataSet")?@@@2017-05-21T02:43:04Z@@@hw1 student
Depth convention@@@I've noticed that in this course, a complete binary tree with 7 nodes would be considered one with depth 3 (was looking at a1, question 2.5). In past courses, it was taught that this would be depth 2. Are we to use the convention that counts nodes (as it seems) from root to bottom, or edges (as I was taught previously). I ask because I answered the question in a0 using the edges convention. =( EDIT: nevermind, I misunderstood.@@@I thinkboth conventions are sane. I don't think it's a big deal either way, as long as we're clear and consistent.@@@2017-05-21T02:16:33Z@@@hw0 student
1.1@@@"Your main.py loads this data for you and stores it in the 2-D numpy array X , where each row corresponds to a week and each column corresponds to a different region. The names of the columns are loaded into the variable names ." It sounds like this is already done for us. But I can't seem to find X in main.py and I can't find "names" either@@@That is done in utils.py so we have to call that function in main.py@@@2017-05-21T01:44:19Z@@@hw1 student
1.1@@@I'm having a difficult time understanding how to go about calculating the various summary statistics. I've tried using the numpy library but have noticed that those methods require arrays as input, and the load_dataset method provided returns a dictionary. I've tried to follow the mold of the other questions, but it doesn't seem to work... any guidance would be very nice. I've spent too much time on the first question already...@@@You can Index into the first item of the dictionary which is an array of the data you need to use the numpy operations on, if I am not mistaken.@@@2017-05-21T00:33:35Z@@@hw1 student
Importing utils (name conflict)@@@I have the built-in Python module "utils" installed on my computer, so when I run "import utils", it imports the built-in module and not the one that we're supposed to use for the assignment.   Does anyone know how to direct Python into importing the correct module? Thanks in advance.@@@Not sure but seems like something you could Google around for. Or, something that would definitely work is renaming your utils.py to something else and making the corresponding changes tothe import statements in the code.@@@2017-05-20T23:06:07Z@@@hw1 student
Executing main on Spyder@@@I'm new to Python and I'm using an IDE called Spyder. I'm trying to understand how I would run something like "python main.py -q 1.1" on the IPython console? I know how to do it through my Terminal but is there a way to do it using Spyder? Thanks :)@@@I use Spyder as well. To enter arguments for command line, go to Run -> Configure, check the box for command line options, then enter "-q 1.1" in the box to the right. To run the other questions, just edit the box.  Or, you can directly type "runfile('../main.py', args='-q 1.1')" into the python console within Spyder. Make sure you enter the correct file path.@@@2017-05-20T22:52:46Z@@@hw1 student
Question 1.1@@@EDIT: If one wishes to use the data and column names, one can do as suggested in the following post: @41 I'm getting an error when I try to run "main -q 1.1". It says that the random forest module doesn't exist. So I commented it out. But then I get another error when I try to print out the elements of the variable "names". It says that variable doesn't exist either. Do we have to define these ourselves?@@@EDIT: Hm, I stand corrected... not sure.@@@2017-05-20T22:34:58Z@@@hw1 student
How to submit my hw?@@@1. I do not use terminal to upload my hw0. 2. I just upload my hw by the button "upload files" in github? Is that ok that my hw showing that way in below?@@@To answer question 2... Pretty sure the homework instruction states that all deliverables should be in their proper folders. .py files in the code folder. Written/report answers in the doc folder.@@@2017-05-20T04:43:40Z@@@hw1 student
a0 - 4.2 Running times of code@@@Hi, I'm just wondering if we need to explain how we got the Big-O. Does it suffice to state just the Big-O without explanation? Thank you! Edit: Wrote down the reasons for good measure. Edit 2: Thanks for the input. I guess I'm just being paranoid haha.@@@The question just says to state it, so I don't think we need any explanation. Just my take.@@@2017-05-20T01:59:13Z@@@hw0 student
Linking in readme.md@@@Is there anything I can read to do this?@@@Nevermind. So it's basically something like [name of hyperlink](directory/name_of_file.file_extension)@@@2017-05-20T00:04:12Z@@@hw0 student
Learning with Non-Numerical Data?@@@Hello! So far in class we've covered how to predict labels based on continuous features such as location and quantity, but I'm now curious about how we would predict labels from non-continuous data, such as a chatbot that is trained on the textbook (the training data) and gives the correct chapter that I should brush up on (the label) when I ask it a question (the test data). The Markov chain is a nice technique, but the bag of words approach that it takes ignores the grammatical aspects of language, and therefore sometimes spouts nonsense words. Is there a way to somehow represent grammar rules (non-continuous data like that) in a numerical manner, or is there a completely different approach in training on non-continuous data? Thanks for your help!@@@This is quite a big question! There are lots of different ways of handing non-numerical data. It seems like you're interested in text in particular, which has its own specific approaches that aren't necessarily the same as other non-numerical data types. This field is calledNatural Language Processing (NLP), in case you want a starting point for searches. There are definitely methods that do *not* ignore the order of words (unlike bag of words). Something gaining popularity these days are recurrent neural networks (RNNs). For a fun blog post, seehttp://karpathy.github.io/2015/05/21/rnn-effectiveness/@@@2017-05-19T23:36:23Z@@@other student
Q 3.3@@@Hi, I am a bit confused on what the output of the gradient functions should be. For foo(x) and bar(x), the outputs are numbers but when tested with scipy's gradient calculator, it returns an array. So for foo_grad(x) and bar_grad(x) do we return a number, or a scipy array? Thanks@@@You have to remember the definition of a gradient from multivariable calculus!  Let's say we have the following function: f(x_1,x_2,x_3) thus f is a function such that it maps from R^3 to R^1. Then: - f returns a *number* based on the input (x_1,x_2,x_3), which is a point in R^3. - gradient of f returns a vector in R^3 (-> in this particular example. In general, it returns a vector in R^n that matches the dimension of domain.)  I like to think of it this way (which could be wrong, by the way): in single variable, we usually we talk about 'derivatives' of functions, which is essentially how much the function changes with respect to change in the input variable. But when we start talking multivariable, we have to ask ourselves, "change in function with respect to *which* variables?".  So when we talk about partial derivatives, it's with respect to *one* input variable, but when we talk about gradients, it's with respect to *all* variables - hence the necessity to output a vector in the same dimension as the domain.  To answer your question: Yes, foo and bar both return a number because it is a multivariable function that returns a number in R^1. Meanwhile, foo_grad and bar_grad return a vector (or an array, as you pointed out) because it gives the gradient.@@@2017-05-19T22:46:46Z@@@hw0 student
Submitting assignments@@@The homework instruction md file said to push to github.ubc.ca, so I was wondering if it was just the latest push to our repo that is graded.@@@From homework_instructions " Submission We anticipate that you will clone your homework repo and do your work from within there. When you push something back to github.ubc.ca then you have submitted the assignment. You can push changes as many times as you want before the deadline; only the final version will be graded (but see below on past commits). " So yes, it is only the last commit before the deadline in your repo that will be graded.@@@2017-05-19T20:28:54Z@@@hw0 student
Assignment 0, Question 2.1, Part 1@@@Sorry if this is a sillyquestion, but I am not sure how to reason about the fair price of a ticket. Can someone please give me some hints? I calculated the expected difference in numbers for a game that is played once, from which I know the expected earnings. Thanks so much@@@The goalis to compute the expected value of your earnings fromplaying the game once. The definition of expected value is explained here: http://www.statisticshowto.com/expected-value/ Hope this helps!@@@2017-05-19T19:39:30Z@@@hw0 student
Student Number/CS ID in assignments@@@Do we need to include our student number and CS ID in our homework assignments considering that our assignments will become publicly available to the rest of the class?@@@No, you don't need to include any of that information. The name of your homework repository, which includes your CWL username, is enough for us to identify you.@@@2017-05-19T18:11:07Z@@@hw1 student
3.1 Q2@@@For 3.1 Q2, I was wondering if we are expected to get a number value or an equation? 2.Let  f(x)=sin(kx)f(x)=sin(kx) . What is the maximum value of the 20th derivative of  f(x) ?@@@Everything you need can be derived from the original expression. We're looking for another expression in terms available inthe original one.@@@2017-05-19T05:34:37Z@@@hw0 student
Q 3.3@@@If the input x to a function is of type (for example) float , is it okay if we return (for example) an arrayof type int ? Thanks@@@I'm tempted to say that your gradients won't be accurate if you just spit out anint after you compute the gradients. You should test your gradientswiththe nice gradient approximation function we provide. Make sure you get similar answers. @Mike Gelbart anything to add?@@@2017-05-19T05:11:27Z@@@hw0 student
Iterate over indices@@@If we have an array and we want to iterate over the indices of the items in the array, is there a good way to do that? Do I just find the length of the array and do some form of for-loop? Thanks@@@Talking about something like this? https://docs.python.org/2.3/whatsnew/section-enumerate.html How to use: for i, item in enumerate(L):     # ... compute some result based on item ...     L[i] = result i would then be the indices of the array@@@2017-05-19T04:28:34Z@@@hw0 student
A0: 3.3 - Derivatives of Code@@@I have looked through the source code and know that I need to write a function that computes the gradient of a givenfunction. I know how to calculate gradients but I'm confused about what this foo_grad and bar_grad . Why do we need two functions to calculate the gradient? If someone can provide some guidance I'd really appreciate it.@@@Hopefully I understood your question correctly and my understanding of the question is correct. I believe that foo_grad is supposed to produce the gradient of the function that foo produces and bar_grad is supposed to produce the gradient of the function bar .@@@2017-05-19T01:47:11Z@@@hw0 student
LaTeX Editor Recommendation@@@The recommened Texmaker prompts errors on mac, whenever I try to press the "run". I try to download the 2 older versions, same thing happen. The 2 online editors recommended are good, but I'm trying to get one that works without uploading a file. There seems to be a lot of LaTex editors online to choose. Can you please revommend another LaTex editor ? Thanks!@@@ShareLatex is pretty good! There's also plenty of support for Latex on Stackoverflow and stuff, so you can probably just google if you get stuck. If you're working with a partner, then OverLeaf might be better for collarboration. You usually don't have to upload a file unless you're attaching a diagram with your explanation or something, and even then it's not terribly complicated :)@@@2017-05-18T23:36:22Z@@@hw0 student
Lecture 5 (KNN) - Missing slides@@@I can't seem to find the slides that we saw in class that had the "curse of dimensionality", and "scaling of features" notes. It's not in the bonus slides either, any help on where to find these would be greatly appreciated.@@@Fixed, thanks.@@@2017-05-18T20:52:22Z@@@other student
Python and Numpy@@@In Matlab, quite a few matrix operations were vectorized. Does this result in any speed gain? E.g. if you increment all elements of a 1xN matrix, it wouldn't go through a for-loop but would do all of them simultaneously.@@@@@@2017-05-18T01:06:25Z@@@hw1 student
Latex Template for assignment@@@I was wondering if there's any latex template available for the assignment? Thanks!@@@It can be found under the doc folder (/doc/a0.tex)@@@2017-05-17T19:16:14Z@@@hw0 student
Assignment format@@@Can we write down our answer on a piece of paper and scan it as a pdf file?@@@(some asked this same question last term, I'm pasting my answer below) You may submit your assignment as a scanned document but(1) I really, really don't recommend it and (2) you are at risk oflosing marks bydoing so. Every assignment will have some marks set aside for "mechanics" whichallows the TA to deduct marks if you did not make things easy for them. This would usually happen if a student did not read and follow the general homework instructions, or maybe made their plots super small so that they were hard to see, or didn't render their equations properly, etc. In the case of a scanned document, I will leave it to the TAs to decide how inconvenienced they are depending on how readable the scanned document is, but I give them permission to give zero for"mechanics" if they want. The current plan is for "mechanics"to be worthabout 10% eachassignment's grade. Rationale: first and foremost, I think producing digital documents is an essential skill these days. So, I was really tempted to say "no" to your request, for your own benefit! But on the other hand it's my job to teach you machine learning and I don't want to intrude too much by imposing all myworkflows for typesetting and publishing documents (I already appreciate that everyone is playing along with GitHub). Second, part of my job is to protect my the valuable time of my TAs so they can focus on helping you and your classmates learn. So if scanned documents are hard for them to read and this takes time away from other activities, I want to give them the power to discourage scanned submissions by deducting marks.@@@2017-05-17T18:52:36Z@@@hw0 student
course website@@@can someone remind me the course website? I missed the first class. Thanks a lot :)@@@https://github.ubc.ca/cpsc340-2017S/home@@@2017-05-17T04:08:50Z@@@other student
A0: 3.3 - Approximation & sig figs@@@For my output for bar_grad, I get the same results as the SciPy gradient method, but with extra decimal places. Should I trim these to match the SciPy output or is it okayto leave the extra decimals? Thanks in advance!@@@It sounds fine. We're grading the code, not the output of the gradient checker, so if you're confident the code is correct then you're good to go.@@@2017-05-17T03:44:08Z@@@hw0 student
[A0] How detailed do we need to be@@@Just wondering for A0 (and later assignments too if applicable), how detailed should our answers be? For example, do we need to include the formulas, stats model, intermediate steps, or just go for the final answer like P(X=1) = 1/2 ?@@@Whoops, nevermind, there's "you do not need to show your work" on assignment pdf.@@@2017-05-17T02:14:09Z@@@hw0 student
A0: 2.1 - Coin flip question@@@You flip 5 coins. What is the probability of observing 4 heads? Is this referring to exactly 4 heads, or at least 4 heads? I'm assuming the former, but I want to make sure. Thanks!@@@Exactly 4 heads.@@@2017-05-17T01:43:43Z@@@hw0 student
Using Jupyter for Report@@@Under the report format section of the homework instructions : "If you wish, you may embed your answers directly in the assignment document, as long as your submission is clear and easy to read." So, if we use a Jupyter notebook and put everything in there, do we still need to put separatecopies of the figures and code into the /figs/ and /code/ directory? Just wanted to double check for future assignments, thank you for your time!@@@No, if you use Jupyteryou can embed everything in there. If the figures are generated by the code in the notebook, which they presumably would be, then you wouldn't need the figure files to be saved separately.@@@2017-05-16T22:52:48Z@@@hw1 hw10 hw2 hw3 hw4 hw5 hw6 hw7 hw8 hw9 student
L3 Slide 15@@@My question is about slide 15 of Lecture 3. What is the result of the decision stump learning pseudo-code in the case where the mode below and above the threshold are the same? Do we just ignore this decision stump rule?@@@If the 2 categories have the same mode (say $$y=1$$), then that means that $$y=1$$ is also the mode of the entire dataset. In such a case, you can just ignore these rules and predict $$y=1$$ with no splitting. Does that help?@@@2017-05-16T22:30:36Z@@@other student
Tutorial Material@@@I happen to be one of those unfortunate folks in 322 who has no tutorial section that fits my schedule. While I know we can attend other sections that are full, I was wondering if the material for tutorials will be posted elsewhere so that I could review it on my own time?@@@Yep, we'll post them at https://github.ubc.ca/cpsc340-2017S/home in a new directory for tutorial materials. It'll be the responsibility of the TA leading the tutorial to do this, so feel free to bug them if they haven't done it yet. BTW if you can only attend the third tutorial because of 322 then it's fine with me if you go even if it's officially full. Just don't take a set and leave a registered student standing. But this seems unlikely because we're moving them to bigger rooms and there should be enough seats.@@@2017-05-16T22:12:35Z@@@other student
