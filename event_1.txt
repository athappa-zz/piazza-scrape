2017-06-23 07:03:24.689655
Do we need to know SVD?@@@SVD seems to be in the assignment, but it's in the bonus slides, do we need to know it for the final?@@@You need to know it exists and that it gives you PCA with orthogonal PCs ordered by importance. That's it.@@@2017-06-23T17:19:06Z@@@other student
Convolutional Neural Networks and Dimensionality Reduction@@@When we make our $$W$$ matrix represent a convolution applied to the elements of $$x_i$$, the outputted $$z_i$$ will have the same number of features as $$x_i$$, just altered after applying the convolution to each entry of $$x_i$$. Thus, convolutional neural networks do NOT do dimensionality reduction. Is this correct? (1) The "dimensionality reduction" then occurs later on if we do max pooling, which reduces the number of features. Or we could do dense layer (PCA layer) and reduce the dimensions in that way. Is this correct? (2)@@@It does not necessarily reduce the dimension nor increase the dimension. It depends on how you pad the image and how many convolution filters you apply. Let's say you have an image of 3 channels, 10 rows and 10 columns. You apply 32filters of size 3x5x5on top of the image,you end up with an image of 32 channels, 6 rows and 6 columns. Then the number of features you have as a result is: 32*6*6 which is larger than 3*10*10. However, you can reduce the dimensions by having large few filters. For example, if you had 2 filters of size 3x8x8 then applying that on the original image gets you an image with 2 channels, 3 rows and 3 columns, which has only 2*3*3 features. Max pooling usually reduces the dimensions significantly.@@@2017-06-21T22:51:14Z@@@other student
Will the final lecture slides be posted@@@@@@I just posted them. I just removed the slide about the prize winnersin case they didn't want to be on aslide.@@@2017-06-22T19:09:07Z@@@final_exam student
A5 3.1@@@I'm a bit confused on 4) Avg of per-user and per-movie averages. Are we supposed to take the average of all each user's average rating and each movie's average rating..?@@@All i did was (movie + user)/2 still unsure about it@@@2017-06-24T00:17:41Z@@@hw5 student
Matrix Factorization@@@Are we basically doing a PCA-esque thing TWICE (once for movie features ($$W$$), once for user features ($$Z$$)) and then combining them in our linear model?@@@No, not quite. The PCA-esque thing gives us $$U$$ and $$V$$ in the assignment's notation. The weights $$W$$ for the features $$Z$$ is a regular linear regression, not a PCA-esque thing. And furthermore the PCA-esque thing has a sort of symmetry in that we interpret$$U$$ and $$V$$ roughly in the same way whereas when we talked about PCA the $$W$$ and $$Z$$ had quite different interpretations. Does that make sense?@@@2017-06-23T06:46:21Z@@@other student
Instructors Office hours@@@Hello Mike, I was wondering if you will be having office hours this week Thanks, Anny.@@@That's a reasonable request! I've just added onefor 2-3pm tomorrow.@@@2017-06-21T17:21:06Z@@@other student
Review session on Monday@@@Is it possible to change the review session time from 10am-12pm to a bit later? Some of us have final for CPSC313 until 11am.@@@It's too late to change the room. It's more complicated to reserve lecture rooms than regular rooms. However, I just added an office hour from 5-6pm on Monday.@@@2017-06-23T16:42:13Z@@@other student
L28 Questions@@@Hello, I have a question about lecture 28 Slide 8 - Inactual neurons, a signal is either propagated through axion, or not.But in our neural networks, we always send the signal (value of $$W_c x_i$$) along, large or small. It is my understanding that we want to only approximate the binary decision of the propagation of the signal in our brain by using a sigmoid function.In the slide,it is mentioned that sigmoid function is used as an approximation to identity function, because identity function ishard to optimize. But identity function being hard to optimize and non-differentiable is not the only reason we are not using it, correct? It is also because we want all signals to be propagated, in our neural network, correct?If we could use the identity function, it would mean that some of the elements of z_i would not be propagated and used for predicting $$y_i$$, which is definitely not want we want, correct? Thank you!@@@If we are talking about the identity, $$f(x) = x$$, I would disagree against the reasoning as to why avoid using it. The reason we use a non-linear activation function like the relu or sigmoid is that we want to add non-linearity to our model. If we just had the identity function as our activation function then we could collapse two hidden layers into a single matrix operation. $$W_2h(W_1X)$$ cannot be simplified if $$h$$ is the sigmoid, for example. However, $$W_2f(W_1X)$$ can be simplified to $$W_2W_1X = (W_2W_1)X = W_3X$$, if $$f$$ is the identity function. We are not adding any non-linearity to our model and therefore we can collapse the two matrix operations $$W_2$$ and $$W_1$$ into $$W_3$$.@@@2017-06-24T18:55:19Z@@@other student
L33-recommender systems@@@I am wondering whether these two W are the same or not? and what are the dimensions for these two Ws? Thanks!@@@They're different. $$w^T$$ is just regression weights, so it is $$1$$ x $$d$$ if we have $$d$$ features. $$w^T_j$$ is a column of $$W$$ ($$k$$ x $$m$$), so it is $$1$$ x $$k$$.@@@2017-06-23T18:34:33Z@@@other student
Can a4 solutions be posted?@@@Thanks!@@@Done: https://github.ubc.ca/cpsc340-2017S/home/tree/master/solutions/a4@@@2017-06-23T20:08:46Z@@@hw4 student
Q3.1 Model 6@@@Is anyone else getting a train/valid loss of ~1.4? Not sure if I've implemented it correctly.@@@I've seen people with lower. Mine is in that regionwhich is why I'm thinking I did something wrong.@@@2017-06-24T02:40:00Z@@@hw5 student
Final exam material@@@How much of the final will be onpre- and post- midterm content?@@@He said in class that it'll be very slightly heavier on post midterm content, but in a pretty hand wavy motion so I think it'll be roughly equal.@@@2017-06-23T16:13:04Z@@@final_exam student
A5: Q3@@@In model 9, why do we have: print("Per-movie average train loss: %f" % score( Y_pred_9 , Y)) print("Per-movie average valid loss: %f" % score( Y_pred_9 , Y_validate)) That is, why are the predictions the same for both the validation and training set?@@@Not sure if understanding your question fully... But, we use use this same setup for all the models. It's just that the Y_validate and Y have sensible entries at different positions. When we validate our model, we only look at the entries where there is a value and not a NaN. Hope this was getting at your question.@@@2017-06-21T20:48:03Z@@@hw5 student
Regression Weight Approach to Feature Selection Lecture 14, Slide 16@@@Why does the regression weight approach to feature selection allow tiny effects? If we have two collinear tiny effects then I understand how each of them could end up with a large weight in absolute value. But if we just have one tiny effect,why will it still be allowed?@@@My interpretation is the same as yours: that it allows tiny effects in the same way it allows non-effects, due to the craziness that can happen with collinearity.@@@2017-06-24T04:49:58Z@@@other student
Q3.1@@@I'm a bit confused with why the Per User Average implementation is using avg_n = np.nanmean(Y,axis=1) with axis = 1? If I'm not mistaken Y is a (671 x 9066) or (N x M) or (user x movie) matrix. In a 2D matrix, is axis = 1 the column (M in this case)? Was this a mistake or am I understanding this wrong? thank you!@@@This takes the average across the columns. Each row in Y represents a user, so taking the average across columns (or axis 1) of a row represents theaverage rating of that user. Running the command, avg_n = np.nanmean(Y,axis=1) results in a 671 sized vector containing the average rating for each of the 671 users.@@@2017-06-21T21:55:34Z@@@hw5 student
HW5 Q2 - MLPClassifier for image data@@@I got all ambitious for Q2 and downloaded about 400 images of cats and dogs and decided I was going to try to classify them, I regularized the image size and converted them all to greyscale. But I'm now realizing this may not be such a good idea. Without any consolation layers do I have any chance? I'm getting about 0.45 error and I think it's because about 45% is dogs and the model has learned just to classify cat. Should I give up on this? Thanks@@@@@@2017-06-22T18:10:54Z@@@hw5 student
A5: Q3 model 6@@@I am getting pretty good training loss~0.7 for model 6, but i got a HUGE (~10^24) validation loss... It doesn't seem normal, but I don't know what went wrong. Can someone shed some light on this?@@@never mind I just restarted thenotebook and it worked@@@2017-06-22T21:37:25Z@@@hw5 student
A5 Q3@@@On the line ratings = pd.read_csv(os.path.join("..", "data", "ml-latest-small", "ratings.csv")) I get the following error: FileNotFoundError: File b'../data/ml-latest-small/ratings.csv' does not exist And I don't see this file in the data folder myself. There is also no such file inhome/assignments on GitHubthat can be downloaded separately. So I'm confused where to get this ratings.csv file.@@@Edit: Nvm, I messed up the code trying to make it work through PyCharm. Found the link in the notebook after redownloading the code and using web-browser.@@@2017-06-23T02:39:12Z@@@hw5 student
A5 q3: In model 9 why does the validation error increase@@@After a certain number of iterations, the validation error increases. How does this happen?@@@This is a classic symptom of overfitting. There's no guarantee that the validation error goes down when training error goes down. Because maybe the model starts getting too crazy.@@@2017-06-23T05:25:57Z@@@hw5 student
A5:Q3.3@@@For this question, should we also mention why we would use L2-regularization vs for example L1-regularization? Thanks@@@You don't have to.What I really want you to think about is why in (5) we don't really want/need any regularization at all.@@@2017-06-23T08:00:39Z@@@hw5 student
Why I can't have 0 training error?@@@When I use a neural network, if I have a single hidden layer with the size being the same as the number of examples, I should have 0 training error, right? I have tried that on the boston house price dataset from sklearn.dataset, but I still get a training error around 23, which is the same as using the linear fitting (hidden_layer_sizes = ()). Why is this the case?@@@There are other things that effect what the net converges too. I was able to get lower and lower training errors increasing iterations with 1 layer the size of n but it requires a specific combinations of other parameters as well.@@@2017-06-24T05:45:16Z@@@hw5 student
A5 Q3.5@@@I'm a little stuck on this question and unfortunately did not get to Q3.5 during office hours. Basically, I'm not sure what the significance is of splitting on the three different classes. Considering this is the question being asked in the assignment, I'd like to know in general: - I'm not entirely sure what concepts are being linked together here. Judging by the wording of the problem, it seems to me that we have to combine the concept of multi-class regression and validation. I could be wrong about this though (in the sense that I don't recall regression with multiple classes just classification), and maybe this is why I got stuck in the first place. Any help is appreciated. Thanks.@@@I'm confused -- what do you mean by three different classes? There is no classification going on here, only regression. We are trying to predict the ratings which are numbers from 1 to 5 (well I guess they are integers but we are treating them as continuous values).@@@2017-06-23T23:42:22Z@@@hw5 student
L28 Questions@@@Hi, I had a few questions about L28. What does it mean by 'we can now think of z_ic as binary features we learn' -I understand that z_ic here refers to an element of z_i. Why is it a binary feature? Thanks :)@@@@288@@@2017-06-21T20:45:51Z@@@other student
Whats the motivation for Gradient Descent?@@@I was wondering if someone could explain the motivation behind gradient descent and stochastic gradient. I understand how they work, just not why we use them. If we know the gradient already, why not just solve for when$$grad f(x) = 0$$ ? I can't follow the motivation described in lecture 12. Thanks@@@Update: Added another answer [Answer 1] because we can't "just solve it". the equation is almost always unsolvable in closed form so we use iterative methods. least squares is a rare exception. [Answer 2] I don't think "Answer 1" is necessarily wrong but I was confused about this too so I'll try to add a bit of color. The tl;dr version is that both are optimization techniques but stochastic gradient descent is a more scalable solution because it uses a subset of the data to pick the "direction to the bottom." Here's how I think about it ( Mike, if this is wrong please let me know ). Consider wehave some data and we've chosen a model and a cost function. For now, let's saywe have a regression problem and are using a linear regression model in $$\mathbb{R}^2$$...Given this, we will want to estimate the weights (or parameters) of the model and we do this using gradient descent. In this case, we have a squared error cost function and we will use gradient descent combined with our cost function to figure out the slope and intercept.In short,we initialize the parameters to something, iterate with gradient descent, and we head to the global minimum (because we're in convex-land). The motivation for why we use Stochastic Gradient Descent is because it's really computationally expensive to compute the gradient because we have to sum over all the examples and then we have to do this over arbitrarily many features. Not good! So the idea istomake it such that we don't have to do these costly training-set long summations by just taking some number of training examples that are in some sort of random order.@@@2017-06-22T01:57:45Z@@@other student
Q3.1 Combining prediction@@@In #4 and #9, we need to combine previous predictions, is it as simple as (predA + predB)/2?@@@For #4 yes, for #9 you need to think about it carefully. It's just one line of code, and not a crazy line, but it requires understanding what the model is doing.@@@2017-06-24T00:27:49Z@@@hw5 student
Linking Jupyter notebook in README file@@@How do I link to theJupyter notebook file? Do I just use the address in my browser? Thanks@@@Yeah, the same way you'd link to a .py file. The nice thing is that GitHub automatically gives in-browser static renderings of Jupyter notebooks.@@@2017-06-23T17:38:09Z@@@hw5 student
method 7 has invalid error@@@I do not know why I have this error. I did not touch anything in method 7. I tried to restart and rerun all the cells but it still doesn't work. Could anyone help me? Thank you so much!@@@I changed the avg_n and avg_m during the implementation of method 4. I think this is why.@@@2017-06-22T23:58:29Z@@@hw5 student
Softmax classes@@@For softmax, do we encode the classes as {-1,1} or {0,1}@@@You just want to keep track of the classes that you model predicts. In the end, the softmax loss does something like this: $$f(w) = \sum_{i=1}^n \log \left( \sum_{c=1}^k \exp(w_c^T x_i) \right) - w_{y_i}^T x_i$$ So, you just want to understand what column of $$w$$ corresponds to what class. It's easier if you assign labels for your $$y_i$$ that go from $$[0, 1, 2 ...]$$ so that you know that the $$0^{th}$$ column of $$w$$ corresponds to label $$0$$ and so on.. But, I guess you could also have labels that are [-1, 1, -100, 300, 666] as long as you know which column of $$w$$ corresponds to what label..@@@2017-06-23T16:40:29Z@@@other student
Search and Score Lecture 14, Slide 20@@@Under "Usual Score Functions" it says "Validation/cross-validation". How doesvalidation/cross-validation act as a score function? Thanks@@@The score function needs to prevent overfitting (hence why we can't use training error, which would cause us to keep all features). Validation error does that. So it's an alternative to training error + L0.@@@2017-06-24T05:16:34Z@@@other student
