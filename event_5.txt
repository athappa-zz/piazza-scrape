2017-06-26 10:17:04.800000
How long is the final?@@@thanks for a good course@@@Last year's was 2.5 hours. I assume ours will be too. Yes it will (lecture 25 slide 2)@@@2017-06-27T02:35:05Z@@@final_exam student
Neural Network Parameters@@@Can someone shed some light as to why a neural network with two hidden layers of size "a" and "b" need to keep the following parameters: da + ab + bk + a + b + k? It makes sense to me why we want da, ab, a and b and k because those are the regression matrices for the hidden layers + intercept + linear regression coefficient for prediction. Why would we want bk though? I thought at the end, we would only have a column vector for the linear regression weights that combine the final learned latent factors (which we've accounted for with k).@@@The question states that $$k$$ is the number of outputs, so in the end we should be getting a vector of size $$k$$. So that means for each $$k_j$$ we take a linear combination of $$b_i$$'s. Hence the extra parameters of size $$bk$$.@@@2017-06-26T22:09:23Z@@@final_exam student
L27 Slide 14@@@I'm really confused as how we got w3, why do we move left from w2 to get w3? Also why do we go back for f1(w)?@@@With SGD using a minibatch size of 1, at each iteration you pick one random training example and take your gradient step with respect to that example only. In this slide you happened to pick a training example that isn't particularly representative (maybe it's an outlier) and its own little loss function (the lower parabola) tells you to go left. So you go left even though a regular gradient descent step would have taken you to the right.@@@2017-06-24T22:55:55Z@@@final_exam student
Convolutional neural network@@@Could somebody explain whatthe whole point of convolutional neural networks is? I know that this is a big question but some form of short explanation might help in getting a better grasp of this. Thanks!@@@@@@2017-06-26T00:54:31Z@@@other student
L0 regularization explanation (slide 14)@@@I'm having some trouble understand the line For L0 regularization, is f(w) the score function or just L0 norm the score function? what should 's' be then?@@@$$s$$ is some subset of the features. $$f(w)$$ is the score function, for example a squared error term plus an L0 term.@@@2017-06-25T21:17:54Z@@@final_exam student
PCA uniqueness@@@Why is it a problem if PCA is not unique?@@@Because it means that without restriction there are infinitely many solutions. I can write: $$X=ZW$$ or $$X=\frac{1}{10}Z*10W=ZW$$ or $$X=\frac{77}{89}Z*\frac{89}{77}W=ZW$$ etc. Remember when we got PC in assignment 4? Theline we got passes through (0,0) and (1,1) and it's equally correct to write it as <1,1> or <2,2> or <1/5,1/5> etc. But there is a restriction |w|=1 to make things more convenient, so now there are only two way to write it: $$<\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}>$$and$$<-\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}>$$@@@2017-06-27T02:31:22Z@@@final_exam other student
Softmax training cost@@@Does anyone know what is Softmax's training cost? I can't seem to find it in the slides...@@@I'm not sure but for training we have to use gradient descent. Gradient descent is usually O(dnt) where t is the number of iterations.So the question is probably how long it takes to calculate the gradient which in this case is a $$d x k$$ matrix. Lets see what Mike says.@@@2017-06-27T01:45:58Z@@@other student
Exam 2016W2 Q3 Intercept Storing@@@I understand storing weights for making the predicitions, but I am unsure what the intercepts are and how they aid in prediciting?@@@The intercept values allow you to shift the model's prediction to the location of the data if it is not centered at 0. Consider a simple linear regression $$y=ax+b$$ . We want to find the $$a$$ and the $$b$$ to get the line of best fit that crosses through some data with minimum squared error. If we didn't have the intercept value, we'd only be able to work with $$a$$ and probably get a very bad fit if the data actually was shifted away from 0. Instead, we can add an intercept value to get a better fit. We can do this sneakily by saying that $$ y = \begin{bmatrix} a & b \end{bmatrix} \begin{bmatrix} x \\ 1 \end{bmatrix}$$ So the parameters we want to learn are $$ \begin{bmatrix} a & b \end{bmatrix}$$. See Lecture 9.@@@2017-06-26T16:48:10Z@@@other student
Coding questions on final exam?@@@Apologies if this was mentioned already, but are there going to be coding questions on the final? The midterm did not have coding questions like Mike said, but I'm not sureif that is the case for the final.@@@Nobody has asked this yet. The answer is, the final might ask you to read and/or write Python code (last year's final had a question that involved reading code). But, if there is a question about writing code, syntax errors will be forgiven -- I understand nobody actually writes code on paper in real life.@@@2017-06-26T00:35:14Z@@@final_exam student
Centring and Standardizing y?@@@Do we ever want to centre and standardize our target/class labels $$y$$, like we do with our examples/features matrix $$X$$?@@@Yes, this is sometimes done. In fact, having an intercept or "bias" term in linear regression is related to this issue. Instead of using an intercept, you could have centred the $$y$$ values instead. But this would not necessarily give you the same solution, because the intercept doesn't necessarily always work out to being exactly the mean of the examples. So it's better not to constraint yourself in this way. The scalingof the features $$X$$ is more important because you have to worry about the scale of each feature relative to the other features, for methods where this matters (e.g. KNN, most regularized models). The question to ask yourself is whether the model would be affected or not by a given preprocessing step.@@@2017-06-24T22:57:37Z@@@final_exam student
Lists of questions@@@I listed my questions below. 1. Lesson 24 Page 9: How does PCA maximize variance in Z space? What does it mean and why? 2. From 2016 w2 midterm exam Q1(c): Including a bias (intercept) parameter in OLS will cause training error to decrease? The answer is Yes. But... - I thought it is acting a similar role as increase$$\lambda $$ in L2-regularized OLS, because it is also adding an extra term in the OLS. But why would including intercept parameter not cause training error will increase?? 3.From 2016 w2 midterm exam Q4(a): I was wondering why is it not 5 * 4 = 20? Because there will be 20 combinations of splits. 4. continued from the question above, (From 2016 w2 midterm exam Q4(b)) I don't quite understand the solution, but my answer was: yes, if we split 4 <= x1 <= 5, 2<=x2<=3, then all data within the range will belong to -1, and everything else will belong to +1. Why is it wrong? Thanks in advance.@@@1. Suggest you ask this as a separate post. A student should be able to answer but students probably don't want to answer all 4 questions. 2. Adding an intercept is completely different from adding regularization. The intercept is a trainable model parameter, whereas $$\lambda$$ is a hyperparameter. This is a critical distinction. More traininable parameters generally means more model complexity and therefore lower training error. Whereas regularization is meant to prevent overfitting but costs you a bit in training error. 3. I don't understand your reasoning. Can you explain it in depth? 4. The question is asking about a decision stump, you are thinking of a decision tree.@@@2017-06-25T07:12:41Z@@@other student
Lecture 18, Slide 17@@@How exactly does $$\lambda$$ control the trade-off? Does a larger $$\lambda$$imply a smaller margin?@@@After teaching SVMs for the third of fourth time this term, I'm starting to think that we should drop the whole notion of margin. It's always taught this way, where you start from linearly separable data and maximize the margin. But whenis a data set ever linearly separable anyway?? And if it's not, does the margin even make sense? No to mention that we set the margin to 1 through some crazy manipulations as discussion in the bonus slides. So I'd say, to understand it to 95%+ depth, you can just forget the margin. Instead, just think about it as a linear model with a bunch of $$w$$'s that multiply the features just like linear regression. And regularization keeps the values in $$w$$ small. When you use a nonlinear basis, regularization is maybe even easier to understand. I suggest you play around with the notebook on this ( https://github.ubc.ca/cpsc340-2017S/home/blob/master/lectures/L20demo.ipynb ) and try changing the regularization parameter. This is $$C$$ in sklearn, which is basically $$\frac{1}{\lambda}$$. So when $$C$$ goes towards zero that means lots of regularization. Another way of answering your question: a bigger $$\lambda$$ means you're more forgiving about misclassifying points. This is true for every model (not just SVM). There's a tension between the data fit term (usually written on the left) and the regularization (usually written on the right), and $$\lambda$$ controls the tradeoff between them.@@@2017-06-25T01:35:59Z@@@other student
2016W2 midterm Q3b@@@Why is the space complexity of Naive Bayes just O(d)? I thought we need to calculate the conditional probabilities, which means we need to have access to the original dataset.@@@Because "with binary features and binary models". So all you need to predict an example is to compare $$p(y=0|x)$$ with$$p(y=1|x)$$ And from L22 slides you can see that we iterate over d only when computing these things:@@@2017-06-27T02:12:21Z@@@final_exam midterm student
Hinge loss@@@We might have discussed this, but how do we optimize the hinge loss?@@@We didn't really talk about it. We just said it's convex and it can be done efficiently.@@@2017-06-26T04:03:00Z@@@other student
2016W2 final, Q4f@@@What parameters have to be initialized for logistic regression and SVMs?@@@The regression weights, $$w$$.@@@2017-06-26T06:53:28Z@@@final_exam student
Hinge loss: Lecture 17, Slide 19@@@Even if the solution is a perfect classifier (getting the sign right for every example), why does that imply that f(w)=0? We could still have a $$1-y_iw^Tx_i > 0$$ for an example even if we correctly predict its sign (for instance if $$y_i=1$$ and $$w^Tx_i = 0.5$$).@@@I added the "because then f(w)=0" to Mark's original slide. Then I remember in lecture saying I wasn't so sure about this anymore. If there is L2 regularization then it is not true. But if it's just $$f(w)$$ as written then it might be, because you could scale $$w$$ to be arbitrarily large. It's probably just confusing though. You can safely ignore it.@@@2017-06-26T20:27:03Z@@@other student
Robust PCA Parameters - 2016W2 Final 3a@@@In 3a) on last term's final, we are asked for the number of values that need to be stored after training to make predictions later on for a number of models. I am just curious as to why the number of parameters for robust PCA doesn't include the means of the features - the answer key gives only kd as the solution, the size of W - but I was under the impression we would also need to store these means in order to subtract them off new examples, as we did in A4, before multiplying them by our W. For this, I would have answered kd + d ... is there something wrong with my intuition here?@@@That's a good point! $$kd+d$$ would be an even better answer.@@@2017-06-27T01:33:08Z@@@final_exam student
A4 3.1 PCA by Hand@@@Why is reconstruction error not the sum of the squared errors but the square root of it.I'm looking at the formula from lecture 23 slide 14.@@@I'm pretty sure that the reconstruction error is different from what you have on the slide which is the loss function. The reconstruction error is just a measurement of how far off you were on the reconstruction,we use the square root of the sum of the squares because that's the distance from out reconstruction to the actual original point.@@@2017-06-27T03:56:42Z@@@hw4 student
Low-dimensional representation?@@@From the2016W2 final question 5 b), I am unsure how to reduce this vector to $$[-2,0]^T$$. Can someone show me their approach?@@@Multiply $$ W^Tz_i $$ where $$ z_i $$ is the centeredlow dimensional representation vector in the quetion.@@@2017-06-27T16:16:07Z@@@final_exam student
What room will the review session be in?@@@Will it be the same as the tutorials?@@@I think Mike mentioned it would be in dmp 110 or whatever the room number our lectures are in?@@@2017-06-26T04:15:30Z@@@final_exam student
L14 Page 23: L0 optimization@@@In L14 P23, it says I was wondering if we cannot use gradient descent, then what do we use to optimize L0?@@@I'm not really sure, but we should minimize the whole thing, which is $$parabola+number\_of\_non\_zeros=parabola+integer$$ And$$parabola+integer$$ is just a parabola, so we can minimize it.@@@2017-06-27T02:47:08Z@@@hw0 student
Final location@@@Does anyone know where the final is? I can't seem to access SSC --> I'm guessingit has something to do with 3rd year course registration, don't know.@@@Angus 098@@@2017-06-27T17:46:45Z@@@final_exam student

Movie Recommender for Unsupervised Learning@@@If I remember correctly, professor said that using unsupervised learning method for movie recommender, it wouldn't work if the new movies don't have ratings yet. Is it because since we are grouping similar users with the movies they rate, if the movies are not rated, we cannot find any users with the new movies?@@@The way I interpret it is that the with an unsupervised model we are try to learn the Z and W that best represent X, i.e. X = ZW. In the assignment the SVD model essentially finds two matrices U and V that best reconstruct the original matrix, let's call it X, which contains all the ratings for particular movies and users. When we constructed a training and validation set we removed certain elements of the matrix X, but not necessarily complete rows or columns, i.e. complete users and movies. The goal of our unsupervised approach is try and fill in the missing matrix entries by using the information we have about the rest of the column and row for that particular movie/user pair, coupled with other information in our data set.@@@2017-06-24T21:16:24Z@@@other student
Pass Final@@@Do we need to pass the final to pass the course?@@@No@@@2017-06-26T22:37:52Z@@@final_exam student
Face Detection via Eigenfaces@@@How much about the eigenfaces from L24 do we have to know for the final?@@@They are an example to help you understand and appreciate PCA and then later NMF. So you need them to the extent that they help you understand, not for the eigenfaces themselves. I think it's worth getting to the point where you understand the basic premise, which is that the images are "flattened" into feature vectors and the principal components can thus be put pack into image form (un-flattened?) and visualized as in the slides.@@@2017-06-24T23:45:13Z@@@final_exam student
Standardizing target@@@In the L2-Regularization slides, it says setting w=0 with a standardized target predicts average y i . I'm confused because wouldn't setting the weights to 0 make all predictions 0?@@@Correct me if I'm wrong: If you set the weights to 0, your predictions are 0, which equals the average$$y_i$$ if$$y_i$$ is standardized. (standardizing$$y_i$$ gives it a mean/average of 0).@@@2017-06-25T16:52:31Z@@@other student
What's the weight percentage for before mt and after? Is that 50:50@@@@@@I guess I don't feel the need to specify it so precisely. The whole course will be covered, especially material that appeared on assignments. I don't want you to overfit to the specificationsof the exam.@@@2017-06-26T06:55:06Z@@@final_exam student
Lecture 26, Slide 18@@@What do we mean by "negative coefficients usually make sense"? Does that mean that sometimes we want sparsity but not necessarily restrict ourselves to non-negativecoefficients because in a certain contextnegative coefficients make sense?@@@You tend to use NMF when negative parameters don't make sense for the problem (because NMF doesn't allow negative parameters). If negative paramters do make sense/is reasonable, then you may want to use L1 instead of NMF because the former allows negative weights.@@@2017-06-27T02:49:17Z@@@final_exam student
backpropagation@@@I am wondering how much we need to know about backpropagation for the final?@@@You should know what it is (derivative of neural net loss wrt weights using a clever algorithm to not re-compute things) but you don't need all the details.@@@2017-06-25T23:09:01Z@@@final_exam student
Pagerank@@@Maywe have bonus slides about studying Pagerank? I've been told that it is curriculum with this course in other terms...May we also have slides about all other missed material? I'd like course material that we missed due to oursummer term...@@@Check out Mark's website: https://www.cs.ubc.ca/~schmidtm/Courses/340-F16/@@@2017-06-27T02:20:08Z@@@other student
2016W1final_sols.pdf@@@Is the solution to Q8c and Q8d correct? Shouldn't it increase the training error instead? Thanks@@@Yep (see @331)@@@2017-06-26T04:53:10Z@@@final_exam student
Gradient Descent with L1 and L0 regularization@@@Hi, I understand that we use smooth approx. to loss function fn so then we can differentiate the objective. So If we are using L1 or L0 regularization term, do we also need to use smooth approximation to the regularization term so that we can differentiate the objective fn? Thanks@@@I don't think we want smooth approximations to the regularizationterms because then we wouldn't get this nice sparsity effect anymore. To optimize loss functions involving L1 regularization we can use proximal gradient methods instead.@@@2017-06-26T21:02:57Z@@@final_exam student
What does the @ symbol do?@@@It doesn't seem to be a standard python thing. And I'm having trouble figuring it out because you cant Google search the @ symbol.@@@When used as an operator (like +, -, /, *), it represents matrix multiplication.@@@2017-06-26T01:30:36Z@@@other student
More questions@@@I have more questions to complete my lecture slides: - L26 page 14: what are the weak assumptions to reach local minimum? - page 16: what is an example for non-sensible ordering? - page 20: which is the better one? - page 25: what is an example of removing correlations? - page 28: what is opponency (I can't find the word in my dictionary)? - L27 page 23: how do we choose numerator gradient? - L29 page 35: is binary search to look at only logn examples? - L31 page 12: what is/how do we subsample? - page 32: what is spacial regularizer? - L33: is bottom inequality restricting rules amount? - page 22: what is the 2^d calculation (is it two for present or not present)?@@@1. Don't know! 2. Maybe you just want a bunch of factors but in no particular order. That's all its saying. Rather than PCA which orders from most to least variance explained. 3. Depends what you're trying to accomplish! 4. See http://ufldl.stanford.edu/tutorial/unsupervised/PCAWhitening/ 5. See https://en.wikipedia.org/wiki/Opponent_process 6. This is described at the bottom of the slide (practical trick). 7. It seems that L29 does not have a page 35? 8. Subsampling means taking a subset of the samples and throwing away the rest. For example you can subsample (or "downsample") an image by throwing away 3 out of every 4 pixels to get half the resolution in each dimension. 9. A term that encourages neighbouring pixels to have similar values. 10. Which page? 11. Yes. Present or not present for each feature.@@@2017-06-28T04:18:57Z@@@other student
What is the terminology "tiny effect" in general@@@@@@I believe it has to do with the weight associateda particular variable. So for instance $$10x_0$$ would have a much larger effect than $$0.000001x_0$$.@@@2017-06-26T06:36:21Z@@@final_exam student
L29 page 38@@@Is "Not really simulating binary signal, but could be simulating rate coding.", about the reLU activation function, meaning that we should not use this when our response variable is a binary variable?@@@@@@2017-06-27T02:15:23Z@@@other student unanswered
Opening an issue on GitHub@@@Just want to make sure I did this correctly. I opened an issue about the Assignment 4 grading by opening an issue in my grade repository. I explained what the problem is and included @cpsc340-2017S/staff . Is that the way to do it? Thanks@@@Yes. If it slipped through the cracks please try again.@@@2017-06-25T06:55:03Z@@@hw4 other student
linear classifier parametric?@@@I know SVM is parametric, but can someone help to clarify if hinge-loss without regularization and logistic regression loss parametric or non-parametric.@@@All those things you mention are linear classifiers. So they are parametric. And in particular you have one weight per feature just like linear regression.@@@2017-06-26T22:47:21Z@@@other student
MDS preserves high dimensional distances@@@I'm trying to understand MDS cost function here: I am confused that, since we need to minimize the cost function, then how does the cost function tell us the "z_i preserve high-dimensional distances between x_i"?@@@If $$f(Z)$$ is small, that means that the terms that we're summing up are small, ie. $$\|z_i - z_j\| - \|x_i - x_j\|$$ are small. In other words, $$\|z_i - z_j\|$$ and $$\|x_i - x_j\|$$ are close to each other. The first term here is the distance between examples $$i$$ and $$j$$ in low dimensions and the second term is the distance in higher dimensions. Thus, what we're trying to do is to minimize the difference between the high dimensional distance between examples $$i$$ and $$j$$ and their low dimensional distance.@@@2017-06-26T03:36:24Z@@@other student
Increased test error for L2?@@@In the slides, it says: It says "almost", so is there any situation that will increase the test error?@@@Iguess if lambda is very (infinitely) large, then the model can be even worse than without regularization, because we focus on minimizing ||w|| ignoring the rest of the function. For example, by playing with L15 demo and setting regularization strength to 100 I got the following. Imagine what would happen if reg strength is 10^10000.@@@2017-06-27T03:18:45Z@@@other student
non-parametric method@@@I am confused that why this is a non-parametric method? Can someone explain it? Also, is linear regression a parametric method or non-parametric method?@@@This is a weird one. Normally, linear regression with a polynomial basis would be parametric. The trick is that the basis of degree $$n$$, which means the complexity grows with the number of training examples. More generally, linear regressionis usually parametric. But if the number of features (and thus weights) grows with $$n$$ (like in the above or with RBF features) then we'd call it non-parametric.@@@2017-06-26T03:04:17Z@@@final_exam student
2016W1final Q8 (b) and (c)@@@I don't quite understand "since we can increase the norm of Z to compensate for any decrease in the norm of W" . How exactly is this done? Will this also affect the first term of the objective function? And for (c), why does the training error decrease instead in this case?@@@This is saying that if you don't have the orthogonality constraint on $$W$$, then you can always multiply the entire $$Z$$ matrix by some constant (say, 2) and divide the whole $$W$$ matrix by that same constant, and you'll get a model with the same loss. Sobasically if you only regularize $$W$$ then the solution is to make $$W$$ arbitrarily close to 0 and $$Z$$ correspondingly huge, which satisfies the regularization term and the data fit term. In (c) we're back to the normal world where regularization actually does stuff.@@@2017-06-24T22:23:49Z@@@final_exam student
When do we need to standardize columns in general?@@@It's in the last lecture slide Big ideas of the course:collecting your data,preprocessing(standardize columns?)@@@An example would be when using PCA. It assumes that the columns are centered around 0... so you'd just subtract the mean of each feature from each feature. So, a process would be standardizing the data, performing PCA, then when new data comes in, standardize with respect to the data. If we want to reconstruct the data, we'd have to reverse the process and so that requires us to add back the mean after the PCA reconstruction.@@@2017-06-26T06:44:17Z@@@final_exam student
collaborative filtering@@@Why is it the case that collaborative filtering cant predict ratings for new users/movies? I read the post @330, which I think is related, but I still don't understand it. Is it simply because we estimate latent factors $$w_j$$ and $$z_i$$ for the existing movies and users and we simply don't have anything to estimate ratings of a new user or movie? But if, for example, we have a new user who has ratings for some movies why don't we just add that user into our original user/movie matrix and repeat the optimization process? Thanks!@@@(Warning: the below might look simple but it's not. Take your time!) Let's use the notation from the assignment, meaning the latent factors are $$u_i$$ and $$v_j$$ and we approximate $$y_{ij}\approx u_i^T v_j$$. Now imagine that $$y_{ij}$$ is missing for all $$j$$, meaningthat user $$i$$ has not rated any movies yet. Then there are no training examples to help us train $$u_i$$. Put another way, all predictions you might make with $$u_i$$ are missing training data, so we cannot train $$u_i$$ at all. The above is the PCA view of the problem. There is another view, which is that collaborative filtering finds similar users/movies (it's the same math, just different intuition).So if we want to predict $$y_{ij}$$, we could ask "what did user $$i$$ rate for similar movies?" or "what did similar users to user $$i$$ rate this movie as?" But if we have no ratings for user $$i$$ then we cannot answer either of these questions.@@@2017-06-26T00:25:21Z@@@other student
